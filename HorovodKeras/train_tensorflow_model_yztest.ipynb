{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tensorflow Model Distributed on Batch AI\n",
    "In this notebook we will train a TensorFlow model ([ResNet50](https://arxiv.org/abs/1512.03385)) in a distributed fashion using [Horovod](https://github.com/uber/horovod) on the Imagenet dataset. This tutorial will take you through the following steps:\n",
    " * [Create Azure Resources](#azure_resources)\n",
    " * [Create Fileserver(NFS)](#create_fileshare)\n",
    " * [Configure Batch AI Cluster](#configure_cluster)\n",
    " * [Submit and Monitor Job](#job)\n",
    " * [Clean Up Resources](#clean_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\") \n",
    "\n",
    "from dotenv import dotenv_values, set_key, find_dotenv, get_key\n",
    "from getpass import getpass\n",
    "import os\n",
    "import json\n",
    "from utils import get_password, write_json_to_file, dotenv_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the variables that describe our experiment. By default we are using the NC24rs_v3 (Standard_NC24rs_v3) VMs which have V100 GPUs and Infiniband. By default we are using 2 nodes with each node having 4 GPUs, this equates to 8 GPUs. Feel free to increase the number of nodes but be aware what limitations your subscription may have.\n",
    "\n",
    "Set the USE_FAKE to True if you want to use fake data rather than the Imagenet dataset. This is often a good way to debug your models as well as checking what IO overhead is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Variables for Batch AI - change as necessary\n",
    "ID                     = \"ddtftestyz\"\n",
    "GROUP_NAME             = f\"batch{ID}rg\"\n",
    "STORAGE_ACCOUNT_NAME   = f\"batch{ID}st\"\n",
    "FILE_SHARE_NAME        = f\"batch{ID}share\"\n",
    "SELECTED_SUBSCRIPTION  = \"Team Danielle Internal\" #\"<YOUR SUBSCRIPTION>\"\n",
    "WORKSPACE              = \"workspace\"\n",
    "NUM_NODES              = 2\n",
    "CLUSTER_NAME           = \"yzhang100\"\n",
    "VM_SIZE                = \"Standard_NC24rs_v3\"\n",
    "GPU_TYPE               = \"V100\"\n",
    "PROCESSES_PER_NODE     = 4\n",
    "LOCATION               = \"eastus\"\n",
    "NFS_NAME               = f\"batch{ID}nfs\"\n",
    "EXPERIMENT             = f\"distributed_tensorflow_{GPU_TYPE}\"\n",
    "USERNAME               = \"batchai_user\"\n",
    "USE_FAKE               = False\n",
    "DOCKERHUB              = \"yzhang001\" #\"<YOUR DOCKERHUB>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAKE='-env FAKE=True' if USE_FAKE else ''\n",
    "TOTAL_PROCESSES = PROCESSES_PER_NODE * NUM_NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='azure_resources'></a>\n",
    "## Create Azure Resources\n",
    "First we need to log in to our Azure account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AFZLBYPLW to authenticate.\u001b[0m\n",
      "CloudName    IsDefault    Name                                                State    TenantId\n",
      "-----------  -----------  --------------------------------------------------  -------  ------------------------------------\n",
      "AzureCloud   True         Boston DS Dev                                       Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Solution Template Testing                           Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        ADS Demo Subscription                               Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Energy Solution Accelerator                         Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Team Danielle Internal                              Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Azure Stack Diagnostics CI and Production VaaS      Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Core-ES-BLD                                         Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Cosmos_WDG_Core_BnB_100348                          Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Agile-BI-Azure-Subscription-2                       Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Visual Studio Enterprise                            Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        ACR-PROD(Converted to EA)                           Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Cloud AI PI - Microsoft Azure Internal Consumption  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Team Ilan                                           Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Marketing Automation                                Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        ADS Dev Dashboard                                   Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        ADS Metrics                                         Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more than one Azure account you will need to select it with the command below. If you only have one account you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set --subscription \"$SELECTED_SUBSCRIPTION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                                CloudName    SubscriptionId                        State    IsDefault\r\n",
      "--------------------------------------------------  -----------  ------------------------------------  -------  -----------\r\n",
      "Boston DS Dev                                       AzureCloud   0ca618d2-22a8-413a-96d0-0f1b531129c3  Enabled  False\r\n",
      "Solution Template Testing                           AzureCloud   3bcfa59c-82a0-44f9-ac08-b3479370bace  Enabled  False\r\n",
      "ADS Demo Subscription                               AzureCloud   9f156ff1-0bac-4c28-adcd-60bd97ff0cfc  Enabled  False\r\n",
      "Energy Solution Accelerator                         AzureCloud   a0691237-17b5-4b11-a762-63d8d3fecfd6  Enabled  False\r\n",
      "Team Danielle Internal                              AzureCloud   edf507a2-6235-46c5-b560-fd463ba2e771  Enabled  True\r\n",
      "Azure Stack Diagnostics CI and Production VaaS      AzureCloud   a8183b2d-7a4c-45e9-8736-dac11b84ff14  Enabled  False\r\n",
      "Core-ES-BLD                                         AzureCloud   54e18c35-3863-4a17-8e52-b5aa1e65847e  Enabled  False\r\n",
      "Cosmos_WDG_Core_BnB_100348                          AzureCloud   dae41bd3-9db4-4b9b-943e-832b57cac828  Enabled  False\r\n",
      "Agile-BI-Azure-Subscription-2                       AzureCloud   10d348d1-e991-47c3-b207-cc86d12b3685  Enabled  False\r\n",
      "Visual Studio Enterprise                            AzureCloud   eaca98da-dead-4803-af35-f0edb23e0537  Enabled  False\r\n",
      "ACR-PROD(Converted to EA)                           AzureCloud   0e6e36a3-d422-497b-b43f-6daa6b83f340  Enabled  False\r\n",
      "Cloud AI PI - Microsoft Azure Internal Consumption  AzureCloud   6b15cf91-a822-4e58-9418-76082752b9b9  Enabled  False\r\n",
      "Team Ilan                                           AzureCloud   ff18d7a8-962a-406c-858f-49acd23d6c01  Enabled  False\r\n",
      "Marketing Automation                                AzureCloud   03909a66-bef8-4d52-8e9a-a346604e0902  Enabled  False\r\n",
      "ADS Dev Dashboard                                   AzureCloud   3cd90aa9-e354-4485-94d8-692ab4525a64  Enabled  False\r\n",
      "ADS Metrics                                         AzureCloud   4b7166a6-fe39-492c-89ce-a67dc1ed87c3  Enabled  False\r\n"
     ]
    }
   ],
   "source": [
    "!az account list -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the group that will hold all our Azure resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\r\n",
      "----------  -----------------\r\n",
      "eastus      batchddtftestyzrg\r\n"
     ]
    }
   ],
   "source": [
    "!az group create -n $GROUP_NAME -l $LOCATION -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the storage account that will store our fileshare where all the outputs from the jobs will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage account batchddtftestyzst provisioning state: Succeeded\n"
     ]
    }
   ],
   "source": [
    "json_data = !az storage account create -l $LOCATION -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME --sku Standard_LRS\n",
    "print('Storage account {} provisioning state: {}'.format(STORAGE_ACCOUNT_NAME, \n",
    "                                                         json.loads(''.join(json_data))['provisioningState']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = !az storage account keys list -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME\n",
    "storage_account_key = json.loads(''.join([i for i in json_data if 'WARNING' not in i]))[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created\": false\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az storage share create --account-name $STORAGE_ACCOUNT_NAME \\\n",
    "--account-key $storage_account_key --name $FILE_SHARE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created\": false\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az storage directory create --share-name $FILE_SHARE_NAME  --name scripts \\\n",
    "--account-name $STORAGE_ACCOUNT_NAME --account-key $storage_account_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting some defaults so we don't have to keep adding them to every command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az configure --defaults location=$LOCATION\n",
    "!az configure --defaults group=$GROUP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AZURE_STORAGE_ACCOUNT=batchddtftestyzst\n",
      "env: AZURE_STORAGE_KEY=Dv6slfbR/0u0TJHUFGGwtFq1YHOXGCtXpUAotikZgFolEt+yP11mzFu8iY+C0xG6iM0lC7Qze2nVWTDMHWojZg==\n"
     ]
    }
   ],
   "source": [
    "%env AZURE_STORAGE_ACCOUNT $STORAGE_ACCOUNT_NAME\n",
    "%env AZURE_STORAGE_KEY=$storage_account_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Workspace\n",
    "Batch AI has the concept of workspaces and experiments. Below we will create the workspace for our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"creationTime\": \"2018-08-14T16:58:56.865000+00:00\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace\",\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"name\": \"workspace\",\r\n",
      "  \"provisioningState\": \"succeeded\",\r\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-14T16:58:56.865000+00:00\",\r\n",
      "  \"resourceGroup\": \"batchddtftestyzrg\",\r\n",
      "  \"tags\": null,\r\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai workspace create -n $WORKSPACE -g $GROUP_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_fileshare'></a>\n",
    "## Create Fileserver\n",
    "In this example we will store the data on an NFS fileshare. It is possible to use many storage solutions with Batch AI. NFS offers the best traideoff between performance and ease of use. The best performance is achieved by loading the data locally but this can be cumbersome since it requires that the data is download by the all the nodes which with the imagenet dataset can take hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"creationTime\": \"2018-08-15T13:13:37.339000+00:00\",\n",
      "  \"dataDisks\": {\n",
      "    \"cachingType\": \"none\",\n",
      "    \"diskCount\": 4,\n",
      "    \"diskSizeInGb\": 250,\n",
      "    \"storageAccountType\": \"Premium_LRS\"\n",
      "  },\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/fileservers/batchddtftestyznfs\",\n",
      "  \"mountSettings\": {\n",
      "    \"fileServerInternalIp\": \"10.0.0.4\",\n",
      "    \"fileServerPublicIp\": \"137.117.110.238\",\n",
      "    \"mountPoint\": \"/data\"\n",
      "  },\n",
      "  \"name\": \"batchddtftestyznfs\",\n",
      "  \"provisioningState\": \"succeeded\",\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-15T13:20:32.858000+00:00\",\n",
      "  \"resourceGroup\": \"batchddtftestyzrg\",\n",
      "  \"sshConfiguration\": {\n",
      "    \"publicIpsToAllow\": null,\n",
      "    \"userAccountSettings\": {\n",
      "      \"adminUserName\": \"batchai_user\",\n",
      "      \"adminUserPassword\": null,\n",
      "      \"adminUserSshPublicKey\": null\n",
      "    }\n",
      "  },\n",
      "  \"subnet\": {\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fileserverrg-e5c95496-3bca-48e0-8a8f-58491d5d4b9a/providers/Microsoft.Network/virtualNetworks/e5c95496-3bca-48e0-8a8f-58491d5d4b9avnet/subnets/Subnet-1\",\n",
      "    \"resourceGroup\": \"fileserverrg-e5c95496-3bca-48e0-8a8f-58491d5d4b9a\"\n",
      "  },\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/fileservers\",\n",
      "  \"vmSize\": \"Standard_DS4_v2\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai file-server create -n $NFS_NAME --disk-count 4 --disk-size 250 -w $WORKSPACE \\\n",
    "-s Standard_DS4_v2 -u $USERNAME -p {get_password(dotenv_for())} -g $GROUP_NAME --storage-sku Premium_LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                Resource Group     Size             Disks       Public IP        Internal IP    Mount Point\r\n",
      "------------------  -----------------  ---------------  ----------  ---------------  -------------  -------------\r\n",
      "batchddtftestyznfs  batchddtftestyzrg  Standard_DS4_v2  4 x 250 Gb  137.117.110.238  10.0.0.4       /data\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai file-server list -o table -w $WORKSPACE -g $GROUP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = !az batchai file-server list -w $WORKSPACE -g $GROUP_NAME\n",
    "nfs_ip=json.loads(''.join([i for i in json_data if 'WARNING' not in i]))[0]['mountSettings']['fileServerPublicIp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have created the NFS share we need to copy the data to it. To do this we write the script below which will be executed on the fileserver. It installs a tool called azcopy and then downloads and extracts the data to the appropriate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nodeprep.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile nodeprep.sh\n",
    "#!/usr/bin/env bash\n",
    "wget https://gist.githubusercontent.com/msalvaris/073c28a9993d58498957294d20d74202/raw/87a78275879f7c9bb8d6fb9de8a2d2996bb66c24/install_azcopy\n",
    "chmod 777 install_azcopy\n",
    "sudo ./install_azcopy\n",
    "\n",
    "mkdir -p /data/imagenet\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/validation.csv \\\n",
    "        --destination  /data/imagenet/validation.csv\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=7x3rN7c/nlXbnZ0gAFywd5Er3r6MdwCq97Vwvda25WE%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/validation.tar.gz \\\n",
    "        --destination  /data/imagenet/validation.tar.gz\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=zy8L4shZa3XXBe152hPnhXsyfBqCufDOz01a9ZHWU28%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/train.csv \\\n",
    "        --destination  /data/imagenet/train.csv\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=EUcahDDZcefOKtHoVWDh7voAC1BoxYNM512spFmjmDU%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/train.tar.gz \\\n",
    "        --destination  /data/imagenet/train.tar.gz\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=qP%2B7lQuFKHo5UhQKpHcKt6p5fHT21lPaLz1O/vv4FNU%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "cd /data/imagenet\n",
    "tar -xzf train.tar.gz\n",
    "tar -xzf validation.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will copy the file over and run it on the NFS VM. This will install azcopy and download and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batchai_user'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'137.117.110.238'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfs_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K - Finished ..\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!az batchai file-server delete -n $NFS_NAME -g $GROUP_NAME -w $WORKSPACE -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\r\n",
      "\u001b[0mCommand\u001b[0m\r\n",
      "\u001b[0m    az batchai file-server delete : Delete a file server.\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0mArguments\u001b[0m\r\n",
      "\u001b[0m    --no-wait           : Do not wait for the long-running operation to finish.\u001b[0m\r\n",
      "\u001b[0m    --yes -y            : Do not prompt for confirmation.\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0mResource Id Arguments\u001b[0m\r\n",
      "\u001b[0m    --ids               : One or more resource IDs (space-delimited). If provided, no other\r\n",
      "                          'Resource Id' arguments should be specified.\u001b[0m\r\n",
      "\u001b[0m    --name -n           : Name of file server.\u001b[0m\r\n",
      "\u001b[0m    --resource-group -g : Name of resource group. You can configure the default group using `az\r\n",
      "                          configure --defaults group=<name>`.  Default: batchddtftestyzrg.\u001b[0m\r\n",
      "\u001b[0m    --workspace -w      : Name of workspace.\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0mGlobal Arguments\u001b[0m\r\n",
      "\u001b[0m    --debug             : Increase logging verbosity to show all debug logs.\u001b[0m\r\n",
      "\u001b[0m    --help -h           : Show this help message and exit.\u001b[0m\r\n",
      "\u001b[0m    --output -o         : Output format.  Allowed values: json, jsonc, table, tsv, yaml.  Default:\r\n",
      "                          json.\u001b[0m\r\n",
      "\u001b[0m    --query             : JMESPath query string. See http://jmespath.org/ for more information and\r\n",
      "                          examples.\u001b[0m\r\n",
      "\u001b[0m    --subscription      : Name or ID of subscription. You can configure the default subscription\r\n",
      "                          using `az account set -s NAME_OR_ID`.\u001b[0m\r\n",
      "\u001b[0m    --verbose           : Increase logging verbosity. Use --debug for full debug logs.\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0mExamples\u001b[0m\r\n",
      "\u001b[0m    Delete file server and wait for deletion to be completed.\u001b[0m\r\n",
      "\u001b[0m        az batchai file-server delete -g MyResourceGroup -w MyWorkspace -n MyNFS\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0m    Delete file server without asking for confirmation (for non-interactive scenarios).\u001b[0m\r\n",
      "\u001b[0m        az batchai file-server delete -g MyResourceGroup -w MyWorkspace -n MyNFS -y\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0m    Request file server deletion without waiting for deletion to be completed.\u001b[0m\r\n",
      "\u001b[0m        az batchai file-server delete -g MyResourceGroup -w MyWorkspace -n MyNFS --no-wait\u001b[0m\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!az batchai file-server delete --help "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added '137.117.110.238' (ECDSA) to the list of known hosts.\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!sshpass -p {get_password(dotenv_for())} scp -o \"StrictHostKeyChecking=no\" nodeprep.sh $USERNAME@{nfs_ip}:~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-08-15 13:27:32--  https://gist.githubusercontent.com/msalvaris/073c28a9993d58498957294d20d74202/raw/87a78275879f7c9bb8d6fb9de8a2d2996bb66c24/install_azcopy\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.32.133\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 481 [text/plain]\n",
      "Saving to: ‘install_azcopy’\n",
      "\n",
      "     0K                                                       100%  118M=0s\n",
      "\n",
      "2018-08-15 13:27:32 (118 MB/s) - ‘install_azcopy’ saved [481/481]\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   983  100   983    0     0   4568      0 --:--:-- --:--:-- --:--:--  4572\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [107 kB]\n",
      "Get:2 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial InRelease [2,846 B]\n",
      "Hit:3 http://azure.archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Get:4 http://azure.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu xenial-security/main Sources [131 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu xenial-security/restricted Sources [2,116 B]\n",
      "Get:7 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [70.8 kB]\n",
      "Get:8 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial/main amd64 Packages [48.8 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu xenial-security/multiverse Sources [2,088 B]\n",
      "Get:10 http://azure.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:11 http://azure.archive.ubuntu.com/ubuntu xenial/main Sources [868 kB]\n",
      "Get:12 http://azure.archive.ubuntu.com/ubuntu xenial/restricted Sources [4,808 B]\n",
      "Get:13 http://azure.archive.ubuntu.com/ubuntu xenial/universe Sources [7,728 kB]\n",
      "Get:14 http://azure.archive.ubuntu.com/ubuntu xenial/multiverse Sources [179 kB]\n",
      "Get:15 http://azure.archive.ubuntu.com/ubuntu xenial-updates/main Sources [318 kB]\n",
      "Get:16 http://azure.archive.ubuntu.com/ubuntu xenial-updates/restricted Sources [2,528 B]\n",
      "Get:17 http://azure.archive.ubuntu.com/ubuntu xenial-updates/universe Sources [218 kB]\n",
      "Get:18 http://azure.archive.ubuntu.com/ubuntu xenial-updates/multiverse Sources [8,408 B]\n",
      "Get:19 http://azure.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [831 kB]\n",
      "Get:20 http://azure.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [680 kB]\n",
      "Get:21 http://azure.archive.ubuntu.com/ubuntu xenial-backports/main Sources [4,488 B]\n",
      "Get:22 http://azure.archive.ubuntu.com/ubuntu xenial-backports/universe Sources [6,736 B]\n",
      "Fetched 11.4 MB in 2s (4,839 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  aspnetcore-store-2.0.0 dotnet-host dotnet-hostfxr-2.0.0 dotnet-runtime-2.0.0\n",
      "  libcurl3 liblttng-ust-ctl2 liblttng-ust0 liburcu4\n",
      "The following NEW packages will be installed:\n",
      "  aspnetcore-store-2.0.0 dotnet-host dotnet-hostfxr-2.0.0 dotnet-runtime-2.0.0\n",
      "  dotnet-sdk-2.0.2 libcurl3 liblttng-ust-ctl2 liblttng-ust0 liburcu4\n",
      "0 upgraded, 9 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 108 MB of archives.\n",
      "After this operation, 311 MB of additional disk space will be used.\n",
      "Get:1 http://azure.archive.ubuntu.com/ubuntu xenial-updates/main amd64 libcurl3 amd64 7.47.0-1ubuntu2.8 [187 kB]\n",
      "Get:2 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial/main amd64 aspnetcore-store-2.0.0 amd64 2.0.0-1 [18.1 MB]\n",
      "Get:3 http://azure.archive.ubuntu.com/ubuntu xenial/universe amd64 liburcu4 amd64 0.9.1-3 [47.3 kB]\n",
      "Get:4 http://azure.archive.ubuntu.com/ubuntu xenial/universe amd64 liblttng-ust-ctl2 amd64 2.7.1-1 [72.2 kB]\n",
      "Get:5 http://azure.archive.ubuntu.com/ubuntu xenial/universe amd64 liblttng-ust0 amd64 2.7.1-1 [127 kB]\n",
      "Get:6 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial/main amd64 dotnet-host amd64 2.1.2-1 [36.5 kB]\n",
      "Get:7 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial/main amd64 dotnet-hostfxr-2.0.0 amd64 2.0.0-1 [135 kB]\n",
      "Get:8 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial/main amd64 dotnet-runtime-2.0.0 amd64 2.0.0-1 [18.6 MB]\n",
      "Get:9 https://packages.microsoft.com/repos/microsoft-ubuntu-xenial-prod xenial/main amd64 dotnet-sdk-2.0.2 amd64 2.0.2-1 [70.5 MB]\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Fetched 108 MB in 5s (20.9 MB/s)\n",
      "Selecting previously unselected package aspnetcore-store-2.0.0.\n",
      "(Reading database ... 55210 files and directories currently installed.)\n",
      "Preparing to unpack .../aspnetcore-store-2.0.0_2.0.0-1_amd64.deb ...\n",
      "Unpacking aspnetcore-store-2.0.0 (2.0.0-1) ...\n",
      "Selecting previously unselected package dotnet-host.\n",
      "Preparing to unpack .../dotnet-host_2.1.2-1_amd64.deb ...\n",
      "Unpacking dotnet-host (2.1.2-1) ...\n",
      "Selecting previously unselected package dotnet-hostfxr-2.0.0.\n",
      "Preparing to unpack .../dotnet-hostfxr-2.0.0_2.0.0-1_amd64.deb ...\n",
      "Unpacking dotnet-hostfxr-2.0.0 (2.0.0-1) ...\n",
      "Selecting previously unselected package libcurl3:amd64.\n",
      "Preparing to unpack .../libcurl3_7.47.0-1ubuntu2.8_amd64.deb ...\n",
      "Unpacking libcurl3:amd64 (7.47.0-1ubuntu2.8) ...\n",
      "Selecting previously unselected package liburcu4:amd64.\n",
      "Preparing to unpack .../liburcu4_0.9.1-3_amd64.deb ...\n",
      "Unpacking liburcu4:amd64 (0.9.1-3) ...\n",
      "Selecting previously unselected package liblttng-ust-ctl2:amd64.\n",
      "Preparing to unpack .../liblttng-ust-ctl2_2.7.1-1_amd64.deb ...\n",
      "Unpacking liblttng-ust-ctl2:amd64 (2.7.1-1) ...\n",
      "Selecting previously unselected package liblttng-ust0:amd64.\n",
      "Preparing to unpack .../liblttng-ust0_2.7.1-1_amd64.deb ...\n",
      "Unpacking liblttng-ust0:amd64 (2.7.1-1) ...\n",
      "Selecting previously unselected package dotnet-runtime-2.0.0.\n",
      "Preparing to unpack .../dotnet-runtime-2.0.0_2.0.0-1_amd64.deb ...\n",
      "Unpacking dotnet-runtime-2.0.0 (2.0.0-1) ...\n",
      "Selecting previously unselected package dotnet-sdk-2.0.2.\n",
      "Preparing to unpack .../dotnet-sdk-2.0.2_2.0.2-1_amd64.deb ...\n",
      "Unpacking dotnet-sdk-2.0.2 (2.0.2-1) ...\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu10) ...\n",
      "Setting up aspnetcore-store-2.0.0 (2.0.0-1) ...\n",
      "Setting up dotnet-host (2.1.2-1) ...\n",
      "Setting up dotnet-hostfxr-2.0.0 (2.0.0-1) ...\n",
      "Setting up libcurl3:amd64 (7.47.0-1ubuntu2.8) ...\n",
      "Setting up liburcu4:amd64 (0.9.1-3) ...\n",
      "Setting up liblttng-ust-ctl2:amd64 (2.7.1-1) ...\n",
      "Setting up liblttng-ust0:amd64 (2.7.1-1) ...\n",
      "Setting up dotnet-runtime-2.0.0 (2.0.0-1) ...\n",
      "Setting up dotnet-sdk-2.0.2 (2.0.2-1) ...\n",
      "This software may collect information about you and your use of the software, and send that to Microsoft.\n",
      "Please visit http://aka.ms/dotnet-cli-eula for more information.\n",
      "Welcome to .NET Core!\n",
      "---------------------\n",
      "Learn more about .NET Core @ https://aka.ms/dotnet-docs. Use dotnet --help to see available commands or go to https://aka.ms/dotnet-cli-docs.\n",
      "\n",
      ".NET Core Tools Telemetry\n",
      "--------------\n",
      "The .NET Core Tools include a telemetry feature that collects usage information. It is important that the .NET Team understands how the tools are being used so that we can improve them.\n",
      "\n",
      "The data collected is anonymous and will be published in an aggregated form for use by both Microsoft and community engineers under the Creative Commons Attribution License.\n",
      "\n",
      "The .NET Core Tools telemetry feature is enabled by default. You can opt-out of the telemetry feature by setting an environment variable DOTNET_CLI_TELEMETRY_OPTOUT (for example, 'export' on macOS/Linux, 'set' on Windows) to true (for example, 'true', 1). You can read more about .NET Core tools telemetry at https://aka.ms/dotnet-cli-telemetry.\n",
      "\n",
      "Installation Note\n",
      "--------------\n",
      "A command will be run during the install process that will improve project restore speed and enable offline access. It will take up to a minute to complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing triggers for libc-bin (2.23-0ubuntu10) ...\n",
      "--2018-08-15 13:28:19--  https://aka.ms/downloadazcopyprlinux\n",
      "Resolving aka.ms (aka.ms)... 23.212.169.122\n",
      "Connecting to aka.ms (aka.ms)|23.212.169.122|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://azcopy.azureedge.net/azcopy-7-1-0-netcorepreview/azcopy_7.1.0-netcorepreview_all.tar.gz [following]\n",
      "--2018-08-15 13:28:20--  https://azcopy.azureedge.net/azcopy-7-1-0-netcorepreview/azcopy_7.1.0-netcorepreview_all.tar.gz\n",
      "Resolving azcopy.azureedge.net (azcopy.azureedge.net)... 72.21.81.200, 2606:2800:11f:17a5:191a:18d5:537:22f9\n",
      "Connecting to azcopy.azureedge.net (azcopy.azureedge.net)|72.21.81.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3841375 (3.7M) [application/octet-stream]\n",
      "Saving to: ‘azcopy.tar.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1% 5.55M 1s\n",
      "    50K .......... .......... .......... .......... ..........  2%  282M 0s\n",
      "   100K .......... .......... .......... .......... ..........  3% 18.3M 0s\n",
      "   150K .......... .......... .......... .......... ..........  5%  182M 0s\n",
      "   200K .......... .......... .......... .......... ..........  6% 21.4M 0s\n",
      "   250K .......... .......... .......... .......... ..........  7%  144M 0s\n",
      "   300K .......... .......... .......... .......... ..........  9%  155M 0s\n",
      "   350K .......... .......... .......... .......... .......... 10% 23.7M 0s\n",
      "   400K .......... .......... .......... .......... .......... 11%  161M 0s\n",
      "   450K .......... .......... .......... .......... .......... 13%  186M 0s\n",
      "   500K .......... .......... .......... .......... .......... 14%  185M 0s\n",
      "   550K .......... .......... .......... .......... .......... 15%  190M 0s\n",
      "   600K .......... .......... .......... .......... .......... 17%  195M 0s\n",
      "   650K .......... .......... .......... .......... .......... 18% 30.9M 0s\n",
      "   700K .......... .......... .......... .......... .......... 19% 19.6M 0s\n",
      "   750K .......... .......... .......... .......... .......... 21%  121M 0s\n",
      "   800K .......... .......... .......... .......... .......... 22%  172M 0s\n",
      "   850K .......... .......... .......... .......... .......... 23% 63.6M 0s\n",
      "   900K .......... .......... .......... .......... .......... 25% 5.84M 0s\n",
      "   950K .......... .......... .......... .......... .......... 26%  241M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 27%  149M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 29%  201M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 30%  244M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 31%  181M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 33%  227M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 34% 48.4M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 35%  171M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 37%  151M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 38%  271M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 39%  180M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 41%  293M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 42%  159M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 43%  252M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 45%  168M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 46%  272M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 47%  187M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 49%  244M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 50%  198M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 51%  226M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 53%  161M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 54%  171M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 55%  176M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 57%  258M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 58%  148M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 59%  272M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 61%  157M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 62%  273M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 63%  177M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 65%  153M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 66%  274M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 67%  279M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 69%  123M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 70%  286M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 71%  262M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 73%  165M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 74%  189M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 75%  155M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 77%  263M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 78%  260M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 79%  136M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 81%  272M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 82%  277M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 83%  155M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 85%  210M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 86%  311M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 87%  182M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 89%  158M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 90%  205M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 91%  252M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 93%  254M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 94%  238M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 95%  182M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 97%  167M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 98%  192M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 99%  239M 0s\n",
      "  3750K .                                                     100% 2561G=0.05s\n",
      "\n",
      "2018-08-15 13:28:20 (78.7 MB/s) - ‘azcopy.tar.gz’ saved [3841375/3841375]\n",
      "\n",
      "sending incremental file list\n",
      "AzCopyConfig.json\n",
      "Microsoft.Data.Edm.dll\n",
      "Microsoft.Data.OData.dll\n",
      "Microsoft.DotNet.Cli.CommandLine.dll\n",
      "Microsoft.WindowsAzure.Storage.AzCopy.CommandLineParameters.dll\n",
      "Microsoft.WindowsAzure.Storage.AzCopy.Common.dll\n",
      "Microsoft.WindowsAzure.Storage.AzCopy.GetOptCommandLineParser.dll\n",
      "Microsoft.WindowsAzure.Storage.DataMovement.dll\n",
      "Microsoft.WindowsAzure.Storage.dll\n",
      "Newtonsoft.Json.dll\n",
      "System.IO.Packaging.dll\n",
      "System.Spatial.dll\n",
      "azcopy.deps.json\n",
      "azcopy.dll\n",
      "azcopy.runtimeconfig.json\n",
      "azcopy_autocomplete\n",
      "es/\n",
      "es/Microsoft.Data.Edm.resources.dll\n",
      "es/Microsoft.Data.OData.resources.dll\n",
      "es/System.Spatial.resources.dll\n",
      "fr/\n",
      "fr/Microsoft.Data.Edm.resources.dll\n",
      "fr/Microsoft.Data.OData.resources.dll\n",
      "fr/System.Spatial.resources.dll\n",
      "it/\n",
      "it/Microsoft.Data.Edm.resources.dll\n",
      "it/Microsoft.Data.OData.resources.dll\n",
      "it/System.Spatial.resources.dll\n",
      "ja/\n",
      "ja/Microsoft.Data.Edm.resources.dll\n",
      "ja/Microsoft.Data.OData.resources.dll\n",
      "ja/System.Spatial.resources.dll\n",
      "ko/\n",
      "ko/Microsoft.Data.Edm.resources.dll\n",
      "ko/Microsoft.Data.OData.resources.dll\n",
      "ko/System.Spatial.resources.dll\n",
      "ru/\n",
      "ru/Microsoft.Data.Edm.resources.dll\n",
      "ru/Microsoft.Data.OData.resources.dll\n",
      "ru/System.Spatial.resources.dll\n",
      "runtimes/\n",
      "runtimes/linux-arm/\n",
      "runtimes/linux-arm/lib/\n",
      "runtimes/linux-arm/lib/netstandard2.0/\n",
      "runtimes/linux-arm/lib/netstandard2.0/Mono.Posix.NETStandard.dll\n",
      "runtimes/linux-arm/native/\n",
      "runtimes/linux-arm/native/libMonoPosixHelper.so\n",
      "runtimes/linux-arm64/\n",
      "runtimes/linux-arm64/lib/\n",
      "runtimes/linux-arm64/lib/netstandard2.0/\n",
      "runtimes/linux-arm64/lib/netstandard2.0/Mono.Posix.NETStandard.dll\n",
      "runtimes/linux-arm64/native/\n",
      "runtimes/linux-arm64/native/libMonoPosixHelper.so\n",
      "runtimes/linux-armel/\n",
      "runtimes/linux-armel/lib/\n",
      "runtimes/linux-armel/lib/netstandard2.0/\n",
      "runtimes/linux-armel/lib/netstandard2.0/Mono.Posix.NETStandard.dll\n",
      "runtimes/linux-armel/native/\n",
      "runtimes/linux-armel/native/libMonoPosixHelper.so\n",
      "runtimes/linux-x64/\n",
      "runtimes/linux-x64/lib/\n",
      "runtimes/linux-x64/lib/netstandard2.0/\n",
      "runtimes/linux-x64/lib/netstandard2.0/Mono.Posix.NETStandard.dll\n",
      "runtimes/linux-x64/native/\n",
      "runtimes/linux-x64/native/libMonoPosixHelper.so\n",
      "runtimes/linux-x86/\n",
      "runtimes/linux-x86/lib/\n",
      "runtimes/linux-x86/lib/netstandard2.0/\n",
      "runtimes/linux-x86/lib/netstandard2.0/Mono.Posix.NETStandard.dll\n",
      "runtimes/linux-x86/native/\n",
      "runtimes/linux-x86/native/libMonoPosixHelper.so\n",
      "runtimes/osx/\n",
      "runtimes/osx/lib/\n",
      "runtimes/osx/lib/netstandard2.0/\n",
      "runtimes/osx/lib/netstandard2.0/Mono.Posix.NETStandard.dll\n",
      "runtimes/osx/native/\n",
      "runtimes/osx/native/libMonoPosixHelper.dylib\n",
      "runtimes/unix/\n",
      "runtimes/unix/lib/\n",
      "runtimes/unix/lib/netstandard1.3/\n",
      "runtimes/unix/lib/netstandard1.3/System.Security.Cryptography.ProtectedData.dll\n",
      "runtimes/win/\n",
      "runtimes/win/lib/\n",
      "runtimes/win/lib/netstandard1.3/\n",
      "runtimes/win/lib/netstandard1.3/System.Security.Cryptography.ProtectedData.dll\n",
      "zh-Hans/\n",
      "zh-Hans/Microsoft.Data.Edm.resources.dll\n",
      "zh-Hans/Microsoft.Data.OData.resources.dll\n",
      "zh-Hans/System.Spatial.resources.dll\n",
      "zh-Hant/\n",
      "zh-Hant/Microsoft.Data.Edm.resources.dll\n",
      "zh-Hant/Microsoft.Data.OData.resources.dll\n",
      "zh-Hant/System.Spatial.resources.dll\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sent 11,682,997 bytes  received 1,290 bytes  23,368,574.00 bytes/sec\n",
      "total size is 11,675,344  speedup is 1.00\n",
      "[2018/08/15 13:28:22] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:01\n",
      "[2018/08/15 13:28:47] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:25\n",
      "[2018/08/15 13:29:03] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:01\n",
      "[2018/08/15 13:41:33] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:12:21\n"
     ]
    }
   ],
   "source": [
    "!sshpass -p {get_password(dotenv_for())} ssh -o \"StrictHostKeyChecking=no\" $USERNAME@{nfs_ip} \"sudo chmod 777 ~/nodeprep.sh && ./nodeprep.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distributed_tensorflow_V100'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K - Starting ..\r",
      "\r",
      "\u001b[K - Finished ..\r",
      "\r",
      "\u001b[K{\r\n",
      "  \"creationTime\": \"2018-08-15T14:16:59.595000+00:00\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/experiments/distributed_tensorflow_v100\",\r\n",
      "  \"name\": \"distributed_tensorflow_v100\",\r\n",
      "  \"provisioningState\": \"succeeded\",\r\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-15T14:16:59.595000+00:00\",\r\n",
      "  \"resourceGroup\": \"batchddtftestyzrg\",\r\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/experiments\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai experiment create -n $EXPERIMENT -g $GROUP_NAME -w $WORKSPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='configure_cluster'></a>\n",
    "## Configure Batch AI Cluster\n",
    "We then upload the scripts we wish to execute onto the fileshare. The fileshare will later be mounted by Batch AI. An alternative to uploading the scripts would be to embedd them inside the Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished[#############################################################]  100.0000%\n",
      "Finished[#############################################################]  100.0000%\n",
      "Finished[#############################################################]  100.0000%\n"
     ]
    }
   ],
   "source": [
    "!az storage file upload --share-name $FILE_SHARE_NAME --source ./src/imagenet_estimator_tf_horovod.py --path scripts\n",
    "!az storage file upload --share-name $FILE_SHARE_NAME --source ./src/resnet_model.py --path scripts\n",
    "!az storage file upload --share-name $FILE_SHARE_NAME --source ../common/timer.py --path scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below it the command to create the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"allocationState\": \"resizing\",\n",
      "  \"allocationStateTransitionTime\": \"2018-08-15T14:24:04.869000+00:00\",\n",
      "  \"creationTime\": \"2018-08-15T14:24:04.869000+00:00\",\n",
      "  \"currentNodeCount\": 0,\n",
      "  \"errors\": null,\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/clusters/yzhang100\",\n",
      "  \"name\": \"yzhang100\",\n",
      "  \"nodeSetup\": {\n",
      "    \"mountVolumes\": {\n",
      "      \"azureBlobFileSystems\": null,\n",
      "      \"azureFileShares\": [\n",
      "        {\n",
      "          \"accountName\": \"batchddtftestyzst\",\n",
      "          \"azureFileUrl\": \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare\",\n",
      "          \"credentials\": {\n",
      "            \"accountKey\": null,\n",
      "            \"accountKeySecretReference\": null\n",
      "          },\n",
      "          \"directoryMode\": \"0777\",\n",
      "          \"fileMode\": \"0777\",\n",
      "          \"relativeMountPath\": \"extfs\"\n",
      "        }\n",
      "      ],\n",
      "      \"fileServers\": [\n",
      "        {\n",
      "          \"fileServer\": {\n",
      "            \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/fileservers/batchddtftestyznfs\",\n",
      "            \"resourceGroup\": \"batchddtftestyzrg\"\n",
      "          },\n",
      "          \"mountOptions\": \"rw\",\n",
      "          \"relativeMountPath\": \"nfs\",\n",
      "          \"sourceDirectory\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmanagedFileSystems\": null\n",
      "    },\n",
      "    \"performanceCountersSettings\": null,\n",
      "    \"setupTask\": null\n",
      "  },\n",
      "  \"nodeStateCounts\": {\n",
      "    \"idleNodeCount\": 0,\n",
      "    \"leavingNodeCount\": 0,\n",
      "    \"preparingNodeCount\": 0,\n",
      "    \"runningNodeCount\": 0,\n",
      "    \"unusableNodeCount\": 0\n",
      "  },\n",
      "  \"provisioningState\": \"succeeded\",\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-15T14:24:37.749000+00:00\",\n",
      "  \"resourceGroup\": \"batchddtftestyzrg\",\n",
      "  \"scaleSettings\": {\n",
      "    \"autoScale\": null,\n",
      "    \"manual\": {\n",
      "      \"nodeDeallocationOption\": \"requeue\",\n",
      "      \"targetNodeCount\": 2\n",
      "    }\n",
      "  },\n",
      "  \"subnet\": {\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fileserverrg-e5c95496-3bca-48e0-8a8f-58491d5d4b9a/providers/Microsoft.Network/virtualNetworks/e5c95496-3bca-48e0-8a8f-58491d5d4b9avnet/subnets/Subnet-1\",\n",
      "    \"resourceGroup\": \"fileserverrg-e5c95496-3bca-48e0-8a8f-58491d5d4b9a\"\n",
      "  },\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/clusters\",\n",
      "  \"userAccountSettings\": {\n",
      "    \"adminUserName\": \"batchai_user\",\n",
      "    \"adminUserPassword\": null,\n",
      "    \"adminUserSshPublicKey\": null\n",
      "  },\n",
      "  \"virtualMachineConfiguration\": {\n",
      "    \"imageReference\": {\n",
      "      \"offer\": \"UbuntuServer\",\n",
      "      \"publisher\": \"Canonical\",\n",
      "      \"sku\": \"16.04-LTS\",\n",
      "      \"version\": \"latest\",\n",
      "      \"virtualMachineImageId\": null\n",
      "    }\n",
      "  },\n",
      "  \"vmPriority\": \"dedicated\",\n",
      "  \"vmSize\": \"STANDARD_NC24RS_V3\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai cluster create \\\n",
    "    -w $WORKSPACE \\\n",
    "    --name $CLUSTER_NAME \\\n",
    "    --image UbuntuLTS \\\n",
    "    --vm-size $VM_SIZE \\\n",
    "    --min $NUM_NODES --max $NUM_NODES \\\n",
    "    --afs-name $FILE_SHARE_NAME \\\n",
    "    --afs-mount-path extfs \\\n",
    "    --user-name $USERNAME \\\n",
    "    --password {get_password(dotenv_for())} \\\n",
    "    --storage-account-name $STORAGE_ACCOUNT_NAME \\\n",
    "    --storage-account-key $storage_account_key \\\n",
    "    --nfs $NFS_NAME \\\n",
    "    --nfs-mount-path nfs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the cluster was created succesfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"allocationState\": \"steady\",\r\n",
      "  \"allocationStateTransitionTime\": \"2018-08-15T14:26:33.091000+00:00\",\r\n",
      "  \"creationTime\": \"2018-08-15T14:24:04.869000+00:00\",\r\n",
      "  \"currentNodeCount\": 2,\r\n",
      "  \"errors\": null,\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/clusters/yzhang100\",\r\n",
      "  \"name\": \"yzhang100\",\r\n",
      "  \"nodeSetup\": {\r\n",
      "    \"mountVolumes\": {\r\n",
      "      \"azureBlobFileSystems\": null,\r\n",
      "      \"azureFileShares\": [\r\n",
      "        {\r\n",
      "          \"accountName\": \"batchddtftestyzst\",\r\n",
      "          \"azureFileUrl\": \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare\",\r\n",
      "          \"credentials\": {\r\n",
      "            \"accountKey\": null,\r\n",
      "            \"accountKeySecretReference\": null\r\n",
      "          },\r\n",
      "          \"directoryMode\": \"0777\",\r\n",
      "          \"fileMode\": \"0777\",\r\n",
      "          \"relativeMountPath\": \"extfs\"\r\n",
      "        }\r\n",
      "      ],\r\n",
      "      \"fileServers\": [\r\n",
      "        {\r\n",
      "          \"fileServer\": {\r\n",
      "            \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/fileservers/batchddtftestyznfs\",\r\n",
      "            \"resourceGroup\": \"batchddtftestyzrg\"\r\n",
      "          },\r\n",
      "          \"mountOptions\": \"rw\",\r\n",
      "          \"relativeMountPath\": \"nfs\",\r\n",
      "          \"sourceDirectory\": null\r\n",
      "        }\r\n",
      "      ],\r\n",
      "      \"unmanagedFileSystems\": null\r\n",
      "    },\r\n",
      "    \"performanceCountersSettings\": null,\r\n",
      "    \"setupTask\": null\r\n",
      "  },\r\n",
      "  \"nodeStateCounts\": {\r\n",
      "    \"idleNodeCount\": 0,\r\n",
      "    \"leavingNodeCount\": 0,\r\n",
      "    \"preparingNodeCount\": 2,\r\n",
      "    \"runningNodeCount\": 0,\r\n",
      "    \"unusableNodeCount\": 0\r\n",
      "  },\r\n",
      "  \"provisioningState\": \"succeeded\",\r\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-15T14:24:37.749000+00:00\",\r\n",
      "  \"resourceGroup\": \"batchddtftestyzrg\",\r\n",
      "  \"scaleSettings\": {\r\n",
      "    \"autoScale\": null,\r\n",
      "    \"manual\": {\r\n",
      "      \"nodeDeallocationOption\": \"requeue\",\r\n",
      "      \"targetNodeCount\": 2\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"subnet\": {\r\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fileserverrg-e5c95496-3bca-48e0-8a8f-58491d5d4b9a/providers/Microsoft.Network/virtualNetworks/e5c95496-3bca-48e0-8a8f-58491d5d4b9avnet/subnets/Subnet-1\",\r\n",
      "    \"resourceGroup\": \"fileserverrg-e5c95496-3bca-48e0-8a8f-58491d5d4b9a\"\r\n",
      "  },\r\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/clusters\",\r\n",
      "  \"userAccountSettings\": {\r\n",
      "    \"adminUserName\": \"batchai_user\",\r\n",
      "    \"adminUserPassword\": null,\r\n",
      "    \"adminUserSshPublicKey\": null\r\n",
      "  },\r\n",
      "  \"virtualMachineConfiguration\": {\r\n",
      "    \"imageReference\": {\r\n",
      "      \"offer\": \"UbuntuServer\",\r\n",
      "      \"publisher\": \"Canonical\",\r\n",
      "      \"sku\": \"16.04-LTS\",\r\n",
      "      \"version\": \"latest\",\r\n",
      "      \"virtualMachineImageId\": null\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"vmPriority\": \"dedicated\",\r\n",
      "  \"vmSize\": \"STANDARD_NC24RS_V3\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster show -n $CLUSTER_NAME -w $WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name       Resource Group     Workspace    VM Size             State    Idle    Running    Preparing    Leaving    Unusable\r\n",
      "---------  -----------------  -----------  ------------------  -------  ------  ---------  -----------  ---------  ----------\r\n",
      "yzhang100  batchddtftestyzrg  workspace    STANDARD_NC24RS_V3  steady   0       0          2            0          0\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster list -w $WORKSPACE -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                IP            SSH Port\r\n",
      "--------------------------------  ------------  ----------\r\n",
      "tvm-587366007_1-20180815t142631z  40.87.83.215  50001\r\n",
      "tvm-587366007_2-20180815t142631z  40.87.83.215  50000\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster node list -c $CLUSTER_NAME -w $WORKSPACE -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "## Submit and Monitor Job\n",
    "Below we specify the job we wish to execute.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_dict = {\n",
    "  \"$schema\": \"https://raw.githubusercontent.com/Azure/BatchAI/master/schemas/2017-09-01-preview/job.json\",\n",
    "  \"properties\": {\n",
    "    \"nodeCount\": NUM_NODES,\n",
    "    \"customToolkitSettings\": {\n",
    "      \"commandLine\": f\"source /opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin/mpivars.sh; \\\n",
    "      echo $AZ_BATCH_HOST_LIST; \\\n",
    "      mpirun -n {TOTAL_PROCESSES} -ppn {PROCESSES_PER_NODE} -hosts $AZ_BATCH_HOST_LIST \\\n",
    "      -env I_MPI_FABRICS=dapl \\\n",
    "      -env I_MPI_DAPL_PROVIDER=ofa-v2-ib0 \\\n",
    "      -env I_MPI_DYNAMIC_CONNECTION=0 \\\n",
    "      -env I_MPI_DEBUG=6 \\\n",
    "      -env I_MPI_HYDRA_DEBUG=on \\\n",
    "      -env DISTRIBUTED=True \\\n",
    "      {FAKE} \\\n",
    "      python -u $AZ_BATCHAI_INPUT_SCRIPTS/imagenet_estimator_tf_horovod.py\"\n",
    "    },\n",
    "    \"stdOutErrPathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
    "    \"inputDirectories\": [{\n",
    "        \"id\": \"SCRIPTS\",\n",
    "        \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs/scripts\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"TRAIN\",\n",
    "        \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\",\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"TEST\",\n",
    "        \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\",\n",
    "      },\n",
    "    ],\n",
    "    \"outputDirectories\": [{\n",
    "        \"id\": \"MODEL\",\n",
    "        \"pathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
    "        \"pathSuffix\": \"Models\"\n",
    "    }],\n",
    "    \"containerSettings\": {\n",
    "      \"imageSourceRegistry\": {\n",
    "        \"image\": f\"{DOCKERHUB}/distributed-training.horovod-tf\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_to_file(jobs_dict, 'job.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME='tf-horovod-{}'.format(NUM_NODES*PROCESSES_PER_NODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now submit the job to Batch AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"caffe2Settings\": null,\n",
      "  \"caffeSettings\": null,\n",
      "  \"chainerSettings\": null,\n",
      "  \"cluster\": {\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/clusters/yzhang100\",\n",
      "    \"resourceGroup\": \"batchddtftestyzrg\"\n",
      "  },\n",
      "  \"cntkSettings\": null,\n",
      "  \"constraints\": {\n",
      "    \"maxWallClockTime\": \"7 days, 0:00:00\"\n",
      "  },\n",
      "  \"containerSettings\": {\n",
      "    \"imageSourceRegistry\": {\n",
      "      \"credentials\": null,\n",
      "      \"image\": \"yzhang001/distributed-training.horovod-tf\",\n",
      "      \"serverUrl\": null\n",
      "    },\n",
      "    \"shmSize\": null\n",
      "  },\n",
      "  \"creationTime\": \"2018-08-15T14:28:26.038000+00:00\",\n",
      "  \"customMpiSettings\": null,\n",
      "  \"customToolkitSettings\": {\n",
      "    \"commandLine\": \"source /opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin/mpivars.sh;       echo $AZ_BATCH_HOST_LIST;       mpirun -n 8 -ppn 4 -hosts $AZ_BATCH_HOST_LIST       -env I_MPI_FABRICS=dapl       -env I_MPI_DAPL_PROVIDER=ofa-v2-ib0       -env I_MPI_DYNAMIC_CONNECTION=0       -env I_MPI_DEBUG=6       -env I_MPI_HYDRA_DEBUG=on       -env DISTRIBUTED=True              python -u $AZ_BATCHAI_INPUT_SCRIPTS/imagenet_estimator_tf_horovod.py\"\n",
      "  },\n",
      "  \"environmentVariables\": null,\n",
      "  \"executionInfo\": null,\n",
      "  \"executionState\": \"queued\",\n",
      "  \"executionStateTransitionTime\": \"2018-08-15T14:28:26.038000+00:00\",\n",
      "  \"horovodSettings\": null,\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtftestyzrg/providers/Microsoft.BatchAI/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8\",\n",
      "  \"inputDirectories\": [\n",
      "    {\n",
      "      \"id\": \"SCRIPTS\",\n",
      "      \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs/scripts\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"TRAIN\",\n",
      "      \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"TEST\",\n",
      "      \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\"\n",
      "    }\n",
      "  ],\n",
      "  \"jobOutputDirectoryPathSegment\": \"edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db\",\n",
      "  \"jobPreparation\": null,\n",
      "  \"mountVolumes\": null,\n",
      "  \"name\": \"tf-horovod-8\",\n",
      "  \"nodeCount\": 2,\n",
      "  \"outputDirectories\": [\n",
      "    {\n",
      "      \"id\": \"MODEL\",\n",
      "      \"pathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
      "      \"pathSuffix\": \"Models\"\n",
      "    }\n",
      "  ],\n",
      "  \"provisioningState\": \"succeeded\",\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-15T14:28:26.929000+00:00\",\n",
      "  \"pyTorchSettings\": null,\n",
      "  \"resourceGroup\": \"batchddtftestyzrg\",\n",
      "  \"schedulingPriority\": \"normal\",\n",
      "  \"secrets\": null,\n",
      "  \"stdOutErrPathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
      "  \"tensorFlowSettings\": null,\n",
      "  \"toolType\": \"custom\",\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/experiments/jobs\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai job create -n $JOB_NAME --cluster $CLUSTER_NAME -w $WORKSPACE -e $EXPERIMENT -f job.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the command below we can check the status of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          Cluster    Cluster RG         Cluster Workspace    Tool    Nodes    State      Exit code\r\n",
      "------------  ---------  -----------------  -------------------  ------  -------  ---------  -----------\r\n",
      "tf-horovod-8  yzhang100  batchddtftestyzrg  workspace            custom  2        succeeded  0\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai job list -w $WORKSPACE -e $EXPERIMENT -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the files that the job has generated use the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"contentLength\": 13055,\r\n",
      "    \"downloadUrl\": \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/stdouterr/execution-tvm-587366007_1-20180815t142631z.log?sv=2016-05-31&sr=f&sig=cbZqwemJ7j3v88eE8kqyMMp979zWNahCy3vkkvLVi%2Bk%3D&se=2018-08-15T15%3A57%3A34Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-15T14:38:17+00:00\",\r\n",
      "    \"name\": \"execution-tvm-587366007_1-20180815t142631z.log\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"contentLength\": 19287,\r\n",
      "    \"downloadUrl\": \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/stdouterr/execution-tvm-587366007_2-20180815t142631z.log?sv=2016-05-31&sr=f&sig=4yjyCtAiYBSuoY9QhiKxgOK3CiYXP3flmn7Nm4G9DPE%3D&se=2018-08-15T15%3A57%3A34Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-15T14:57:32+00:00\",\r\n",
      "    \"name\": \"execution-tvm-587366007_2-20180815t142631z.log\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"contentLength\": 44647,\r\n",
      "    \"downloadUrl\": \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/stdouterr/stderr.txt?sv=2016-05-31&sr=f&sig=uVM1gsk0RiZ3tYEEDdfnwaFZoEZ66i4psSPZkJCOhHo%3D&se=2018-08-15T15%3A57%3A34Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-15T14:57:21+00:00\",\r\n",
      "    \"name\": \"stderr.txt\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"contentLength\": 49468,\r\n",
      "    \"downloadUrl\": \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/stdouterr/stdout.txt?sv=2016-05-31&sr=f&sig=1ryIpnU%2B0w98GgS4ZJMjAT5c04wpSmraCmz0NMf9XDA%3D&se=2018-08-15T15%3A57%3A34Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-15T14:57:21+00:00\",\r\n",
      "    \"name\": \"stdout.txt\"\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai job file list -w $WORKSPACE -e $EXPERIMENT --j $JOB_NAME --output-directory-id stdouterr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also able to stream the stdout and stderr that our job produces. This is great to check the progress of our job as well as debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFile found with URL \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/stdouterr/stdout.txt?sv=2016-05-31&sr=f&sig=fu9zqjXgUs%2BcVEjO8x96I0QKS5xgdh0g%2Bx9y%2BSRPuAQ%3D&se=2018-08-15T16%3A08%3A27Z&sp=rl\". Start streaming\u001b[0m\n",
      "10.0.0.5,10.0.0.6\n",
      "[0] MPI startup(): Intel(R) MPI Library, Version 2017 Update 3  Build 20170405 (id: 17193)\n",
      "[0] MPI startup(): Copyright (C) 2003-2017 Intel Corporation.  All rights reserved.\n",
      "[0] MPI startup(): Multi-threaded optimized library\n",
      "[0] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[2] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[5] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[3] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[4] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[1] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[6] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[3] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[7] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[3] MPI startup(): dapl data transfer mode\n",
      "[4] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[0] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[4] MPI startup(): dapl data transfer mode\n",
      "[0] MPI startup(): dapl data transfer mode\n",
      "[5] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[2] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[5] MPI startup(): dapl data transfer mode\n",
      "[2] MPI startup(): dapl data transfer mode\n",
      "[7] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[1] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[7] MPI startup(): dapl data transfer mode\n",
      "[6] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[6] MPI startup(): dapl data transfer mode\n",
      "[1] MPI startup(): dapl data transfer mode\n",
      "[0] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[0] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[1] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[1] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[4] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[4] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[2] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[2] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[5] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[5] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[3] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[3] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[6] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[6] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[0] MPI startup(): Device_reset_idx=4\n",
      "[0] MPI startup(): Allgather: 3: 0-0 & 0-8\n",
      "[0] MPI startup(): Allgather: 1: 1-16 & 0-8\n",
      "[0] MPI startup(): Allgather: 5: 17-41 & 0-8\n",
      "[7] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[7] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[0] MPI startup(): Allgather: 1: 42-8192 & 0-8\n",
      "[0] MPI startup(): Allgather: 5: 8193-123115 & 0-8\n",
      "[0] MPI startup(): Allgather: 3: 123116-2303247 & 0-8\n",
      "[0] MPI startup(): Allgather: 5: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Allgather: 2: 0-0 & 9-16\n",
      "[0] MPI startup(): Allgather: 1: 1-256 & 9-16\n",
      "[0] MPI startup(): Allgather: 5: 257-1024 & 9-16\n",
      "[0] MPI startup(): Allgather: 1: 1025-4345 & 9-16\n",
      "[4] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[0] MPI startup(): Allgather: 5: 4346-131072 & 9-16\n",
      "[0] MPI startup(): Allgather: 3: 131073-1058271 & 9-16\n",
      "[0] MPI startup(): Allgather: 5: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Allgather: 1: 0-2 & 17-32\n",
      "[0] MPI startup(): Allgather: 5: 3-11 & 17-32\n",
      "[5] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[0] MPI startup(): Allgather: 1: 12-64 & 17-32\n",
      "[0] MPI startup(): Allgather: 5: 65-48283 & 17-32\n",
      "[0] MPI startup(): Allgather: 3: 48284-740967 & 17-32\n",
      "[0] MPI startup(): Allgather: 5: 0-2147483647 & 17-32\n",
      "[6] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[0] MPI startup(): Allgather: 2: 0-0 & 33-64\n",
      "[0] MPI startup(): Allgather: 1: 1-256 & 33-64\n",
      "[0] MPI startup(): Allgather: 5: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Allgather: 1: 0-256 & 65-128\n",
      "[7] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[0] MPI startup(): Allgather: 5: 257-78452 & 65-128\n",
      "[0] MPI startup(): Allgather: 3: 78453-167908 & 65-128\n",
      "[0] MPI startup(): Allgather: 5: 167909-335315 & 65-128\n",
      "[0] MPI startup(): Allgather: 1: 335316-524288 & 65-128\n",
      "INFO:__main__:4:  Runnin Distributed\n",
      "[0] MPI startup(): Allgather: 5: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Allgather: 3: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Allgather: 1: 1-2 & 129-2147483647\n",
      "[0] MPI startup(): Allgather: 5: 3-4 & 129-2147483647\n",
      "INFO:__main__:4:  Tensorflow version 1.9.0\n",
      "[0] MPI startup(): Allgather: 1: 5-256 & 129-2147483647\n",
      "[0] MPI startup(): Allgather: 5: 257-27716 & 129-2147483647\n",
      "[0] MPI startup(): Allgather: 3: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Allgatherv: 3: 0-0 & 0-8\n",
      "INFO:__main__:6:  Runnin Distributed\n",
      "[0] MPI startup(): Allgatherv: 1: 1-4096 & 0-8\n",
      "[0] MPI startup(): Allgatherv: 3: 4097-8192 & 0-8\n",
      "[0] MPI startup(): Allgatherv: 1: 8193-19391 & 0-8\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 0-8\n",
      "INFO:__main__:4:  Reading training data info\n",
      "[0] MPI startup(): Allgatherv: 1: 0-8192 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 2: 8193-16384 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 1: 0-1 & 17-32\n",
      "INFO:__main__:6:  Tensorflow version 1.9.0\n",
      "[0] MPI startup(): Allgatherv: 2: 2-43 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 1: 44-10031 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 2: 10032-21034 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 17-32\n",
      "INFO:__main__:7:  Runnin Distributed\n",
      "[0] MPI startup(): Allgatherv: 1: 0-8192 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 2: 8193-26640 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 1: 0-128 & 65-128\n",
      "INFO:__main__:6:  Reading training data info\n",
      "[0] MPI startup(): Allgatherv: 2: 129-3017 & 65-128\n",
      "[0] MPI startup(): Allgatherv: 1: 3018-6818 & 65-128\n",
      "[0] MPI startup(): Allgatherv: 2: 6819-8192 & 65-128\n",
      "[0] MPI startup(): Allgatherv: 1: 8193-30133 & 65-128\n",
      "INFO:__main__:7:  Tensorflow version 1.9.0\n",
      "INFO:__main__:7:  Reading training data info\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Allgatherv: 2: 0-1 & 129-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 2-2 & 129-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 3-4 & 129-2147483647\n",
      "INFO:__main__:5:  Runnin Distributed\n",
      "[0] MPI startup(): Allgatherv: 1: 5-64 & 129-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 65-128 & 129-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 129-8125 & 129-2147483647\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 129-2147483647\n",
      "INFO:__main__:5:  Tensorflow version 1.9.0\n",
      "[0] MPI startup(): Allreduce: 4: 0-0 & 0-8\n",
      "[0] MPI startup(): Allreduce: 11: 1-4 & 0-8\n",
      "[0] MPI startup(): Allreduce: 10: 5-8 & 0-8\n",
      "[0] MPI startup(): Allreduce: 11: 9-16 & 0-8\n",
      "INFO:__main__:5:  Reading training data info\n",
      "[0] MPI startup(): Allreduce: 12: 17-37 & 0-8\n",
      "[0] MPI startup(): Allreduce: 10: 38-64 & 0-8\n",
      "[0] MPI startup(): Allreduce: 11: 65-128 & 0-8\n",
      "[0] MPI startup(): Allreduce: 10: 129-512 & 0-8\n",
      "[0] MPI startup(): Allreduce: 12: 513-2048 & 0-8\n",
      "[0] MPI startup(): Allreduce: 11: 2049-4096 & 0-8\n",
      "[0] MPI startup(): Allreduce: 10: 4097-8192 & 0-8\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Allreduce: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 1-6 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 7-11 & 9-16\n",
      "[0] MPI startup(): Allreduce: 10: 12-29 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 30-32 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 33-64 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 65-128 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 129-369 & 9-16\n",
      "[0] MPI startup(): Allreduce: 10: 370-512 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 513-6523 & 9-16\n",
      "[0] MPI startup(): Allreduce: 10: 6524-8192 & 9-16\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Allreduce: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Allreduce: 10: 1-5 & 17-32\n",
      "[0] MPI startup(): Allreduce: 12: 6-43 & 17-32\n",
      "[0] MPI startup(): Allreduce: 11: 44-64 & 17-32\n",
      "[0] MPI startup(): Allreduce: 10: 65-512 & 17-32\n",
      "[0] MPI startup(): Allreduce: 11: 513-7157 & 17-32\n",
      "[0] MPI startup(): Allreduce: 12: 7158-8192 & 17-32\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Allreduce: 1: 0-0 & 33-64\n",
      "[0] MPI startup(): Allreduce: 10: 1-29 & 33-64\n",
      "[0] MPI startup(): Allreduce: 12: 30-36 & 33-64\n",
      "[0] MPI startup(): Allreduce: 10: 37-85 & 33-64\n",
      "[0] MPI startup(): Allreduce: 11: 86-198 & 33-64\n",
      "[0] MPI startup(): Allreduce: 10: 199-4096 & 33-64\n",
      "[0] MPI startup(): Allreduce: 11: 4097-8192 & 33-64\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Allreduce: 1: 0-0 & 65-128\n",
      "[0] MPI startup(): Allreduce: 12: 1-4 & 65-128\n",
      "[0] MPI startup(): Allreduce: 11: 5-29 & 65-128\n",
      "[0] MPI startup(): Allreduce: 12: 30-32 & 65-128\n",
      "[0] MPI startup(): Allreduce: 11: 33-118 & 65-128\n",
      "[0] MPI startup(): Allreduce: 10: 119-170 & 65-128\n",
      "[0] MPI startup(): Allreduce: 12: 171-256 & 65-128\n",
      "[0] MPI startup(): Allreduce: 11: 257-512 & 65-128\n",
      "[0] MPI startup(): Allreduce: 12: 513-2048 & 65-128\n",
      "[0] MPI startup(): Allreduce: 11: 2049-6280 & 65-128\n",
      "[0] MPI startup(): Allreduce: 10: 6281-8192 & 65-128\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Allreduce: 8: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 1-5 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 10: 6-14 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 15-32 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 10: 33-128 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 12: 129-512 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 513-2048 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 12: 2049-4230 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 4231-13217 & 129-2147483647\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Alltoall: 2: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Alltoall: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Alltoall: 2: 1-8 & 9-16\n",
      "[0] MPI startup(): Alltoall: 1: 9-32 & 9-16\n",
      "[0] MPI startup(): Alltoall: 2: 33-262144 & 9-16\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Alltoall: 1: 0-256 & 17-32\n",
      "[0] MPI startup(): Alltoall: 2: 257-131072 & 17-32\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Alltoall: 1: 0-256 & 33-64\n",
      "[0] MPI startup(): Alltoall: 2: 257-65536 & 33-64\n",
      "[0] MPI startup(): Alltoall: 3: 65537-131072 & 33-64\n",
      "[0] MPI startup(): Alltoall: 2: 131073-1048576 & 33-64\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Alltoall: 1: 0-128 & 65-128\n",
      "[0] MPI startup(): Alltoall: 2: 129-131072 & 65-128\n",
      "[0] MPI startup(): Alltoall: 4: 131073-262144 & 65-128\n",
      "[0] MPI startup(): Alltoall: 2: 262145-524288 & 65-128\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Alltoall: 3: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Alltoall: 1: 1-256 & 129-2147483647\n",
      "[0] MPI startup(): Alltoall: 2: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Alltoallv: 1: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Alltoallw: 0: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Barrier: 7: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Barrier: 9: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Barrier: 7: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Barrier: 8: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Barrier: 7: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 3: 0-0 & 0-8\n",
      "[0] MPI startup(): Bcast: 9: 1-64 & 0-8\n",
      "[0] MPI startup(): Bcast: 10: 65-256 & 0-8\n",
      "[0] MPI startup(): Bcast: 9: 257-4096 & 0-8\n",
      "[0] MPI startup(): Bcast: 10: 4097-16384 & 0-8\n",
      "[0] MPI startup(): Bcast: 11: 16385-136906 & 0-8\n",
      "[0] MPI startup(): Bcast: 9: 136907-262144 & 0-8\n",
      "[0] MPI startup(): Bcast: 6: 262145-524288 & 0-8\n",
      "[0] MPI startup(): Bcast: 3: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Bcast: 3: 0-0 & 9-16\n",
      "[0] MPI startup(): Bcast: 10: 1-16384 & 9-16\n",
      "[0] MPI startup(): Bcast: 9: 16385-232630 & 9-16\n",
      "[0] MPI startup(): Bcast: 2: 232631-1048576 & 9-16\n",
      "[0] MPI startup(): Bcast: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Bcast: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Bcast: 10: 1-32768 & 17-32\n",
      "[0] MPI startup(): Bcast: 2: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Bcast: 7: 0-0 & 33-64\n",
      "[0] MPI startup(): Bcast: 8: 1-1 & 33-64\n",
      "[0] MPI startup(): Bcast: 10: 2-2 & 33-64\n",
      "[0] MPI startup(): Bcast: 8: 3-6 & 33-64\n",
      "[0] MPI startup(): Bcast: 10: 7-128 & 33-64\n",
      "[0] MPI startup(): Bcast: 9: 129-256 & 33-64\n",
      "[0] MPI startup(): Bcast: 11: 257-512 & 33-64\n",
      "[0] MPI startup(): Bcast: 10: 513-1024 & 33-64\n",
      "[0] MPI startup(): Bcast: 1: 1025-2048 & 33-64\n",
      "[0] MPI startup(): Bcast: 10: 2049-4096 & 33-64\n",
      "[0] MPI startup(): Bcast: 11: 4097-8192 & 33-64\n",
      "[0] MPI startup(): Bcast: 10: 8193-16384 & 33-64\n",
      "[0] MPI startup(): Bcast: 2: 16385-2842493 & 33-64\n",
      "[0] MPI startup(): Bcast: 6: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Bcast: 7: 0-0 & 65-128\n",
      "[0] MPI startup(): Bcast: 4: 1-1 & 65-128\n",
      "[0] MPI startup(): Bcast: 10: 2-3 & 65-128\n",
      "[0] MPI startup(): Bcast: 8: 4-6 & 65-128\n",
      "[0] MPI startup(): Bcast: 10: 7-32768 & 65-128\n",
      "[0] MPI startup(): Bcast: 9: 32769-251843 & 65-128\n",
      "[0] MPI startup(): Bcast: 11: 251844-427405 & 65-128\n",
      "[0] MPI startup(): Bcast: 6: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Bcast: 1: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 8: 1-16 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 10: 17-32 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 8: 33-64 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 10: 65-512 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 1: 513-1024 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 10: 1025-9906 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 4: 9907-16384 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 2: 16385-1346076 & 129-2147483647\n",
      "[0] MPI startup(): Bcast: 6: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Exscan: 0: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Gather: 3: 0-21 & 0-8\n",
      "[0] MPI startup(): Gather: 1: 22-101 & 0-8\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Gather: 3: 0-8 & 9-16\n",
      "[0] MPI startup(): Gather: 2: 9-512 & 9-16\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Gather: 3: 0-0 & 17-32\n",
      "[0] MPI startup(): Gather: 2: 1-1024 & 17-32\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Gather: 3: 0-0 & 33-64\n",
      "[0] MPI startup(): Gather: 1: 1-4 & 33-64\n",
      "[0] MPI startup(): Gather: 4: 5-12 & 33-64\n",
      "[0] MPI startup(): Gather: 1: 13-22 & 33-64\n",
      "[0] MPI startup(): Gather: 4: 23-51 & 33-64\n",
      "[0] MPI startup(): Gather: 1: 52-256 & 33-64\n",
      "[0] MPI startup(): Gather: 2: 257-1024 & 33-64\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Gather: 1: 0-0 & 65-128\n",
      "[0] MPI startup(): Gather: 4: 1-8 & 65-128\n",
      "[0] MPI startup(): Gather: 1: 9-32 & 65-128\n",
      "[0] MPI startup(): Gather: 4: 33-1118 & 65-128\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Gather: 3: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Gather: 1: 1-512 & 129-2147483647\n",
      "[0] MPI startup(): Gather: 4: 513-1423 & 129-2147483647\n",
      "[0] MPI startup(): Gather: 3: 1424-16384 & 129-2147483647\n",
      "[0] MPI startup(): Gather: 2: 16385-32768 & 129-2147483647\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Gatherv: 1: 0-2147483647 & 0-32\n",
      "[0] MPI startup(): Gatherv: 3: 0-2147483647 & 33-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 4: 0-0 & 0-8\n",
      "[0] MPI startup(): Reduce_scatter: 1: 1-30 & 0-8\n",
      "[0] MPI startup(): Reduce_scatter: 3: 31-262144 & 0-8\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Reduce_scatter: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-4 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 5: 5-16 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 1: 17-50 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 3: 51-105648 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 3: 105649-137527 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-0 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-4 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 1: 5-1152 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 3: 1153-189120 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 3: 0-0 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-4 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 1: 5-1337 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 3: 1338-80624 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 3: 80625-148357 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 3: 148358-335236 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 1: 0-0 & 65-128\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-4 & 65-128\n",
      "[0] MPI startup(): Reduce_scatter: 1: 5-4096 & 65-128\n",
      "[0] MPI startup(): Reduce_scatter: 3: 4097-1383065 & 65-128\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-147 & 129-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 1: 148-19938 & 129-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 3: 19939-1272411 & 129-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 0-8\n",
      "[0] MPI startup(): Reduce: 9: 1-4 & 0-8\n",
      "[0] MPI startup(): Reduce: 10: 5-8 & 0-8\n",
      "[0] MPI startup(): Reduce: 9: 9-256 & 0-8\n",
      "[0] MPI startup(): Reduce: 10: 257-512 & 0-8\n",
      "[0] MPI startup(): Reduce: 9: 513-2048 & 0-8\n",
      "[0] MPI startup(): Reduce: 10: 2049-8192 & 0-8\n",
      "[0] MPI startup(): Reduce: 11: 8193-16384 & 0-8\n",
      "[0] MPI startup(): Reduce: 5: 16385-71836 & 0-8\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Reduce: 8: 1-8 & 9-16\n",
      "[0] MPI startup(): Reduce: 9: 9-32 & 9-16\n",
      "[0] MPI startup(): Reduce: 10: 33-512 & 9-16\n",
      "[0] MPI startup(): Reduce: 8: 513-8192 & 9-16\n",
      "[0] MPI startup(): Reduce: 5: 8193-100753 & 9-16\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Reduce: 10: 1-4 & 17-32\n",
      "[0] MPI startup(): Reduce: 8: 5-8 & 17-32\n",
      "[0] MPI startup(): Reduce: 10: 9-16 & 17-32\n",
      "[0] MPI startup(): Reduce: 9: 17-52 & 17-32\n",
      "[0] MPI startup(): Reduce: 10: 53-65 & 17-32\n",
      "[0] MPI startup(): Reduce: 11: 66-512 & 17-32\n",
      "[0] MPI startup(): Reduce: 8: 513-1024 & 17-32\n",
      "[0] MPI startup(): Reduce: 10: 1025-2048 & 17-32\n",
      "[0] MPI startup(): Reduce: 9: 2049-4096 & 17-32\n",
      "[0] MPI startup(): Reduce: 8: 4097-8192 & 17-32\n",
      "[0] MPI startup(): Reduce: 5: 8193-196408 & 17-32\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Reduce: 7: 0-0 & 33-64\n",
      "[0] MPI startup(): Reduce: 9: 1-13 & 33-64\n",
      "[0] MPI startup(): Reduce: 8: 14-16 & 33-64\n",
      "[0] MPI startup(): Reduce: 10: 17-879 & 33-64\n",
      "[0] MPI startup(): Reduce: 8: 880-2048 & 33-64\n",
      "[0] MPI startup(): Reduce: 10: 2049-4096 & 33-64\n",
      "[0] MPI startup(): Reduce: 8: 4097-8192 & 33-64\n",
      "[0] MPI startup(): Reduce: 5: 8193-403968 & 33-64\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Reduce: 3: 0-0 & 65-128\n",
      "[0] MPI startup(): Reduce: 8: 1-16 & 65-128\n",
      "[0] MPI startup(): Reduce: 10: 17-46 & 65-128\n",
      "[0] MPI startup(): Reduce: 11: 47-64 & 65-128\n",
      "[0] MPI startup(): Reduce: 10: 65-1024 & 65-128\n",
      "[0] MPI startup(): Reduce: 8: 1025-2218 & 65-128\n",
      "[0] MPI startup(): Reduce: 11: 2219-5549 & 65-128\n",
      "[0] MPI startup(): Reduce: 8: 5550-9629 & 65-128\n",
      "[0] MPI startup(): Reduce: 11: 9630-16384 & 65-128\n",
      "[0] MPI startup(): Reduce: 6: 16385-32768 & 65-128\n",
      "[0] MPI startup(): Reduce: 5: 32769-1048576 & 65-128\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 10: 1-7 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 4: 8-8 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 10: 9-1987 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 1988-5916 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 10: 5917-9580 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 9581-16384 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 5: 16385-1048576 & 129-2147483647\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Scan: 0: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Scatter: 2: 0-0 & 0-8\n",
      "[0] MPI startup(): Scatter: 1: 1-64 & 0-8\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Scatter: 2: 0-150 & 9-16\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Scatter: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Scatter: 2: 1-29 & 17-32\n",
      "[0] MPI startup(): Scatter: 1: 30-37 & 17-32\n",
      "[0] MPI startup(): Scatter: 2: 38-138 & 17-32\n",
      "[0] MPI startup(): Scatter: 1: 139-886 & 17-32\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Scatter: 3: 0-0 & 33-64\n",
      "[0] MPI startup(): Scatter: 2: 1-32 & 33-64\n",
      "[0] MPI startup(): Scatter: 1: 33-1595 & 33-64\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Scatter: 3: 0-0 & 65-128\n",
      "[0] MPI startup(): Scatter: 1: 1-17376 & 65-128\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 65-128\n",
      "[0] MPI startup(): Scatter: 1: 0-26387 & 129-2147483647\n",
      "[0] MPI startup(): Scatter: 3: 26388-51099 & 129-2147483647\n",
      "[0] MPI startup(): Scatter: 1: 51100-95214 & 129-2147483647\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 129-2147483647\n",
      "[0] MPI startup(): Scatterv: 1: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Rank    Pid      Node name                               Pin cpu\n",
      "[0] MPI startup(): 0       902      01588dc97fd84b4a97a41b899feede44000000  {0,1,2,3,4,5}\n",
      "[0] MPI startup(): 1       903      01588dc97fd84b4a97a41b899feede44000000  {6,7,8,9,10,11}\n",
      "[0] MPI startup(): 2       904      01588dc97fd84b4a97a41b899feede44000000  {12,13,14,15,16,17}\n",
      "[0] MPI startup(): 3       905      01588dc97fd84b4a97a41b899feede44000000  {18,19,20,21,22,23}\n",
      "[0] MPI startup(): 4       875      01588dc97fd84b4a97a41b899feede44000001  {0,1,2,3,4,5}\n",
      "[0] MPI startup(): 5       876      01588dc97fd84b4a97a41b899feede44000001  {6,7,8,9,10,11}\n",
      "[0] MPI startup(): 6       877      01588dc97fd84b4a97a41b899feede44000001  {12,13,14,15,16,17}\n",
      "[0] MPI startup(): 7       878      01588dc97fd84b4a97a41b899feede44000001  {18,19,20,21,22,23}\n",
      "[0] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[1] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[2] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[3] MPI startup(): Recognition=2 Platform(code=128 ippn=2 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[0] MPI startup(): I_MPI_DAPL_PROVIDER=ofa-v2-ib0\n",
      "[0] MPI startup(): I_MPI_DEBUG=6\n",
      "[0] MPI startup(): I_MPI_DYNAMIC_CONNECTION=0\n",
      "[0] MPI startup(): I_MPI_FABRICS=dapl\n",
      "[0] MPI startup(): I_MPI_INFO_NUMA_NODE_MAP=mlx4_0:-1\n",
      "[0] MPI startup(): I_MPI_INFO_NUMA_NODE_NUM=2\n",
      "[0] MPI startup(): I_MPI_PIN_MAPPING=4:0 0,1 6,2 12,3 18\n",
      "INFO:__main__:1:  Runnin Distributed\n",
      "INFO:__main__:1:  Tensorflow version 1.9.0\n",
      "INFO:__main__:1:  Reading training data info\n",
      "INFO:__main__:2:  Runnin Distributed\n",
      "INFO:__main__:2:  Tensorflow version 1.9.0\n",
      "INFO:__main__:2:  Reading training data info\n",
      "INFO:__main__:3:  Runnin Distributed\n",
      "INFO:__main__:3:  Tensorflow version 1.9.0\n",
      "INFO:__main__:3:  Reading training data info\n",
      "INFO:__main__:0:  Runnin Distributed\n",
      "INFO:__main__:0:  Tensorflow version 1.9.0\n",
      "INFO:__main__:0:  Reading training data info\n",
      "INFO:__main__:2:  Reading validation data info\n",
      "INFO:__main__:3:  Reading validation data info\n",
      "INFO:__main__:1:  Reading validation data info\n",
      "INFO:__main__:5:  Reading validation data info\n",
      "INFO:__main__:0:  Reading validation data info\n",
      "INFO:__main__:7:  Reading validation data info\n",
      "INFO:__main__:4:  Reading validation data info\n",
      "INFO:__main__:6:  Reading validation data info\n",
      "INFO:__main__:5:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "Using config: {'_save_checkpoints_steps': None, '_task_id': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_master': '', '_evaluation_master': '', '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff73fe5d68>, '_global_id_in_cluster': 0, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_service': None, '_train_distribute': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"1\"\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_is_chief': True}\n",
      "INFO:__main__:5:  Rank: 1 Cluster Size 8\n",
      "INFO:__main__:5:  Training...\n",
      "INFO:__main__:4:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "INFO:__main__:3:  Creating estimator with params: {'learning_rate': 0.001, 'classes': 1000}\n",
      "Using config: {'_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd9e9c77d68>, '_device_fn': None, '_num_worker_replicas': 1, '_master': '', '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "}\n",
      ", '_train_distribute': None, '_evaluation_master': '', '_is_chief': True, '_service': None, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_tf_random_seed': None}\n",
      "INFO:__main__:4:  Rank: 0 Cluster Size 8\n",
      "Using config: {'_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2f703a5d68>, '_train_distribute': None, '_device_fn': None, '_task_id': 0, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"3\"\n",
      "}\n",
      ", '_save_summary_steps': 100, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_evaluation_master': '', '_save_checkpoints_steps': None, '_task_type': 'worker', '_is_chief': True, '_service': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5}\n",
      "INFO:__main__:4:  Training...\n",
      "INFO:__main__:3:  Rank: 3 Cluster Size 8\n",
      "INFO:__main__:7:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "INFO:__main__:3:  Training...\n",
      "INFO:__main__:2:  Creating estimator with params: {'learning_rate': 0.001, 'classes': 1000}\n",
      "Using config: {'_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_evaluation_master': '', '_train_distribute': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"3\"\n",
      "}\n",
      ", '_is_chief': True, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_task_type': 'worker', '_task_id': 0, '_save_checkpoints_secs': None, '_num_worker_replicas': 1, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f08ed6e8da0>, '_log_step_count_steps': 100}\n",
      "INFO:__main__:7:  Rank: 3 Cluster Size 8\n",
      "Using config: {'_save_checkpoints_secs': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_device_fn': None, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_master': '', '_save_checkpoints_steps': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"2\"\n",
      "}\n",
      ", '_task_type': 'worker', '_num_worker_replicas': 1, '_train_distribute': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_task_id': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb2534b8e80>, '_global_id_in_cluster': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_summary_steps': 100}\n",
      "INFO:__main__:7:  Training...\n",
      "INFO:__main__:1:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "INFO:__main__:6:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "INFO:__main__:2:  Rank: 2 Cluster Size 8\n",
      "INFO:__main__:2:  Training...\n",
      "Using config: {'_save_checkpoints_secs': None, '_task_id': 0, '_save_summary_steps': 100, '_service': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"2\"\n",
      "}\n",
      ", '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb146924da0>, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_num_ps_replicas': 0, '_train_distribute': None, '_log_step_count_steps': 100, '_global_id_in_cluster': 0, '_num_worker_replicas': 1, '_device_fn': None, '_evaluation_master': '', '_master': ''}\n",
      "INFO:__main__:6:  Rank: 2 Cluster Size 8\n",
      "Using config: {'_evaluation_master': '', '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"1\"\n",
      "}\n",
      ", '_is_chief': True, '_global_id_in_cluster': 0, '_task_id': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa25b2b7d30>, '_device_fn': None, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_task_type': 'worker', '_service': None, '_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_log_step_count_steps': 100, '_save_summary_steps': 100}\n",
      "INFO:__main__:6:  Training...\n",
      "INFO:__main__:1:  Rank: 1 Cluster Size 8\n",
      "INFO:__main__:1:  Training...\n",
      "INFO:__main__:0:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "Using config: {'_save_checkpoints_secs': None, '_service': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_model_dir': '/mnt/batch/tasks/shared/LS_root/mounts/extfs/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/outputs/Models', '_keep_checkpoint_max': 5, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_task_type': 'worker', '_train_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_global_id_in_cluster': 0, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe4b7a28d30>, '_save_checkpoints_steps': None}\n",
      "INFO:__main__:0:  Rank: 0 Cluster Size 8\n",
      "INFO:__main__:0:  Training...\n",
      "Calling model_fn.\n",
      "INFO:__main__:5:  Creating model in train mode\n",
      "Calling model_fn.\n",
      "INFO:__main__:0:  Creating model in train mode\n",
      "Calling model_fn.\n",
      "INFO:__main__:4:  Creating model in train mode\n",
      "Calling model_fn.\n",
      "Calling model_fn.\n",
      "INFO:__main__:3:  Creating model in train mode\n",
      "INFO:__main__:7:  Creating model in train mode\n",
      "Calling model_fn.\n",
      "INFO:__main__:1:  Creating model in train mode\n",
      "Calling model_fn.\n",
      "Calling model_fn.\n",
      "INFO:__main__:6:  Creating model in train mode\n",
      "INFO:__main__:2:  Creating model in train mode\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "Running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "loss = 7.0262647, step = 0\n",
      "loss = 7.023757, step = 0\n",
      "loss = 7.02165, step = 0\n",
      "loss = 7.023191, step = 0\n",
      "loss = 7.0261097, step = 0\n",
      "loss = 7.0293336, step = 0\n",
      "loss = 7.0235987, step = 0\n",
      "loss = 7.0259333, step = 0\n",
      "global_step/sec: 1.6044\n",
      "global_step/sec: 1.6043\n",
      "loss = 1.968276, step = 100 (62.327 sec)\n",
      "loss = 1.7812864, step = 100 (62.333 sec)\n",
      "global_step/sec: 1.60402\n",
      "global_step/sec: 1.60461\n",
      "global_step/sec: 1.60377\n",
      "global_step/sec: 1.60425\n",
      "loss = 1.2768344, step = 100 (62.317 sec)\n",
      "loss = 1.6019878, step = 100 (62.350 sec)\n",
      "loss = 1.8812897, step = 100 (62.363 sec)\n",
      "global_step/sec: 1.60394\n",
      "global_step/sec: 1.60371\n",
      "loss = 1.5130352, step = 100 (62.346 sec)\n",
      "loss = 1.7420961, step = 100 (62.356 sec)\n",
      "loss = 1.1562251, step = 100 (62.370 sec)\n",
      "global_step/sec: 2.47993\n",
      "global_step/sec: 2.48029\n",
      "global_step/sec: 2.47886\n",
      "global_step/sec: 2.479\n",
      "global_step/sec: 2.47895\n",
      "global_step/sec: 2.4799\n",
      "loss = 1.5808711, step = 200 (40.313 sec)\n",
      "loss = 1.8088562, step = 200 (40.318 sec)\n",
      "loss = 1.4978338, step = 200 (40.333 sec)\n",
      "loss = 1.3778839, step = 200 (40.327 sec)\n",
      "global_step/sec: 2.48026\n",
      "loss = 1.4728491, step = 200 (40.320 sec)\n",
      "loss = 1.2838467, step = 200 (40.324 sec)\n",
      "loss = 1.4355891, step = 200 (40.288 sec)\n",
      "global_step/sec: 2.47806\n",
      "loss = 2.0288079, step = 200 (40.795 sec)\n",
      "global_step/sec: 2.96104\n",
      "global_step/sec: 2.9611\n",
      "global_step/sec: 2.96103\n",
      "global_step/sec: 2.96114\n",
      "global_step/sec: 2.96105\n",
      "global_step/sec: 2.96116\n",
      "loss = 3.459573, step = 300 (33.772 sec)\n",
      "loss = 3.33856, step = 300 (33.771 sec)\n",
      "loss = 3.152646, step = 300 (33.772 sec)\n",
      "loss = 3.2958803, step = 300 (33.770 sec)\n",
      "loss = 3.2395964, step = 300 (33.331 sec)\n",
      "loss = 3.429389, step = 300 (33.771 sec)\n",
      "global_step/sec: 2.96082\n",
      "global_step/sec: 2.96108\n",
      "loss = 3.5489187, step = 300 (33.774 sec)\n",
      "loss = 3.6337729, step = 300 (33.771 sec)\n",
      "global_step/sec: 2.84701\n",
      "global_step/sec: 2.84671\n",
      "global_step/sec: 2.84669\n",
      "global_step/sec: 2.84688\n",
      "global_step/sec: 2.84687\n",
      "loss = 2.8767803, step = 400 (35.129 sec)\n",
      "loss = 2.8613267, step = 400 (35.129 sec)\n",
      "loss = 2.8967195, step = 400 (35.125 sec)\n",
      "global_step/sec: 2.84684\n",
      "global_step/sec: 2.84674\n",
      "loss = 2.9951787, step = 400 (35.126 sec)\n",
      "global_step/sec: 2.84653\n",
      "loss = 2.9902096, step = 400 (35.127 sec)\n",
      "loss = 2.830135, step = 400 (35.128 sec)\n",
      "loss = 2.9750733, step = 400 (35.127 sec)\n",
      "loss = 3.0553179, step = 400 (35.131 sec)\n",
      "global_step/sec: 2.75849\n",
      "loss = 5.3336945, step = 500 (36.251 sec)\n",
      "global_step/sec: 2.7586\n",
      "global_step/sec: 2.75857\n",
      "global_step/sec: 2.75845\n",
      "global_step/sec: 2.75843\n",
      "global_step/sec: 2.75841\n",
      "global_step/sec: 2.75842\n",
      "global_step/sec: 2.75838\n",
      "loss = 4.276077, step = 500 (36.250 sec)\n",
      "loss = 4.31872, step = 500 (36.253 sec)\n",
      "loss = 4.856769, step = 500 (36.253 sec)\n",
      "loss = 4.923771, step = 500 (36.252 sec)\n",
      "loss = 5.1662655, step = 500 (36.252 sec)\n",
      "loss = 5.0098653, step = 500 (36.253 sec)\n",
      "loss = 4.724147, step = 500 (36.251 sec)\n",
      "global_step/sec: 2.70091\n",
      "global_step/sec: 2.70078\n",
      "loss = 5.174935, step = 600 (37.024 sec)\n",
      "loss = 4.512304, step = 600 (37.026 sec)\n",
      "global_step/sec: 2.70084\n",
      "global_step/sec: 2.70079\n",
      "global_step/sec: 2.70068\n",
      "global_step/sec: 2.70067\n",
      "loss = 5.281273, step = 600 (37.026 sec)\n",
      "loss = 4.523691, step = 600 (37.028 sec)\n",
      "global_step/sec: 2.7007\n",
      "loss = 5.2982817, step = 600 (37.028 sec)\n",
      "loss = 5.2501807, step = 600 (37.026 sec)\n",
      "loss = 4.844928, step = 600 (37.028 sec)\n",
      "global_step/sec: 2.7008\n",
      "loss = 5.195343, step = 600 (37.530 sec)\n",
      "global_step/sec: 2.62771\n",
      "global_step/sec: 2.62783\n",
      "global_step/sec: 2.6277\n",
      "global_step/sec: 2.62774\n",
      "global_step/sec: 2.62783\n",
      "loss = 4.189908, step = 700 (38.056 sec)\n",
      "global_step/sec: 2.62753\n",
      "global_step/sec: 2.62767\n",
      "loss = 4.0279565, step = 700 (38.056 sec)\n",
      "loss = 4.015774, step = 700 (38.056 sec)\n",
      "loss = 3.938725, step = 700 (38.054 sec)\n",
      "loss = 4.3575225, step = 700 (38.058 sec)\n",
      "global_step/sec: 2.62757\n",
      "loss = 4.366, step = 700 (38.054 sec)\n",
      "loss = 4.046942, step = 700 (38.058 sec)\n",
      "loss = 4.4312687, step = 700 (37.553 sec)\n",
      "global_step/sec: 2.64851\n",
      "global_step/sec: 2.64851\n",
      "global_step/sec: 2.64775\n",
      "global_step/sec: 2.64778\n",
      "loss = 4.096563, step = 800 (37.757 sec)\n",
      "global_step/sec: 2.64771\n",
      "loss = 4.1936445, step = 800 (37.757 sec)\n",
      "loss = 4.1151633, step = 800 (37.768 sec)\n",
      "global_step/sec: 2.64814\n",
      "loss = 3.9743552, step = 800 (37.767 sec)\n",
      "global_step/sec: 2.64813\n",
      "loss = 4.095417, step = 800 (37.768 sec)\n",
      "loss = 4.2552824, step = 800 (37.762 sec)\n",
      "global_step/sec: 2.64751\n",
      "loss = 3.6756606, step = 800 (37.762 sec)\n",
      "loss = 3.9406998, step = 800 (37.771 sec)\n",
      "global_step/sec: 2.53762\n",
      "global_step/sec: 2.53683\n",
      "global_step/sec: 2.53765\n",
      "loss = 4.7627125, step = 900 (39.419 sec)\n",
      "global_step/sec: 2.53785\n",
      "global_step/sec: 2.53683\n",
      "global_step/sec: 2.53761\n",
      "global_step/sec: 2.53706\n",
      "loss = 4.8420095, step = 900 (39.407 sec)\n",
      "loss = 5.0216775, step = 900 (39.407 sec)\n",
      "loss = 4.933311, step = 900 (39.420 sec)\n",
      "global_step/sec: 2.53708\n",
      "loss = 5.087771, step = 900 (39.407 sec)\n",
      "loss = 4.9424405, step = 900 (39.416 sec)\n",
      "loss = 4.8163204, step = 900 (39.404 sec)\n",
      "loss = 4.964511, step = 900 (39.416 sec)\n",
      "global_step/sec: 2.47162\n",
      "global_step/sec: 2.47153\n",
      "global_step/sec: 2.47163\n",
      "loss = 4.6237555, step = 1000 (40.461 sec)\n",
      "loss = 4.7041736, step = 1000 (40.459 sec)\n",
      "global_step/sec: 2.47137\n",
      "loss = 5.057312, step = 1000 (40.459 sec)\n",
      "loss = 4.802891, step = 1000 (40.463 sec)\n",
      "global_step/sec: 2.47145\n",
      "global_step/sec: 2.47127\n",
      "global_step/sec: 2.47146\n",
      "loss = 4.0304174, step = 1000 (40.465 sec)\n",
      "loss = 4.4292808, step = 1000 (40.462 sec)\n",
      "loss = 4.368412, step = 1000 (40.462 sec)\n",
      "global_step/sec: 2.47153\n",
      "loss = 4.3763022, step = 1000 (40.904 sec)\n",
      "global_step/sec: 2.43781\n",
      "global_step/sec: 2.43763\n",
      "global_step/sec: 2.43747\n",
      "global_step/sec: 2.43748\n",
      "loss = 3.7629142, step = 1100 (41.020 sec)\n",
      "loss = 4.3076124, step = 1100 (41.026 sec)\n",
      "loss = 4.4155483, step = 1100 (41.023 sec)\n",
      "loss = 4.7672997, step = 1100 (41.026 sec)\n",
      "global_step/sec: 2.43742\n",
      "global_step/sec: 2.43754\n",
      "loss = 4.743989, step = 1100 (40.584 sec)\n",
      "global_step/sec: 2.43756\n",
      "global_step/sec: 2.43753\n",
      "loss = 4.87465, step = 1100 (41.025 sec)\n",
      "loss = 4.1766796, step = 1100 (41.025 sec)\n",
      "loss = 3.8870168, step = 1100 (41.025 sec)\n",
      "global_step/sec: 2.37396\n",
      "global_step/sec: 2.37391\n",
      "global_step/sec: 2.37395\n",
      "global_step/sec: 2.3738\n",
      "global_step/sec: 2.37369\n",
      "global_step/sec: 2.37369\n",
      "loss = 4.92071, step = 1200 (42.123 sec)\n",
      "global_step/sec: 2.37403\n",
      "global_step/sec: 2.3738\n",
      "loss = 4.038947, step = 1200 (42.124 sec)\n",
      "loss = 4.5683784, step = 1200 (42.126 sec)\n",
      "loss = 4.593329, step = 1200 (42.129 sec)\n",
      "loss = 4.84105, step = 1200 (42.124 sec)\n",
      "loss = 4.556196, step = 1200 (42.123 sec)\n",
      "loss = 4.1505804, step = 1200 (42.126 sec)\n",
      "loss = 4.7723513, step = 1200 (42.129 sec)\n",
      "global_step/sec: 2.27816\n",
      "global_step/sec: 2.27758\n",
      "global_step/sec: 2.27817\n",
      "loss = 4.654607, step = 1300 (43.895 sec)\n",
      "loss = 3.8426337, step = 1300 (43.906 sec)\n",
      "global_step/sec: 2.27753\n",
      "global_step/sec: 2.27786\n",
      "loss = 4.8132586, step = 1300 (43.908 sec)\n",
      "loss = 4.880578, step = 1300 (43.901 sec)\n",
      "global_step/sec: 2.27742\n",
      "global_step/sec: 2.2778\n",
      "loss = 4.9106903, step = 1300 (43.910 sec)\n",
      "loss = 4.2398477, step = 1300 (43.902 sec)\n",
      "global_step/sec: 2.27726\n",
      "loss = 4.614159, step = 1300 (44.379 sec)\n",
      "loss = 4.374689, step = 1300 (43.913 sec)\n",
      "global_step/sec: 2.2492\n",
      "global_step/sec: 2.2493\n",
      "global_step/sec: 2.24913\n",
      "global_step/sec: 2.24933\n",
      "global_step/sec: 2.24883\n",
      "global_step/sec: 2.24883\n",
      "global_step/sec: 2.24945\n",
      "global_step/sec: 2.24963\n",
      "loss = 4.7810335, step = 1400 (44.461 sec)\n",
      "loss = 4.4696164, step = 1400 (44.457 sec)\n",
      "loss = 4.5608654, step = 1400 (44.460 sec)\n",
      "loss = 5.0543804, step = 1400 (44.458 sec)\n",
      "loss = 4.3953314, step = 1400 (43.983 sec)\n",
      "loss = 4.7093344, step = 1400 (44.455 sec)\n",
      "loss = 4.693498, step = 1400 (44.468 sec)\n",
      "loss = 4.5910807, step = 1400 (44.452 sec)\n",
      "global_step/sec: 2.21096\n",
      "global_step/sec: 2.21096\n",
      "global_step/sec: 2.21099\n",
      "global_step/sec: 2.21096\n",
      "global_step/sec: 2.21099\n",
      "global_step/sec: 2.21095\n",
      "global_step/sec: 2.21098\n",
      "global_step/sec: 2.21098\n",
      "loss = 4.922705, step = 1500 (45.229 sec)\n",
      "loss = 4.9539204, step = 1500 (45.229 sec)\n",
      "loss = 4.1477947, step = 1500 (45.229 sec)\n",
      "loss = 4.793047, step = 1500 (45.229 sec)\n",
      "loss = 4.8748493, step = 1500 (45.230 sec)\n",
      "loss = 4.346819, step = 1500 (45.229 sec)\n",
      "loss = 4.994398, step = 1500 (45.230 sec)\n",
      "loss = 4.156906, step = 1500 (45.229 sec)\n",
      "global_step/sec: 2.20741\n",
      "global_step/sec: 2.20711\n",
      "global_step/sec: 2.20739\n",
      "loss = 4.644325, step = 1600 (45.308 sec)\n",
      "loss = 4.107157, step = 1600 (45.303 sec)\n",
      "global_step/sec: 2.20706\n",
      "global_step/sec: 2.20712\n",
      "loss = 4.4447837, step = 1600 (45.309 sec)\n",
      "global_step/sec: 2.20711\n",
      "global_step/sec: 2.20703\n",
      "loss = 4.795426, step = 1600 (45.307 sec)\n",
      "global_step/sec: 2.207\n",
      "loss = 4.447397, step = 1600 (45.308 sec)\n",
      "loss = 4.814273, step = 1600 (45.310 sec)\n",
      "loss = 5.0961595, step = 1600 (45.672 sec)\n",
      "loss = 4.2997055, step = 1600 (45.310 sec)\n",
      "global_step/sec: 2.24692\n",
      "global_step/sec: 2.24701\n",
      "loss = 4.652685, step = 1700 (44.505 sec)\n",
      "global_step/sec: 2.2469\n",
      "global_step/sec: 2.24708\n",
      "global_step/sec: 2.24706\n",
      "global_step/sec: 2.24656\n",
      "loss = 4.4207816, step = 1700 (44.504 sec)\n",
      "global_step/sec: 2.2466\n",
      "loss = 4.4772463, step = 1700 (44.503 sec)\n",
      "loss = 4.6780605, step = 1700 (44.506 sec)\n",
      "loss = 4.506156, step = 1700 (44.502 sec)\n",
      "loss = 3.9944005, step = 1700 (44.142 sec)\n",
      "global_step/sec: 2.24707\n",
      "loss = 4.3670626, step = 1700 (44.512 sec)\n",
      "loss = 5.256071, step = 1700 (44.503 sec)\n",
      "global_step/sec: 2.21439\n",
      "global_step/sec: 2.21435\n",
      "global_step/sec: 2.21437\n",
      "global_step/sec: 2.21434\n",
      "loss = 4.276792, step = 1800 (45.159 sec)\n",
      "loss = 4.584486, step = 1800 (45.160 sec)\n",
      "loss = 4.3048296, step = 1800 (45.160 sec)\n",
      "loss = 4.3025885, step = 1800 (45.160 sec)\n",
      "global_step/sec: 2.21424\n",
      "global_step/sec: 2.21417\n",
      "global_step/sec: 2.21424\n",
      "global_step/sec: 2.21419\n",
      "loss = 4.8548007, step = 1800 (45.162 sec)\n",
      "loss = 4.784687, step = 1800 (45.164 sec)\n",
      "loss = 4.710178, step = 1800 (45.162 sec)\n",
      "loss = 4.8479137, step = 1800 (45.163 sec)\n",
      "global_step/sec: 2.21722\n",
      "global_step/sec: 2.21695\n",
      "global_step/sec: 2.21721\n",
      "global_step/sec: 2.21709\n",
      "global_step/sec: 2.2174\n",
      "global_step/sec: 2.21711\n",
      "global_step/sec: 2.21741\n",
      "global_step/sec: 2.21694\n",
      "loss = 4.8529654, step = 1900 (45.101 sec)\n",
      "loss = 4.7054405, step = 1900 (45.107 sec)\n",
      "loss = 4.145448, step = 1900 (45.102 sec)\n",
      "loss = 4.507749, step = 1900 (45.104 sec)\n",
      "loss = 5.2595825, step = 1900 (45.098 sec)\n",
      "loss = 4.623999, step = 1900 (45.107 sec)\n",
      "loss = 4.830428, step = 1900 (45.098 sec)\n",
      "loss = 5.0210567, step = 1900 (45.568 sec)\n",
      "global_step/sec: 2.2009\n",
      "global_step/sec: 2.20067\n",
      "global_step/sec: 2.20088\n",
      "global_step/sec: 2.20069\n",
      "global_step/sec: 2.20089\n",
      "global_step/sec: 2.20069\n",
      "global_step/sec: 2.2009\n",
      "loss = 4.7918053, step = 2000 (45.436 sec)\n",
      "loss = 4.8228416, step = 2000 (45.436 sec)\n",
      "loss = 5.4671783, step = 2000 (45.440 sec)\n",
      "loss = 4.765086, step = 2000 (45.440 sec)\n",
      "loss = 4.9670134, step = 2000 (45.440 sec)\n",
      "loss = 4.9040823, step = 2000 (44.972 sec)\n",
      "global_step/sec: 2.20069\n",
      "loss = 4.9030805, step = 2000 (45.436 sec)\n",
      "loss = 4.9556856, step = 2000 (45.441 sec)\n",
      "global_step/sec: 2.23237\n",
      "global_step/sec: 2.23234\n",
      "global_step/sec: 2.23232\n",
      "global_step/sec: 2.23231\n",
      "global_step/sec: 2.23233\n",
      "global_step/sec: 2.2323\n",
      "loss = 5.532014, step = 2100 (44.796 sec)\n",
      "loss = 5.261668, step = 2100 (44.797 sec)\n",
      "loss = 4.9596024, step = 2100 (44.796 sec)\n",
      "loss = 5.1827, step = 2100 (44.797 sec)\n",
      "global_step/sec: 2.2323\n",
      "global_step/sec: 2.23228\n",
      "loss = 4.929597, step = 2100 (44.796 sec)\n",
      "loss = 5.079831, step = 2100 (44.797 sec)\n",
      "loss = 4.832711, step = 2100 (44.797 sec)\n",
      "loss = 4.92614, step = 2100 (44.797 sec)\n",
      "global_step/sec: 2.23326\n",
      "global_step/sec: 2.23331\n",
      "global_step/sec: 2.23326\n",
      "global_step/sec: 2.23326\n",
      "global_step/sec: 2.23325\n",
      "loss = 5.230373, step = 2200 (44.778 sec)\n",
      "loss = 4.491722, step = 2200 (44.777 sec)\n",
      "loss = 5.036561, step = 2200 (44.778 sec)\n",
      "loss = 5.0031376, step = 2200 (44.777 sec)\n",
      "global_step/sec: 2.23325\n",
      "loss = 4.96193, step = 2200 (44.778 sec)\n",
      "global_step/sec: 2.23321\n",
      "loss = 4.6167603, step = 2200 (44.778 sec)\n",
      "loss = 4.6888766, step = 2200 (44.778 sec)\n",
      "global_step/sec: 2.23325\n",
      "loss = 4.42426, step = 2200 (45.562 sec)\n",
      "global_step/sec: 2.16387\n",
      "global_step/sec: 2.16387\n",
      "global_step/sec: 2.16372\n",
      "global_step/sec: 2.1638\n",
      "loss = 5.580351, step = 2300 (46.213 sec)\n",
      "global_step/sec: 2.16376\n",
      "global_step/sec: 2.16387\n",
      "global_step/sec: 2.1637\n",
      "loss = 5.454565, step = 2300 (46.213 sec)\n",
      "global_step/sec: 2.16388\n",
      "loss = 5.3873634, step = 2300 (46.215 sec)\n",
      "loss = 4.860387, step = 2300 (46.216 sec)\n",
      "loss = 5.4184146, step = 2300 (46.214 sec)\n",
      "loss = 5.591509, step = 2300 (45.429 sec)\n",
      "loss = 5.318435, step = 2300 (46.217 sec)\n",
      "loss = 5.624173, step = 2300 (46.216 sec)\n",
      "global_step/sec: 2.15767\n",
      "global_step/sec: 2.15782\n",
      "global_step/sec: 2.15767\n",
      "global_step/sec: 2.15777\n",
      "global_step/sec: 2.15768\n",
      "loss = 4.730831, step = 2400 (46.346 sec)\n",
      "global_step/sec: 2.15776\n",
      "loss = 4.2862773, step = 2400 (46.346 sec)\n",
      "loss = 4.6234083, step = 2400 (46.343 sec)\n",
      "loss = 4.6103525, step = 2400 (46.344 sec)\n",
      "global_step/sec: 2.15766\n",
      "loss = 4.0109315, step = 2400 (46.346 sec)\n",
      "loss = 4.4846063, step = 2400 (46.344 sec)\n",
      "global_step/sec: 2.15777\n",
      "loss = 4.2999334, step = 2400 (46.346 sec)\n",
      "loss = 4.5429296, step = 2400 (46.344 sec)\n",
      "global_step/sec: 2.16628\n",
      "global_step/sec: 2.16624\n",
      "global_step/sec: 2.16622\n",
      "global_step/sec: 2.16621\n",
      "global_step/sec: 2.16621\n",
      "loss = 5.4624367, step = 2500 (46.163 sec)\n",
      "loss = 5.1173954, step = 2500 (46.162 sec)\n",
      "global_step/sec: 2.16622\n",
      "loss = 4.909484, step = 2500 (46.163 sec)\n",
      "global_step/sec: 2.1662\n",
      "loss = 4.565445, step = 2500 (46.164 sec)\n",
      "loss = 5.2983255, step = 2500 (46.164 sec)\n",
      "global_step/sec: 2.16626\n",
      "loss = 4.791439, step = 2500 (46.560 sec)\n",
      "loss = 4.9473243, step = 2500 (46.163 sec)\n",
      "loss = 4.8556304, step = 2500 (46.164 sec)\n",
      "Loss for final step: 5.1841965.\n",
      "INFO:__main__:2:  Training took 1129.274 seconds\n",
      "INFO:__main__:2:  Data length:      1281167\n",
      "Loss for final step: 5.168008.\n",
      "INFO:__main__:2:  Total duration:   1129.274\n",
      "INFO:__main__:6:  Training took 1129.264 seconds\n",
      "INFO:__main__:2:  Total images/sec: 1134.505\n",
      "INFO:__main__:6:  Data length:      1281167\n",
      "INFO:__main__:2:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:6:  Total duration:   1129.264\n",
      "INFO:__main__:2:  Distributed:      True\n",
      "INFO:__main__:6:  Total images/sec: 1134.516\n",
      "INFO:__main__:2:  Num GPUs:         8.000\n",
      "INFO:__main__:6:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:2:  Dataset:          Imagenet\n",
      "INFO:__main__:6:  Distributed:      True\n",
      "INFO:__main__:6:  Num GPUs:         8.000\n",
      "Loss for final step: 5.123181.\n",
      "INFO:__main__:6:  Dataset:          Imagenet\n",
      "INFO:__main__:1:  Training took 1129.288 seconds\n",
      "INFO:__main__:1:  Data length:      1281167\n",
      "Loss for final step: 5.1974177.\n",
      "INFO:__main__:1:  Total duration:   1129.288\n",
      "INFO:__main__:4:  Training took 1129.333 seconds\n",
      "INFO:__main__:1:  Total images/sec: 1134.491\n",
      "INFO:__main__:4:  Data length:      1281167\n",
      "INFO:__main__:1:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:4:  Total duration:   1129.333\n",
      "INFO:__main__:1:  Distributed:      True\n",
      "INFO:__main__:4:  Total images/sec: 1134.445\n",
      "INFO:__main__:1:  Num GPUs:         8.000\n",
      "INFO:__main__:4:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:1:  Dataset:          Imagenet\n",
      "INFO:__main__:4:  Distributed:      True\n",
      "INFO:__main__:4:  Num GPUs:         8.000\n",
      "Loss for final step: 5.035472.\n",
      "INFO:__main__:4:  Dataset:          Imagenet\n",
      "INFO:__main__:3:  Training took 1129.336 seconds\n",
      "INFO:__main__:3:  Data length:      1281167\n",
      "Loss for final step: 5.5872955.\n",
      "INFO:__main__:3:  Total duration:   1129.336\n",
      "INFO:__main__:5:  Training took 1129.368 seconds\n",
      "INFO:__main__:3:  Total images/sec: 1134.442\n",
      "INFO:__main__:5:  Data length:      1281167\n",
      "INFO:__main__:3:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:5:  Total duration:   1129.368\n",
      "INFO:__main__:3:  Distributed:      True\n",
      "INFO:__main__:5:  Total images/sec: 1134.410\n",
      "INFO:__main__:3:  Num GPUs:         8.000\n",
      "INFO:__main__:5:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:3:  Dataset:          Imagenet\n",
      "INFO:__main__:5:  Distributed:      True\n",
      "INFO:__main__:5:  Num GPUs:         8.000\n",
      "Loss for final step: 5.0678415.\n",
      "INFO:__main__:5:  Dataset:          Imagenet\n",
      "INFO:__main__:0:  Training took 1129.336 seconds\n",
      "INFO:__main__:0:  Data length:      1281167\n",
      "Loss for final step: 4.8995314.\n",
      "INFO:__main__:0:  Total duration:   1129.336\n",
      "INFO:__main__:7:  Training took 1129.333 seconds\n",
      "INFO:__main__:0:  Total images/sec: 1134.443\n",
      "INFO:__main__:7:  Data length:      1281167\n",
      "INFO:__main__:0:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:7:  Total duration:   1129.333\n",
      "INFO:__main__:0:  Distributed:      True\n",
      "INFO:__main__:7:  Total images/sec: 1134.446\n",
      "INFO:__main__:0:  Num GPUs:         8.000\n",
      "INFO:__main__:7:  Batch size:       (Per GPU 64: Total 512)\n",
      "INFO:__main__:0:  Dataset:          Imagenet\n",
      "INFO:__main__:7:  Distributed:      True\n",
      "INFO:__main__:7:  Num GPUs:         8.000\n",
      "INFO:__main__:7:  Dataset:          Imagenet\n"
     ]
    }
   ],
   "source": [
    "!az batchai job file stream -w $WORKSPACE -e $EXPERIMENT --j $JOB_NAME --output-directory-id stdouterr -f stdout.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFile found with URL \"https://batchddtftestyzst.file.core.windows.net/batchddtftestyzshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/stdouterr/stderr.txt?sv=2016-05-31&sr=f&sig=IsGAoIbia9KRCzHSlXr1Pof918B1%2BfiQVZna1ikvwD4%3D&se=2018-08-15T16%3A08%3A41Z&sp=rl\". Start streaming\u001b[0m\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_task_id': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_master': '', '_evaluation_master': '', '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff73fe5d68>, '_global_id_in_cluster': 0, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_service': None, '_train_distribute': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"1\"\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_is_chief': True}\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd9e9c77d68>, '_device_fn': None, '_num_worker_replicas': 1, '_master': '', '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "}\n",
      ", '_train_distribute': None, '_evaluation_master': '', '_is_chief': True, '_service': None, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_tf_random_seed': None}\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2f703a5d68>, '_train_distribute': None, '_device_fn': None, '_task_id': 0, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"3\"\n",
      "}\n",
      ", '_save_summary_steps': 100, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_evaluation_master': '', '_save_checkpoints_steps': None, '_task_type': 'worker', '_is_chief': True, '_service': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5}\n",
      "INFO:tensorflow:Using config: {'_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_evaluation_master': '', '_train_distribute': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"3\"\n",
      "}\n",
      ", '_is_chief': True, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_task_type': 'worker', '_task_id': 0, '_save_checkpoints_secs': None, '_num_worker_replicas': 1, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f08ed6e8da0>, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_device_fn': None, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_master': '', '_save_checkpoints_steps': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"2\"\n",
      "}\n",
      ", '_task_type': 'worker', '_num_worker_replicas': 1, '_train_distribute': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_task_id': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb2534b8e80>, '_global_id_in_cluster': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_task_id': 0, '_save_summary_steps': 100, '_service': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"2\"\n",
      "}\n",
      ", '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb146924da0>, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_num_ps_replicas': 0, '_train_distribute': None, '_log_step_count_steps': 100, '_global_id_in_cluster': 0, '_num_worker_replicas': 1, '_device_fn': None, '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"1\"\n",
      "}\n",
      ", '_is_chief': True, '_global_id_in_cluster': 0, '_task_id': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa25b2b7d30>, '_device_fn': None, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_task_type': 'worker', '_service': None, '_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_log_step_count_steps': 100, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_service': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_model_dir': '/mnt/batch/tasks/shared/LS_root/mounts/extfs/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtftestyzrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2837b74b-1269-424d-a17f-58918a8f70db/outputs/Models', '_keep_checkpoint_max': 5, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_task_type': 'worker', '_train_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_global_id_in_cluster': 0, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe4b7a28d30>, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:43.597711: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:43.665537: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-08-15 14:38:43.667622: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:43.797917: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:43.835632: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:43.927725: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:43.932531: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-08-15 14:38:44.179602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: ca4e:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.35GiB\n",
      "2018-08-15 14:38:44.179656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 1\n",
      "2018-08-15 14:38:44.216742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: a6f7:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.34GiB\n",
      "2018-08-15 14:38:44.216796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 1\n",
      "2018-08-15 14:38:44.583897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: bc51:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.33GiB\n",
      "2018-08-15 14:38:44.583952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n",
      "2018-08-15 14:38:44.658163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:44.658245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      1 \n",
      "2018-08-15 14:38:44.658260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N \n",
      "2018-08-15 14:38:44.658680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14849 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-16GB, pci bus id: a6f7:00:00.0, compute capability: 7.0)\n",
      "2018-08-15 14:38:44.693211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:44.693297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      1 \n",
      "2018-08-15 14:38:44.693312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N \n",
      "2018-08-15 14:38:44.694438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-16GB, pci bus id: ca4e:00:00.0, compute capability: 7.0)\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-15 14:38:44.716746: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-08-15 14:38:44.831281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: d2e2:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.34GiB\n",
      "2018-08-15 14:38:44.831352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 3\n",
      "2018-08-15 14:38:44.849178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: bebe:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.34GiB\n",
      "2018-08-15 14:38:44.849221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 2\n",
      "2018-08-15 14:38:45.073409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: f7dd:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.33GiB\n",
      "2018-08-15 14:38:45.073465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 3\n",
      "2018-08-15 14:38:45.073536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: df0e:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.33GiB\n",
      "2018-08-15 14:38:45.073585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 2\n",
      "2018-08-15 14:38:45.085234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:45.085310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n",
      "2018-08-15 14:38:45.085323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n",
      "2018-08-15 14:38:45.085667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: bc51:00:00.0, compute capability: 7.0)\n",
      "2018-08-15 14:38:45.273105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 98b1:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.33GiB\n",
      "2018-08-15 14:38:45.273161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n",
      "2018-08-15 14:38:45.281128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:45.281211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      3 \n",
      "2018-08-15 14:38:45.281225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   N \n",
      "2018-08-15 14:38:45.325862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:45.325948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      2 \n",
      "2018-08-15 14:38:45.325961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   N \n",
      "2018-08-15 14:38:45.281884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 3, name: Tesla V100-PCIE-16GB, pci bus id: d2e2:00:00.0, compute capability: 7.0)\n",
      "2018-08-15 14:38:45.326254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 2, name: Tesla V100-PCIE-16GB, pci bus id: df0e:00:00.0, compute capability: 7.0)\n",
      "2018-08-15 14:38:45.299194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:45.299271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      2 \n",
      "2018-08-15 14:38:45.299285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   N \n",
      "2018-08-15 14:38:45.342495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:45.342573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      3 \n",
      "2018-08-15 14:38:45.342585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   N \n",
      "2018-08-15 14:38:45.299579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 2, name: Tesla V100-PCIE-16GB, pci bus id: bebe:00:00.0, compute capability: 7.0)\n",
      "2018-08-15 14:38:45.342870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 3, name: Tesla V100-PCIE-16GB, pci bus id: f7dd:00:00.0, compute capability: 7.0)\n",
      "2018-08-15 14:38:45.525975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-15 14:38:45.526060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n",
      "2018-08-15 14:38:45.526074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n",
      "2018-08-15 14:38:45.526370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14841 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 98b1:00:00.0, compute capability: 7.0)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:loss = 7.0262647, step = 0\n",
      "INFO:tensorflow:loss = 7.023757, step = 0\n",
      "INFO:tensorflow:loss = 7.02165, step = 0\n",
      "INFO:tensorflow:loss = 7.023191, step = 0\n",
      "INFO:tensorflow:loss = 7.0261097, step = 0\n",
      "INFO:tensorflow:loss = 7.0293336, step = 0\n",
      "INFO:tensorflow:loss = 7.0235987, step = 0\n",
      "INFO:tensorflow:loss = 7.0259333, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.6044\n",
      "INFO:tensorflow:global_step/sec: 1.6043\n",
      "INFO:tensorflow:loss = 1.968276, step = 100 (62.327 sec)\n",
      "INFO:tensorflow:loss = 1.7812864, step = 100 (62.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.60402\n",
      "INFO:tensorflow:global_step/sec: 1.60377\n",
      "INFO:tensorflow:global_step/sec: 1.60461\n",
      "INFO:tensorflow:global_step/sec: 1.60425\n",
      "INFO:tensorflow:loss = 1.2768344, step = 100 (62.317 sec)\n",
      "INFO:tensorflow:loss = 1.6019878, step = 100 (62.350 sec)\n",
      "INFO:tensorflow:loss = 1.8812897, step = 100 (62.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.60394\n",
      "INFO:tensorflow:global_step/sec: 1.60371\n",
      "INFO:tensorflow:loss = 1.5130352, step = 100 (62.346 sec)\n",
      "INFO:tensorflow:loss = 1.7420961, step = 100 (62.356 sec)\n",
      "INFO:tensorflow:loss = 1.1562251, step = 100 (62.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.47895\n",
      "INFO:tensorflow:global_step/sec: 2.47993\n",
      "INFO:tensorflow:global_step/sec: 2.479\n",
      "INFO:tensorflow:global_step/sec: 2.47886\n",
      "INFO:tensorflow:global_step/sec: 2.48029\n",
      "INFO:tensorflow:global_step/sec: 2.4799\n",
      "INFO:tensorflow:global_step/sec: 2.48026\n",
      "INFO:tensorflow:global_step/sec: 2.47806\n",
      "INFO:tensorflow:loss = 1.5808711, step = 200 (40.313 sec)\n",
      "INFO:tensorflow:loss = 1.3778839, step = 200 (40.327 sec)\n",
      "INFO:tensorflow:loss = 1.8088562, step = 200 (40.318 sec)\n",
      "INFO:tensorflow:loss = 1.4978338, step = 200 (40.333 sec)\n",
      "INFO:tensorflow:loss = 1.4728491, step = 200 (40.320 sec)\n",
      "INFO:tensorflow:loss = 1.2838467, step = 200 (40.324 sec)\n",
      "INFO:tensorflow:loss = 1.4355891, step = 200 (40.288 sec)\n",
      "INFO:tensorflow:loss = 2.0288079, step = 200 (40.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96104\n",
      "INFO:tensorflow:global_step/sec: 2.96114\n",
      "INFO:tensorflow:global_step/sec: 2.96103\n",
      "INFO:tensorflow:global_step/sec: 2.9611\n",
      "INFO:tensorflow:global_step/sec: 2.96105\n",
      "INFO:tensorflow:loss = 3.459573, step = 300 (33.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96116\n",
      "INFO:tensorflow:loss = 3.33856, step = 300 (33.771 sec)\n",
      "INFO:tensorflow:loss = 3.152646, step = 300 (33.772 sec)\n",
      "INFO:tensorflow:loss = 3.2958803, step = 300 (33.770 sec)\n",
      "INFO:tensorflow:loss = 3.2395964, step = 300 (33.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96082\n",
      "INFO:tensorflow:loss = 3.429389, step = 300 (33.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96108\n",
      "INFO:tensorflow:loss = 3.5489187, step = 300 (33.774 sec)\n",
      "INFO:tensorflow:loss = 3.6337729, step = 300 (33.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84701\n",
      "INFO:tensorflow:global_step/sec: 2.84671\n",
      "INFO:tensorflow:global_step/sec: 2.84688\n",
      "INFO:tensorflow:global_step/sec: 2.84669\n",
      "INFO:tensorflow:global_step/sec: 2.84687\n",
      "INFO:tensorflow:loss = 2.8767803, step = 400 (35.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84684\n",
      "INFO:tensorflow:loss = 2.8613267, step = 400 (35.129 sec)\n",
      "INFO:tensorflow:loss = 2.8967195, step = 400 (35.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84674\n",
      "INFO:tensorflow:loss = 2.9951787, step = 400 (35.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84653\n",
      "INFO:tensorflow:loss = 2.9902096, step = 400 (35.127 sec)\n",
      "INFO:tensorflow:loss = 2.830135, step = 400 (35.128 sec)\n",
      "INFO:tensorflow:loss = 2.9750733, step = 400 (35.127 sec)\n",
      "INFO:tensorflow:loss = 3.0553179, step = 400 (35.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75849\n",
      "INFO:tensorflow:global_step/sec: 2.7586\n",
      "INFO:tensorflow:global_step/sec: 2.75845\n",
      "INFO:tensorflow:loss = 5.3336945, step = 500 (36.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75857\n",
      "INFO:tensorflow:global_step/sec: 2.75841\n",
      "INFO:tensorflow:global_step/sec: 2.75843\n",
      "INFO:tensorflow:global_step/sec: 2.75842\n",
      "INFO:tensorflow:global_step/sec: 2.75838\n",
      "INFO:tensorflow:loss = 4.276077, step = 500 (36.250 sec)\n",
      "INFO:tensorflow:loss = 4.923771, step = 500 (36.252 sec)\n",
      "INFO:tensorflow:loss = 4.724147, step = 500 (36.251 sec)\n",
      "INFO:tensorflow:loss = 4.31872, step = 500 (36.253 sec)\n",
      "INFO:tensorflow:loss = 4.856769, step = 500 (36.253 sec)\n",
      "INFO:tensorflow:loss = 5.1662655, step = 500 (36.252 sec)\n",
      "INFO:tensorflow:loss = 5.0098653, step = 500 (36.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70091\n",
      "INFO:tensorflow:global_step/sec: 2.7008\n",
      "INFO:tensorflow:global_step/sec: 2.70078\n",
      "INFO:tensorflow:loss = 5.174935, step = 600 (37.024 sec)\n",
      "INFO:tensorflow:loss = 4.512304, step = 600 (37.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70084\n",
      "INFO:tensorflow:global_step/sec: 2.70068\n",
      "INFO:tensorflow:global_step/sec: 2.70079\n",
      "INFO:tensorflow:global_step/sec: 2.70067\n",
      "INFO:tensorflow:loss = 5.281273, step = 600 (37.026 sec)\n",
      "INFO:tensorflow:loss = 4.523691, step = 600 (37.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7007\n",
      "INFO:tensorflow:loss = 5.2982817, step = 600 (37.028 sec)\n",
      "INFO:tensorflow:loss = 5.2501807, step = 600 (37.026 sec)\n",
      "INFO:tensorflow:loss = 4.844928, step = 600 (37.028 sec)\n",
      "INFO:tensorflow:loss = 5.195343, step = 600 (37.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.62771\n",
      "INFO:tensorflow:global_step/sec: 2.62783\n",
      "INFO:tensorflow:global_step/sec: 2.62774\n",
      "INFO:tensorflow:global_step/sec: 2.6277\n",
      "INFO:tensorflow:global_step/sec: 2.62783\n",
      "INFO:tensorflow:global_step/sec: 2.62753\n",
      "INFO:tensorflow:loss = 4.189908, step = 700 (38.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.62767\n",
      "INFO:tensorflow:loss = 4.0279565, step = 700 (38.056 sec)\n",
      "INFO:tensorflow:loss = 3.938725, step = 700 (38.054 sec)\n",
      "INFO:tensorflow:loss = 4.015774, step = 700 (38.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.62757\n",
      "INFO:tensorflow:loss = 4.3575225, step = 700 (38.058 sec)\n",
      "INFO:tensorflow:loss = 4.366, step = 700 (38.054 sec)\n",
      "INFO:tensorflow:loss = 4.046942, step = 700 (38.058 sec)\n",
      "INFO:tensorflow:loss = 4.4312687, step = 700 (37.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64851\n",
      "INFO:tensorflow:global_step/sec: 2.64775\n",
      "INFO:tensorflow:global_step/sec: 2.64851\n",
      "INFO:tensorflow:global_step/sec: 2.64778\n",
      "INFO:tensorflow:loss = 4.096563, step = 800 (37.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64771\n",
      "INFO:tensorflow:loss = 4.1936445, step = 800 (37.757 sec)\n",
      "INFO:tensorflow:loss = 4.1151633, step = 800 (37.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64814\n",
      "INFO:tensorflow:loss = 3.9743552, step = 800 (37.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64813\n",
      "INFO:tensorflow:loss = 4.2552824, step = 800 (37.762 sec)\n",
      "INFO:tensorflow:loss = 4.095417, step = 800 (37.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64751\n",
      "INFO:tensorflow:loss = 3.6756606, step = 800 (37.762 sec)\n",
      "INFO:tensorflow:loss = 3.9406998, step = 800 (37.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.53762\n",
      "INFO:tensorflow:global_step/sec: 2.53683\n",
      "INFO:tensorflow:global_step/sec: 2.53765\n",
      "INFO:tensorflow:global_step/sec: 2.53785\n",
      "INFO:tensorflow:global_step/sec: 2.53683\n",
      "INFO:tensorflow:loss = 4.7627125, step = 900 (39.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.53761\n",
      "INFO:tensorflow:global_step/sec: 2.53706\n",
      "INFO:tensorflow:loss = 4.8420095, step = 900 (39.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.53708\n",
      "INFO:tensorflow:loss = 5.0216775, step = 900 (39.407 sec)\n",
      "INFO:tensorflow:loss = 4.933311, step = 900 (39.420 sec)\n",
      "INFO:tensorflow:loss = 5.087771, step = 900 (39.407 sec)\n",
      "INFO:tensorflow:loss = 4.9424405, step = 900 (39.416 sec)\n",
      "INFO:tensorflow:loss = 4.8163204, step = 900 (39.404 sec)\n",
      "INFO:tensorflow:loss = 4.964511, step = 900 (39.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.47162\n",
      "INFO:tensorflow:global_step/sec: 2.47153\n",
      "INFO:tensorflow:global_step/sec: 2.47153\n",
      "INFO:tensorflow:global_step/sec: 2.47163\n",
      "INFO:tensorflow:loss = 4.6237555, step = 1000 (40.461 sec)\n",
      "INFO:tensorflow:loss = 4.7041736, step = 1000 (40.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.47137\n",
      "INFO:tensorflow:loss = 5.057312, step = 1000 (40.459 sec)\n",
      "INFO:tensorflow:loss = 4.802891, step = 1000 (40.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.47145\n",
      "INFO:tensorflow:global_step/sec: 2.47127\n",
      "INFO:tensorflow:global_step/sec: 2.47146\n",
      "INFO:tensorflow:loss = 4.0304174, step = 1000 (40.465 sec)\n",
      "INFO:tensorflow:loss = 4.4292808, step = 1000 (40.462 sec)\n",
      "INFO:tensorflow:loss = 4.368412, step = 1000 (40.462 sec)\n",
      "INFO:tensorflow:loss = 4.3763022, step = 1000 (40.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.43781\n",
      "INFO:tensorflow:global_step/sec: 2.43763\n",
      "INFO:tensorflow:global_step/sec: 2.43747\n",
      "INFO:tensorflow:global_step/sec: 2.43748\n",
      "INFO:tensorflow:loss = 3.7629142, step = 1100 (41.020 sec)\n",
      "INFO:tensorflow:loss = 4.4155483, step = 1100 (41.023 sec)\n",
      "INFO:tensorflow:loss = 4.3076124, step = 1100 (41.026 sec)\n",
      "INFO:tensorflow:loss = 4.7672997, step = 1100 (41.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.43742\n",
      "INFO:tensorflow:global_step/sec: 2.43756\n",
      "INFO:tensorflow:loss = 4.743989, step = 1100 (40.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.43754\n",
      "INFO:tensorflow:global_step/sec: 2.43753\n",
      "INFO:tensorflow:loss = 4.87465, step = 1100 (41.025 sec)\n",
      "INFO:tensorflow:loss = 4.1766796, step = 1100 (41.025 sec)\n",
      "INFO:tensorflow:loss = 3.8870168, step = 1100 (41.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.37396\n",
      "INFO:tensorflow:global_step/sec: 2.37391\n",
      "INFO:tensorflow:global_step/sec: 2.37395\n",
      "INFO:tensorflow:global_step/sec: 2.37369\n",
      "INFO:tensorflow:global_step/sec: 2.3738\n",
      "INFO:tensorflow:global_step/sec: 2.37403\n",
      "INFO:tensorflow:global_step/sec: 2.37369\n",
      "INFO:tensorflow:loss = 4.92071, step = 1200 (42.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.3738\n",
      "INFO:tensorflow:loss = 4.038947, step = 1200 (42.124 sec)\n",
      "INFO:tensorflow:loss = 4.84105, step = 1200 (42.124 sec)\n",
      "INFO:tensorflow:loss = 4.593329, step = 1200 (42.129 sec)\n",
      "INFO:tensorflow:loss = 4.5683784, step = 1200 (42.126 sec)\n",
      "INFO:tensorflow:loss = 4.556196, step = 1200 (42.123 sec)\n",
      "INFO:tensorflow:loss = 4.7723513, step = 1200 (42.129 sec)\n",
      "INFO:tensorflow:loss = 4.1505804, step = 1200 (42.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.27816\n",
      "INFO:tensorflow:global_step/sec: 2.27758\n",
      "INFO:tensorflow:global_step/sec: 2.27817\n",
      "INFO:tensorflow:loss = 3.8426337, step = 1300 (43.906 sec)\n",
      "INFO:tensorflow:loss = 4.654607, step = 1300 (43.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.27753\n",
      "INFO:tensorflow:global_step/sec: 2.27786\n",
      "INFO:tensorflow:loss = 4.8132586, step = 1300 (43.908 sec)\n",
      "INFO:tensorflow:loss = 4.880578, step = 1300 (43.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.27742\n",
      "INFO:tensorflow:global_step/sec: 2.2778\n",
      "INFO:tensorflow:loss = 4.9106903, step = 1300 (43.910 sec)\n",
      "INFO:tensorflow:loss = 4.2398477, step = 1300 (43.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.27726\n",
      "INFO:tensorflow:loss = 4.614159, step = 1300 (44.379 sec)\n",
      "INFO:tensorflow:loss = 4.374689, step = 1300 (43.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.2492\n",
      "INFO:tensorflow:global_step/sec: 2.24933\n",
      "INFO:tensorflow:global_step/sec: 2.24913\n",
      "INFO:tensorflow:global_step/sec: 2.2493\n",
      "INFO:tensorflow:global_step/sec: 2.24883\n",
      "INFO:tensorflow:global_step/sec: 2.24945\n",
      "INFO:tensorflow:global_step/sec: 2.24883\n",
      "INFO:tensorflow:global_step/sec: 2.24963\n",
      "INFO:tensorflow:loss = 4.5608654, step = 1400 (44.460 sec)\n",
      "INFO:tensorflow:loss = 4.7810335, step = 1400 (44.461 sec)\n",
      "INFO:tensorflow:loss = 4.4696164, step = 1400 (44.457 sec)\n",
      "INFO:tensorflow:loss = 4.3953314, step = 1400 (43.983 sec)\n",
      "INFO:tensorflow:loss = 5.0543804, step = 1400 (44.458 sec)\n",
      "INFO:tensorflow:loss = 4.7093344, step = 1400 (44.455 sec)\n",
      "INFO:tensorflow:loss = 4.693498, step = 1400 (44.468 sec)\n",
      "INFO:tensorflow:loss = 4.5910807, step = 1400 (44.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.21096\n",
      "INFO:tensorflow:global_step/sec: 2.21096\n",
      "INFO:tensorflow:global_step/sec: 2.21099\n",
      "INFO:tensorflow:global_step/sec: 2.21098\n",
      "INFO:tensorflow:global_step/sec: 2.21098\n",
      "INFO:tensorflow:global_step/sec: 2.21096\n",
      "INFO:tensorflow:global_step/sec: 2.21099\n",
      "INFO:tensorflow:global_step/sec: 2.21095\n",
      "INFO:tensorflow:loss = 4.922705, step = 1500 (45.229 sec)\n",
      "INFO:tensorflow:loss = 4.1477947, step = 1500 (45.229 sec)\n",
      "INFO:tensorflow:loss = 4.9539204, step = 1500 (45.229 sec)\n",
      "INFO:tensorflow:loss = 4.793047, step = 1500 (45.229 sec)\n",
      "INFO:tensorflow:loss = 4.8748493, step = 1500 (45.230 sec)\n",
      "INFO:tensorflow:loss = 4.346819, step = 1500 (45.229 sec)\n",
      "INFO:tensorflow:loss = 4.994398, step = 1500 (45.230 sec)\n",
      "INFO:tensorflow:loss = 4.156906, step = 1500 (45.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20741\n",
      "INFO:tensorflow:global_step/sec: 2.20711\n",
      "INFO:tensorflow:global_step/sec: 2.20739\n",
      "INFO:tensorflow:loss = 4.644325, step = 1600 (45.308 sec)\n",
      "INFO:tensorflow:loss = 4.107157, step = 1600 (45.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20706\n",
      "INFO:tensorflow:global_step/sec: 2.20712\n",
      "INFO:tensorflow:global_step/sec: 2.20711\n",
      "INFO:tensorflow:loss = 4.4447837, step = 1600 (45.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20703\n",
      "INFO:tensorflow:loss = 4.447397, step = 1600 (45.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.207\n",
      "INFO:tensorflow:loss = 4.795426, step = 1600 (45.307 sec)\n",
      "INFO:tensorflow:loss = 4.814273, step = 1600 (45.310 sec)\n",
      "INFO:tensorflow:loss = 5.0961595, step = 1600 (45.672 sec)\n",
      "INFO:tensorflow:loss = 4.2997055, step = 1600 (45.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.24692\n",
      "INFO:tensorflow:global_step/sec: 2.24701\n",
      "INFO:tensorflow:loss = 4.652685, step = 1700 (44.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.24708\n",
      "INFO:tensorflow:global_step/sec: 2.2469\n",
      "INFO:tensorflow:global_step/sec: 2.24706\n",
      "INFO:tensorflow:global_step/sec: 2.2466\n",
      "INFO:tensorflow:global_step/sec: 2.24656\n",
      "INFO:tensorflow:loss = 4.4207816, step = 1700 (44.504 sec)\n",
      "INFO:tensorflow:loss = 4.506156, step = 1700 (44.502 sec)\n",
      "INFO:tensorflow:loss = 3.9944005, step = 1700 (44.142 sec)\n",
      "INFO:tensorflow:loss = 4.4772463, step = 1700 (44.503 sec)\n",
      "INFO:tensorflow:loss = 4.6780605, step = 1700 (44.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.24707\n",
      "INFO:tensorflow:loss = 4.3670626, step = 1700 (44.512 sec)\n",
      "INFO:tensorflow:loss = 5.256071, step = 1700 (44.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.21439\n",
      "INFO:tensorflow:global_step/sec: 2.21437\n",
      "INFO:tensorflow:global_step/sec: 2.21435\n",
      "INFO:tensorflow:global_step/sec: 2.21434\n",
      "INFO:tensorflow:loss = 4.276792, step = 1800 (45.159 sec)\n",
      "INFO:tensorflow:loss = 4.3048296, step = 1800 (45.160 sec)\n",
      "INFO:tensorflow:loss = 4.584486, step = 1800 (45.160 sec)\n",
      "INFO:tensorflow:loss = 4.3025885, step = 1800 (45.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.21424\n",
      "INFO:tensorflow:global_step/sec: 2.21417\n",
      "INFO:tensorflow:global_step/sec: 2.21424\n",
      "INFO:tensorflow:global_step/sec: 2.21419\n",
      "INFO:tensorflow:loss = 4.8548007, step = 1800 (45.162 sec)\n",
      "INFO:tensorflow:loss = 4.784687, step = 1800 (45.164 sec)\n",
      "INFO:tensorflow:loss = 4.710178, step = 1800 (45.162 sec)\n",
      "INFO:tensorflow:loss = 4.8479137, step = 1800 (45.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.21722\n",
      "INFO:tensorflow:global_step/sec: 2.21695\n",
      "INFO:tensorflow:global_step/sec: 2.21721\n",
      "INFO:tensorflow:global_step/sec: 2.21694\n",
      "INFO:tensorflow:global_step/sec: 2.21709\n",
      "INFO:tensorflow:global_step/sec: 2.21741\n",
      "INFO:tensorflow:global_step/sec: 2.21711\n",
      "INFO:tensorflow:global_step/sec: 2.2174\n",
      "INFO:tensorflow:loss = 4.8529654, step = 1900 (45.101 sec)\n",
      "INFO:tensorflow:loss = 4.7054405, step = 1900 (45.107 sec)\n",
      "INFO:tensorflow:loss = 4.507749, step = 1900 (45.104 sec)\n",
      "INFO:tensorflow:loss = 4.145448, step = 1900 (45.102 sec)\n",
      "INFO:tensorflow:loss = 5.2595825, step = 1900 (45.098 sec)\n",
      "INFO:tensorflow:loss = 4.623999, step = 1900 (45.107 sec)\n",
      "INFO:tensorflow:loss = 4.830428, step = 1900 (45.098 sec)\n",
      "INFO:tensorflow:loss = 5.0210567, step = 1900 (45.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20088\n",
      "INFO:tensorflow:global_step/sec: 2.2009\n",
      "INFO:tensorflow:global_step/sec: 2.20069\n",
      "INFO:tensorflow:global_step/sec: 2.20069\n",
      "INFO:tensorflow:global_step/sec: 2.20089\n",
      "INFO:tensorflow:global_step/sec: 2.20067\n",
      "INFO:tensorflow:global_step/sec: 2.2009\n",
      "INFO:tensorflow:global_step/sec: 2.20069\n",
      "INFO:tensorflow:loss = 4.7918053, step = 2000 (45.436 sec)\n",
      "INFO:tensorflow:loss = 5.4671783, step = 2000 (45.440 sec)\n",
      "INFO:tensorflow:loss = 4.765086, step = 2000 (45.440 sec)\n",
      "INFO:tensorflow:loss = 4.8228416, step = 2000 (45.436 sec)\n",
      "INFO:tensorflow:loss = 4.9670134, step = 2000 (45.440 sec)\n",
      "INFO:tensorflow:loss = 4.9030805, step = 2000 (45.436 sec)\n",
      "INFO:tensorflow:loss = 4.9040823, step = 2000 (44.972 sec)\n",
      "INFO:tensorflow:loss = 4.9556856, step = 2000 (45.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.23237\n",
      "INFO:tensorflow:global_step/sec: 2.23232\n",
      "INFO:tensorflow:global_step/sec: 2.23234\n",
      "INFO:tensorflow:global_step/sec: 2.23231\n",
      "INFO:tensorflow:global_step/sec: 2.23233\n",
      "INFO:tensorflow:global_step/sec: 2.2323\n",
      "INFO:tensorflow:loss = 5.532014, step = 2100 (44.796 sec)\n",
      "INFO:tensorflow:loss = 4.9596024, step = 2100 (44.796 sec)\n",
      "INFO:tensorflow:loss = 5.1827, step = 2100 (44.797 sec)\n",
      "INFO:tensorflow:loss = 5.261668, step = 2100 (44.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.2323\n",
      "INFO:tensorflow:global_step/sec: 2.23228\n",
      "INFO:tensorflow:loss = 4.929597, step = 2100 (44.796 sec)\n",
      "INFO:tensorflow:loss = 5.079831, step = 2100 (44.797 sec)\n",
      "INFO:tensorflow:loss = 4.832711, step = 2100 (44.797 sec)\n",
      "INFO:tensorflow:loss = 4.92614, step = 2100 (44.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.23326\n",
      "INFO:tensorflow:global_step/sec: 2.23331\n",
      "INFO:tensorflow:global_step/sec: 2.23326\n",
      "INFO:tensorflow:global_step/sec: 2.23326\n",
      "INFO:tensorflow:global_step/sec: 2.23325\n",
      "INFO:tensorflow:loss = 5.230373, step = 2200 (44.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.23325\n",
      "INFO:tensorflow:loss = 4.491722, step = 2200 (44.777 sec)\n",
      "INFO:tensorflow:loss = 5.036561, step = 2200 (44.778 sec)\n",
      "INFO:tensorflow:loss = 5.0031376, step = 2200 (44.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.23325\n",
      "INFO:tensorflow:global_step/sec: 2.23321\n",
      "INFO:tensorflow:loss = 4.96193, step = 2200 (44.778 sec)\n",
      "INFO:tensorflow:loss = 4.6167603, step = 2200 (44.778 sec)\n",
      "INFO:tensorflow:loss = 4.6888766, step = 2200 (44.778 sec)\n",
      "INFO:tensorflow:loss = 4.42426, step = 2200 (45.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.16387\n",
      "INFO:tensorflow:global_step/sec: 2.16372\n",
      "INFO:tensorflow:global_step/sec: 2.16387\n",
      "INFO:tensorflow:global_step/sec: 2.1638\n",
      "INFO:tensorflow:loss = 5.580351, step = 2300 (46.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.16376\n",
      "INFO:tensorflow:global_step/sec: 2.16387\n",
      "INFO:tensorflow:global_step/sec: 2.16388\n",
      "INFO:tensorflow:global_step/sec: 2.1637\n",
      "INFO:tensorflow:loss = 5.454565, step = 2300 (46.213 sec)\n",
      "INFO:tensorflow:loss = 5.3873634, step = 2300 (46.215 sec)\n",
      "INFO:tensorflow:loss = 4.860387, step = 2300 (46.216 sec)\n",
      "INFO:tensorflow:loss = 5.4184146, step = 2300 (46.214 sec)\n",
      "INFO:tensorflow:loss = 5.624173, step = 2300 (46.216 sec)\n",
      "INFO:tensorflow:loss = 5.591509, step = 2300 (45.429 sec)\n",
      "INFO:tensorflow:loss = 5.318435, step = 2300 (46.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.15767\n",
      "INFO:tensorflow:global_step/sec: 2.15782\n",
      "INFO:tensorflow:global_step/sec: 2.15767\n",
      "INFO:tensorflow:global_step/sec: 2.15777\n",
      "INFO:tensorflow:global_step/sec: 2.15768\n",
      "INFO:tensorflow:global_step/sec: 2.15776\n",
      "INFO:tensorflow:loss = 4.730831, step = 2400 (46.346 sec)\n",
      "INFO:tensorflow:loss = 4.6234083, step = 2400 (46.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.15766\n",
      "INFO:tensorflow:loss = 4.6103525, step = 2400 (46.344 sec)\n",
      "INFO:tensorflow:loss = 4.2862773, step = 2400 (46.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.15777\n",
      "INFO:tensorflow:loss = 4.0109315, step = 2400 (46.346 sec)\n",
      "INFO:tensorflow:loss = 4.4846063, step = 2400 (46.344 sec)\n",
      "INFO:tensorflow:loss = 4.2999334, step = 2400 (46.346 sec)\n",
      "INFO:tensorflow:loss = 4.5429296, step = 2400 (46.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.16628\n",
      "INFO:tensorflow:global_step/sec: 2.16626\n",
      "INFO:tensorflow:global_step/sec: 2.16624\n",
      "INFO:tensorflow:global_step/sec: 2.16622\n",
      "INFO:tensorflow:global_step/sec: 2.16621\n",
      "INFO:tensorflow:loss = 5.1173954, step = 2500 (46.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.16622\n",
      "INFO:tensorflow:global_step/sec: 2.16621\n",
      "INFO:tensorflow:global_step/sec: 2.1662\n",
      "INFO:tensorflow:loss = 5.4624367, step = 2500 (46.163 sec)\n",
      "INFO:tensorflow:loss = 4.909484, step = 2500 (46.163 sec)\n",
      "INFO:tensorflow:loss = 4.565445, step = 2500 (46.164 sec)\n",
      "INFO:tensorflow:loss = 5.2983255, step = 2500 (46.164 sec)\n",
      "INFO:tensorflow:loss = 4.9473243, step = 2500 (46.163 sec)\n",
      "INFO:tensorflow:loss = 4.791439, step = 2500 (46.560 sec)\n",
      "INFO:tensorflow:loss = 4.8556304, step = 2500 (46.164 sec)\n",
      "INFO:tensorflow:Loss for final step: 5.1841965.\n",
      "INFO:tensorflow:Loss for final step: 5.168008.\n",
      "INFO:tensorflow:Loss for final step: 5.123181.\n",
      "INFO:tensorflow:Loss for final step: 5.1974177.\n",
      "INFO:tensorflow:Loss for final step: 5.035472.\n",
      "INFO:tensorflow:Loss for final step: 5.5872955.\n",
      "INFO:tensorflow:Loss for final step: 5.0678415.\n",
      "INFO:tensorflow:Loss for final step: 4.8995314.\n"
     ]
    }
   ],
   "source": [
    "!az batchai job file stream -w $WORKSPACE -e $EXPERIMENT --j $JOB_NAME --output-directory-id stdouterr -f stderr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either wait for the job to complete or delete it with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az batchai job delete -w $WORKSPACE -e $EXPERIMENT --name $JOB_NAME -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean_up'></a>\n",
    "## Clean Up Resources\n",
    "Next we wish to tidy up the resource we created.  \n",
    "First we reset the default values we set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az configure --defaults group=''\n",
    "!az configure --defaults location=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next we delete the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az batchai cluster delete -w $WORKSPACE --name $CLUSTER_NAME -g $GROUP_NAME -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cluster is deleted you will not incur any cost for the computation but you can still retain your experiments and workspace. If you wish to delete those as well execute the commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az batchai experiment delete -w $WORKSPACE --name $EXPERIMENT -g $GROUP_NAME -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az batchai workspace delete -n $WORKSPACE -g $GROUP_NAME -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can delete the group and we will have deleted everything created for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az group delete --name $GROUP_NAME -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
