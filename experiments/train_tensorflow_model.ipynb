{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tensorflow Model Distributed on Batch AI\n",
    "In this notebook we will train a TensorFlow model (ResNet50) in a distributed fashion using Horovod on the Imagenet dataset. This tutorial will take you through the steps of creating the cluster, creating the fileserver (NFS fileshare) and running the job on the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values, set_key, find_dotenv, get_key\n",
    "from getpass import getpass\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = find_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the variables that describe our experiment. By default we are using the NC24rs_v3 (Standard_NC24rs_v3) vms which have V100 GPUs and Infiniband. By default we are using 2 nodes with each node having 4 GPUs, this equates to 8 GPUs. Feel free to increase the number of nodes but be aware what limitations your subscription may have.\n",
    "\n",
    "Set the USE_FAKE to True if you want to use fake data rather than the Imagenet dataset. This is often a good way to debug your models as well as checking what IO overhead is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Variables for Batch AI - change as necessary\n",
    "ID                     = \"ddtf\"\n",
    "GROUP_NAME             = f\"batch{ID}rg\"\n",
    "STORAGE_ACCOUNT_NAME   = f\"batch{ID}st\"\n",
    "FILE_SHARE_NAME        = f\"batch{ID}share\"\n",
    "SELECTED_SUBSCRIPTION  = \"Team Danielle Internal\" #\"<YOUR SUBSCRIPTION>\"\n",
    "WORKSPACE              = \"workspace\"\n",
    "NUM_NODES              = 2\n",
    "CLUSTER_NAME           = \"msv100\"\n",
    "VM_SIZE                = \"Standard_NC24rs_v3\"\n",
    "GPU_TYPE               = \"V100\"\n",
    "PROCESSES_PER_NODE     = 4\n",
    "LOCATION               = \"eastus\"\n",
    "NFS_NAME               = f\"batch{ID}nfs\"\n",
    "EXPERIMENT             = f\"distributed_tensorflow_{GPU_TYPE}\"\n",
    "USERNAME               = \"batchai_user\"\n",
    "USE_FAKE               =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAKE='-env FAKE=True' if USE_FAKE else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PASSWORD' not in dotenv_values(dotenv_path=dotenv_path):\n",
    "    password = getpass('Please enter password to use for cluster')\n",
    "    if dotenv_path=='':\n",
    "        dotenv_path='.env'\n",
    "        with open(dotenv_path, 'a'):\n",
    "            os.utime(dotenv_path)\n",
    "    _=set_key(dotenv_path, 'PASSWORD', password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to log in to our Azure account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code ACGVPUSPK to authenticate.\u001b[0m\n",
      "CloudName    IsDefault    Name                                            State    TenantId\n",
      "-----------  -----------  ----------------------------------------------  -------  ------------------------------------\n",
      "AzureCloud   False        Boston DS Dev                                   Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Azure Internal - London                         Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   True         Team Danielle Internal                          Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Visual Studio Enterprise                        Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Azure Stack Diagnostics CI and Production VaaS  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Core-ES-BLD                                     Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        PhillyExt                                       Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Cosmos_WDG_Core_BnB_100348                      Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        PhillyInt                                       Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        AzureCAT WWAHAIHoL                              Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        ASutton Subscription                            Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Solution Template Testing                       Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Team Ilan                                       Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Marketing Automation                            Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more than one Azure account you will need to select it with the command below. If you only have one account you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set --subscription \"$SELECTED_SUBSCRIPTION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                            CloudName    SubscriptionId                        State    IsDefault\r\n",
      "----------------------------------------------  -----------  ------------------------------------  -------  -----------\r\n",
      "Boston DS Dev                                   AzureCloud   0ca618d2-22a8-413a-96d0-0f1b531129c3  Enabled  False\r\n",
      "Azure Internal - London                         AzureCloud   1ba81249-8edd-4619-a486-3d28a2176aad  Enabled  False\r\n",
      "Team Danielle Internal                          AzureCloud   edf507a2-6235-46c5-b560-fd463ba2e771  Enabled  True\r\n",
      "Visual Studio Enterprise                        AzureCloud   fb11e9eb-22e1-4347-8d0a-84ef60157664  Enabled  False\r\n",
      "Azure Stack Diagnostics CI and Production VaaS  AzureCloud   a8183b2d-7a4c-45e9-8736-dac11b84ff14  Enabled  False\r\n",
      "Core-ES-BLD                                     AzureCloud   54e18c35-3863-4a17-8e52-b5aa1e65847e  Enabled  False\r\n",
      "PhillyExt                                       AzureCloud   a20c82c7-4497-4d44-952a-3105f790e26b  Enabled  False\r\n",
      "Cosmos_WDG_Core_BnB_100348                      AzureCloud   dae41bd3-9db4-4b9b-943e-832b57cac828  Enabled  False\r\n",
      "PhillyInt                                       AzureCloud   d50e5f6b-6c27-4ab1-8587-3d85cef6426e  Enabled  False\r\n",
      "AzureCAT WWAHAIHoL                              AzureCloud   1abb567b-bfef-4fac-9574-f55db5b506b4  Enabled  False\r\n",
      "ASutton Subscription                            AzureCloud   10d0b7c6-9243-4713-91a9-2730375d3a1b  Enabled  False\r\n",
      "Solution Template Testing                       AzureCloud   3bcfa59c-82a0-44f9-ac08-b3479370bace  Enabled  False\r\n",
      "Team Ilan                                       AzureCloud   ff18d7a8-962a-406c-858f-49acd23d6c01  Enabled  False\r\n",
      "Marketing Automation                            AzureCloud   03909a66-bef8-4d52-8e9a-a346604e0902  Enabled  False\r\n"
     ]
    }
   ],
   "source": [
    "!az account list -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the group that will hold all our Azure resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\r\n",
      "----------  -----------\r\n",
      "eastus      batchddtfrg\r\n"
     ]
    }
   ],
   "source": [
    "!az group create -n $GROUP_NAME -l $LOCATION -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the storage account that will store our fileshare where all the outputs from the jobs will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-348a2638fc88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'az storage account create -l $LOCATION -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME --sku Standard_LRS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print('Storage account {} provisioning state: {}'.format(STORAGE_ACCOUNT_NAME, \n\u001b[0;32m----> 3\u001b[0;31m                                                          json.loads(''.join(json_data))['provisioningState']))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "json_data = !az storage account create -l $LOCATION -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME --sku Standard_LRS\n",
    "print('Storage account {} provisioning state: {}'.format(STORAGE_ACCOUNT_NAME, \n",
    "                                                         json.loads(''.join(json_data))['provisioningState']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = !az storage account keys list -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME\n",
    "storage_account_key = json.loads(''.join([i for i in json_data if 'WARNING' not in i]))[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created\": true\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az storage share create --account-name $STORAGE_ACCOUNT_NAME --account-key $storage_account_key --name $FILE_SHARE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created\": true\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az storage directory create --share-name $FILE_SHARE_NAME  --name scripts \\\n",
    "--account-name $STORAGE_ACCOUNT_NAME --account-key $storage_account_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting some defaults so we don't have to keep adding them to every command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az configure --defaults location=$LOCATION\n",
    "!az configure --defaults group=$GROUP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AZURE_STORAGE_ACCOUNT=batchddtfst\n",
      "env: AZURE_STORAGE_KEY=YTqQ/B56LmycbuCg5ogzDUZXcjWw0z0WuSlbUTAbWm88vSqRGBq2+WuFlAC9U/XYM/zH1yD3ueuVStY7cEc/lg==\n"
     ]
    }
   ],
   "source": [
    "%env AZURE_STORAGE_ACCOUNT $STORAGE_ACCOUNT_NAME\n",
    "%env AZURE_STORAGE_KEY=$storage_account_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch AI has the concept of workspaces and experiments. Below we will create the workspace for our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"creationTime\": \"2018-08-07T13:47:16.736000+00:00\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace\",\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"name\": \"workspace\",\r\n",
      "  \"provisioningState\": \"succeeded\",\r\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-07T13:47:16.736000+00:00\",\r\n",
      "  \"resourceGroup\": \"batchddtfrg\",\r\n",
      "  \"tags\": null,\r\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai workspace create -n $WORKSPACE -g $GROUP_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will store the data on an NFS fileshare. It is possible to use many storage solutions with Batch AI. NFS offers the best traideoff between performance and ease of use. The best performance is achieved by loading the data locally but this can be cumbersome since it requires that the data is download by the all the nodes which with the imagenet dataset can take hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"creationTime\": \"2018-08-08T13:25:29.951000+00:00\",\n",
      "  \"dataDisks\": {\n",
      "    \"cachingType\": \"none\",\n",
      "    \"diskCount\": 4,\n",
      "    \"diskSizeInGb\": 250,\n",
      "    \"storageAccountType\": \"Premium_LRS\"\n",
      "  },\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace/fileservers/batchddtfnfs\",\n",
      "  \"mountSettings\": {\n",
      "    \"fileServerInternalIp\": \"10.0.0.4\",\n",
      "    \"fileServerPublicIp\": \"40.87.14.176\",\n",
      "    \"mountPoint\": \"/data\"\n",
      "  },\n",
      "  \"name\": \"batchddtfnfs\",\n",
      "  \"provisioningState\": \"succeeded\",\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-08T13:38:17.697000+00:00\",\n",
      "  \"resourceGroup\": \"batchddtfrg\",\n",
      "  \"sshConfiguration\": {\n",
      "    \"publicIpsToAllow\": null,\n",
      "    \"userAccountSettings\": {\n",
      "      \"adminUserName\": \"batchai_user\",\n",
      "      \"adminUserPassword\": null,\n",
      "      \"adminUserSshPublicKey\": null\n",
      "    }\n",
      "  },\n",
      "  \"subnet\": {\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fileserverrg-eba0fa78-2566-468a-b9b6-205739b35675/providers/Microsoft.Network/virtualNetworks/eba0fa78-2566-468a-b9b6-205739b35675vnet/subnets/Subnet-1\",\n",
      "    \"resourceGroup\": \"fileserverrg-eba0fa78-2566-468a-b9b6-205739b35675\"\n",
      "  },\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/fileservers\",\n",
      "  \"vmSize\": \"Standard_DS4_v2\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai file-server create -n $NFS_NAME --disk-count 4 --disk-size 250 -w $WORKSPACE \\\n",
    "-s Standard_DS4_v2 -u $USERNAME -p {get_key(dotenv_path,'PASSWORD')} -g $GROUP_NAME --storage-sku Premium_LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          Resource Group    Size             Disks       Public IP     Internal IP    Mount Point\r\n",
      "------------  ----------------  ---------------  ----------  ------------  -------------  -------------\r\n",
      "batchddtfnfs  batchddtfrg       Standard_DS4_v2  4 x 250 Gb  40.87.14.176  10.0.0.4       /data\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai file-server list -o table -w $WORKSPACE -g $GROUP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = !az batchai file-server list -w $WORKSPACE -g $GROUP_NAME\n",
    "nfs_ip=json.loads(''.join([i for i in json_data if 'WARNING' not in i]))[0]['mountSettings']['fileServerPublicIp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have created the NFS share we need to copy the data to it. To do this we write the script below which will be executed on the fileserver. It installs a tool called azcopy and then downloads and extracts the data to the appropriate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nodeprep.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile nodeprep.sh\n",
    "#!/usr/bin/env bash\n",
    "wget https://gist.githubusercontent.com/msalvaris/073c28a9993d58498957294d20d74202/raw/87a78275879f7c9bb8d6fb9de8a2d2996bb66c24/install_azcopy\n",
    "chmod 777 install_azcopy\n",
    "sudo ./install_azcopy\n",
    "\n",
    "mkdir -p /data/imagenet\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/validation.csv \\\n",
    "        --destination  /data/imagenet/validation.csv\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=7x3rN7c/nlXbnZ0gAFywd5Er3r6MdwCq97Vwvda25WE%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/validation.tar.gz \\\n",
    "        --destination  /data/imagenet/validation.tar.gz\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=zy8L4shZa3XXBe152hPnhXsyfBqCufDOz01a9ZHWU28%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/train.csv \\\n",
    "        --destination  /data/imagenet/train.csv\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=EUcahDDZcefOKtHoVWDh7voAC1BoxYNM512spFmjmDU%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "azcopy --source https://datasharesa.blob.core.windows.net/imagenet/train.tar.gz \\\n",
    "        --destination  /data/imagenet/train.tar.gz\\\n",
    "        --source-sas \"?se=2025-01-01&sp=r&sv=2017-04-17&sr=b&sig=qP%2B7lQuFKHo5UhQKpHcKt6p5fHT21lPaLz1O/vv4FNU%3D\"\\\n",
    "        --quiet\n",
    "\n",
    "cd /data/imagenet\n",
    "tar -xzf train.tar.gz\n",
    "tar -xzf validation.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will copy the file over and run it on the NFS VM. This will install azcopy and download and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sshpass -p {get_key(dotenv_path,'PASSWORD')} scp nodeprep.sh $USERNAME@{nfs_ip}:~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "!sshpass -p {get_key(dotenv_path,'PASSWORD')} ssh $USERNAME@{nfs_ip} \"sudo chmod 777 ~/nodeprep.sh && ./nodeprep.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K - Starting ..\r",
      "\r",
      "\u001b[K - Finished ..\r",
      "\r",
      "\u001b[K{\r\n",
      "  \"creationTime\": \"2018-08-08T16:24:39.322000+00:00\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace/experiments/distributed_tensorflow_v100\",\r\n",
      "  \"name\": \"distributed_tensorflow_v100\",\r\n",
      "  \"provisioningState\": \"succeeded\",\r\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-08T16:24:39.322000+00:00\",\r\n",
      "  \"resourceGroup\": \"batchddtfrg\",\r\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/experiments\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai experiment create -n $EXPERIMENT -g $GROUP_NAME -w $WORKSPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then upload the scripts we wish to execute onto the fileserver. The fileshare will later be mounted Batch AI. An alternative to uploading the scripts would be to embedd them inside the Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished[#############################################################]  100.0000%\n",
      "Finished[#############################################################]  100.0000%\n",
      "Finished[#############################################################]  100.0000%\n"
     ]
    }
   ],
   "source": [
    "!az storage file upload --share-name $FILE_SHARE_NAME --source ../HorovodTF/src/imagenet_estimator_tf_horovod.py --path scripts\n",
    "!az storage file upload --share-name $FILE_SHARE_NAME --source ../HorovodTF/src/resnet_model.py --path scripts\n",
    "!az storage file upload --share-name $FILE_SHARE_NAME --source ../common/timer.py --path scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below it the command to create the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\"msv100\" already exists in \"batchddtfrg\" resource group under workspace resource group.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster create \\\n",
    "    -w $WORKSPACE \\\n",
    "    --name $CLUSTER_NAME \\\n",
    "    --image UbuntuLTS \\\n",
    "    --vm-size $VM_SIZE \\\n",
    "    --min $NUM_NODES --max $NUM_NODES \\\n",
    "    --afs-name $FILE_SHARE_NAME \\\n",
    "    --afs-mount-path extfs \\\n",
    "    --user-name $USERNAME \\\n",
    "    --password {get_key(dotenv_path,'PASSWORD')} \\\n",
    "    --storage-account-name $STORAGE_ACCOUNT_NAME \\\n",
    "    --storage-account-key $storage_account_key \\\n",
    "    --nfs $NFS_NAME \\\n",
    "    --nfs-mount-path nfs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the cluster was created succesfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"allocationState\": \"steady\",\r\n",
      "  \"allocationStateTransitionTime\": \"2018-08-08T16:45:04.509000+00:00\",\r\n",
      "  \"creationTime\": \"2018-08-08T16:42:34.670000+00:00\",\r\n",
      "  \"currentNodeCount\": 2,\r\n",
      "  \"errors\": null,\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace/clusters/msv100\",\r\n",
      "  \"name\": \"msv100\",\r\n",
      "  \"nodeSetup\": {\r\n",
      "    \"mountVolumes\": {\r\n",
      "      \"azureBlobFileSystems\": null,\r\n",
      "      \"azureFileShares\": [\r\n",
      "        {\r\n",
      "          \"accountName\": \"batchddtfst\",\r\n",
      "          \"azureFileUrl\": \"https://batchddtfst.file.core.windows.net/batchddtfshare\",\r\n",
      "          \"credentials\": {\r\n",
      "            \"accountKey\": null,\r\n",
      "            \"accountKeySecretReference\": null\r\n",
      "          },\r\n",
      "          \"directoryMode\": \"0777\",\r\n",
      "          \"fileMode\": \"0777\",\r\n",
      "          \"relativeMountPath\": \"extfs\"\r\n",
      "        }\r\n",
      "      ],\r\n",
      "      \"fileServers\": [\r\n",
      "        {\r\n",
      "          \"fileServer\": {\r\n",
      "            \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace/fileservers/batchddtfnfs\",\r\n",
      "            \"resourceGroup\": \"batchddtfrg\"\r\n",
      "          },\r\n",
      "          \"mountOptions\": \"rw\",\r\n",
      "          \"relativeMountPath\": \"nfs\",\r\n",
      "          \"sourceDirectory\": null\r\n",
      "        }\r\n",
      "      ],\r\n",
      "      \"unmanagedFileSystems\": null\r\n",
      "    },\r\n",
      "    \"performanceCountersSettings\": null,\r\n",
      "    \"setupTask\": null\r\n",
      "  },\r\n",
      "  \"nodeStateCounts\": {\r\n",
      "    \"idleNodeCount\": 2,\r\n",
      "    \"leavingNodeCount\": 0,\r\n",
      "    \"preparingNodeCount\": 0,\r\n",
      "    \"runningNodeCount\": 0,\r\n",
      "    \"unusableNodeCount\": 0\r\n",
      "  },\r\n",
      "  \"provisioningState\": \"succeeded\",\r\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-08T16:42:44.675000+00:00\",\r\n",
      "  \"resourceGroup\": \"batchddtfrg\",\r\n",
      "  \"scaleSettings\": {\r\n",
      "    \"autoScale\": null,\r\n",
      "    \"manual\": {\r\n",
      "      \"nodeDeallocationOption\": \"requeue\",\r\n",
      "      \"targetNodeCount\": 2\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"subnet\": {\r\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fileserverrg-eba0fa78-2566-468a-b9b6-205739b35675/providers/Microsoft.Network/virtualNetworks/eba0fa78-2566-468a-b9b6-205739b35675vnet/subnets/Subnet-1\",\r\n",
      "    \"resourceGroup\": \"fileserverrg-eba0fa78-2566-468a-b9b6-205739b35675\"\r\n",
      "  },\r\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/clusters\",\r\n",
      "  \"userAccountSettings\": {\r\n",
      "    \"adminUserName\": \"batchai_user\",\r\n",
      "    \"adminUserPassword\": null,\r\n",
      "    \"adminUserSshPublicKey\": null\r\n",
      "  },\r\n",
      "  \"virtualMachineConfiguration\": {\r\n",
      "    \"imageReference\": {\r\n",
      "      \"offer\": \"UbuntuServer\",\r\n",
      "      \"publisher\": \"Canonical\",\r\n",
      "      \"sku\": \"16.04-LTS\",\r\n",
      "      \"version\": \"latest\",\r\n",
      "      \"virtualMachineImageId\": null\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"vmPriority\": \"dedicated\",\r\n",
      "  \"vmSize\": \"STANDARD_NC24RS_V3\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster show -n $CLUSTER_NAME -w $WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    Resource Group    Workspace    VM Size             State      Idle    Running    Preparing    Leaving    Unusable\r\n",
      "------  ----------------  -----------  ------------------  -------  ------  ---------  -----------  ---------  ----------\r\n",
      "msv100  batchddtfrg       workspace    STANDARD_NC24RS_V3  steady        2          0            0          0           0\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster list -w $WORKSPACE -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                 IP               SSH Port\r\n",
      "---------------------------------  -------------  ----------\r\n",
      "tvm-1783593343_1-20180808t164503z  40.117.139.38       50001\r\n",
      "tvm-1783593343_2-20180808t164503z  40.117.139.38       50000\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai cluster node list -c $CLUSTER_NAME -w $WORKSPACE -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we specify the job we wish to execute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_dict = {\n",
    "  \"$schema\": \"https://raw.githubusercontent.com/Azure/BatchAI/master/schemas/2017-09-01-preview/job.json\",\n",
    "  \"properties\": {\n",
    "    \"nodeCount\": NUM_NODES,\n",
    "    \"customToolkitSettings\": {\n",
    "      \"commandLine\": f\"source /opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin/mpivars.sh; \\\n",
    "      echo $AZ_BATCH_HOST_LIST; \\\n",
    "      mpirun -n {NUM_NODES} -ppn {PROCESSES_PER_NODE} -hosts $AZ_BATCH_HOST_LIST \\\n",
    "      -env I_MPI_FABRICS=dapl \\\n",
    "      -env I_MPI_DAPL_PROVIDER=ofa-v2-ib0 \\\n",
    "      -env I_MPI_DYNAMIC_CONNECTION=0 \\\n",
    "      -env I_MPI_DEBUG=6 \\\n",
    "      -env I_MPI_HYDRA_DEBUG=on \\\n",
    "      -env DISTRIBUTED=True \\\n",
    "      {FAKE} \\\n",
    "      python -u $AZ_BATCHAI_INPUT_SCRIPTS/imagenet_estimator_tf_horovod.py\"\n",
    "    },\n",
    "    \"stdOutErrPathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
    "    \"inputDirectories\": [{\n",
    "        \"id\": \"SCRIPTS\",\n",
    "        \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs/scripts\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"TRAIN\",\n",
    "        \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\",\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"TEST\",\n",
    "        \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\",\n",
    "      },\n",
    "    ],\n",
    "    \"outputDirectories\": [{\n",
    "        \"id\": \"MODEL\",\n",
    "        \"pathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
    "        \"pathSuffix\": \"Models\"\n",
    "    }],\n",
    "    \"containerSettings\": {\n",
    "      \"imageSourceRegistry\": {\n",
    "        \"image\": \"caia/distributed-training.horovod-tf\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_file(json_dict, filename, mode='w'):\n",
    "    with open(filename, mode) as outfile:\n",
    "        json.dump(json_dict, outfile, indent=4, sort_keys=True)\n",
    "        outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_to_file(jobs_dict, 'job.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME='tf-horovod-{}'.format(NUM_NODES*PROCESSES_PER_NODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now submit the job to Batch AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"caffe2Settings\": null,\n",
      "  \"caffeSettings\": null,\n",
      "  \"chainerSettings\": null,\n",
      "  \"cluster\": {\n",
      "    \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace/clusters/msv100\",\n",
      "    \"resourceGroup\": \"batchddtfrg\"\n",
      "  },\n",
      "  \"cntkSettings\": null,\n",
      "  \"constraints\": {\n",
      "    \"maxWallClockTime\": \"7 days, 0:00:00\"\n",
      "  },\n",
      "  \"containerSettings\": {\n",
      "    \"imageSourceRegistry\": {\n",
      "      \"credentials\": null,\n",
      "      \"image\": \"caia/distributed-training.horovod-tf\",\n",
      "      \"serverUrl\": null\n",
      "    },\n",
      "    \"shmSize\": null\n",
      "  },\n",
      "  \"creationTime\": \"2018-08-09T10:17:10.961000+00:00\",\n",
      "  \"customMpiSettings\": null,\n",
      "  \"customToolkitSettings\": {\n",
      "    \"commandLine\": \"source /opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin/mpivars.sh;       echo $AZ_BATCH_HOST_LIST;       mpirun -n 2 -ppn 4 -hosts $AZ_BATCH_HOST_LIST       -env I_MPI_FABRICS=dapl       -env I_MPI_DAPL_PROVIDER=ofa-v2-ib0       -env I_MPI_DYNAMIC_CONNECTION=0       -env I_MPI_DEBUG=6       -env I_MPI_HYDRA_DEBUG=on       -env DISTRIBUTED=True              python -u $AZ_BATCHAI_INPUT_SCRIPTS/imagenet_estimator_tf_horovod.py\"\n",
      "  },\n",
      "  \"environmentVariables\": null,\n",
      "  \"executionInfo\": {\n",
      "    \"endTime\": null,\n",
      "    \"errors\": null,\n",
      "    \"exitCode\": null,\n",
      "    \"startTime\": \"2018-08-09T10:17:15.349000+00:00\"\n",
      "  },\n",
      "  \"executionState\": \"running\",\n",
      "  \"executionStateTransitionTime\": \"2018-08-09T10:17:15.349000+00:00\",\n",
      "  \"horovodSettings\": null,\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/batchddtfrg/providers/Microsoft.BatchAI/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8\",\n",
      "  \"inputDirectories\": [\n",
      "    {\n",
      "      \"id\": \"SCRIPTS\",\n",
      "      \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs/scripts\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"TRAIN\",\n",
      "      \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"TEST\",\n",
      "      \"path\": \"$AZ_BATCHAI_MOUNT_ROOT/nfs/imagenet\"\n",
      "    }\n",
      "  ],\n",
      "  \"jobOutputDirectoryPathSegment\": \"edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4\",\n",
      "  \"jobPreparation\": null,\n",
      "  \"mountVolumes\": null,\n",
      "  \"name\": \"tf-horovod-8\",\n",
      "  \"nodeCount\": 2,\n",
      "  \"outputDirectories\": [\n",
      "    {\n",
      "      \"id\": \"MODEL\",\n",
      "      \"pathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
      "      \"pathSuffix\": \"Models\"\n",
      "    }\n",
      "  ],\n",
      "  \"provisioningState\": \"succeeded\",\n",
      "  \"provisioningStateTransitionTime\": \"2018-08-09T10:17:11.336000+00:00\",\n",
      "  \"pyTorchSettings\": null,\n",
      "  \"resourceGroup\": \"batchddtfrg\",\n",
      "  \"schedulingPriority\": \"normal\",\n",
      "  \"secrets\": null,\n",
      "  \"stdOutErrPathPrefix\": \"$AZ_BATCHAI_MOUNT_ROOT/extfs\",\n",
      "  \"tensorFlowSettings\": null,\n",
      "  \"toolType\": \"custom\",\n",
      "  \"type\": \"Microsoft.BatchAI/workspaces/experiments/jobs\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az batchai job create -n $JOB_NAME --cluster $CLUSTER_NAME -w $WORKSPACE -e $EXPERIMENT -f job.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the command below we can check the status of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          Cluster    Cluster RG    Cluster Workspace    Tool      Nodes  State        Exit code\r\n",
      "------------  ---------  ------------  -------------------  ------  -------  ---------  -----------\r\n",
      "tf-horovod-8  msv100     batchddtfrg   workspace            custom        2  succeeded            0\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai job list -w $WORKSPACE -e $EXPERIMENT -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the files that the job has generated use the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"contentLength\": 11345,\r\n",
      "    \"downloadUrl\": \"https://batchddtfst.file.core.windows.net/batchddtfshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/stdouterr/execution-tvm-1783593343_1-20180808t164503z.log?sv=2016-05-31&sr=f&sig=LoVQSqjRkDHTk%2BLM0EHYutEgw2p%2B8f3l97cQLjwC3%2F8%3D&se=2018-08-09T12%3A43%3A28Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-09T10:17:28+00:00\",\r\n",
      "    \"name\": \"execution-tvm-1783593343_1-20180808t164503z.log\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"contentLength\": 16608,\r\n",
      "    \"downloadUrl\": \"https://batchddtfst.file.core.windows.net/batchddtfshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/stdouterr/execution-tvm-1783593343_2-20180808t164503z.log?sv=2016-05-31&sr=f&sig=mOJ9oiuzH5lONeNohHVqotSVNtlM1W88kd2KPRGD%2BB8%3D&se=2018-08-09T12%3A43%3A28Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-09T10:58:17+00:00\",\r\n",
      "    \"name\": \"execution-tvm-1783593343_2-20180808t164503z.log\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"contentLength\": 26161,\r\n",
      "    \"downloadUrl\": \"https://batchddtfst.file.core.windows.net/batchddtfshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/stdouterr/stderr.txt?sv=2016-05-31&sr=f&sig=9tL1IgiyouNLiUkISwY1aBSDyy7HeBLT6WfXIJs679s%3D&se=2018-08-09T12%3A43%3A28Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-09T10:58:16+00:00\",\r\n",
      "    \"name\": \"stderr.txt\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"contentLength\": 37824,\r\n",
      "    \"downloadUrl\": \"https://batchddtfst.file.core.windows.net/batchddtfshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/stdouterr/stdout.txt?sv=2016-05-31&sr=f&sig=xw%2BQ1t7zTvcngc4PE8MXBW7PDC3Tgv6pOCb2hX9dpM8%3D&se=2018-08-09T12%3A43%3A28Z&sp=rl\",\r\n",
      "    \"fileType\": \"file\",\r\n",
      "    \"lastModified\": \"2018-08-09T10:58:16+00:00\",\r\n",
      "    \"name\": \"stdout.txt\"\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!az batchai job file list -w $WORKSPACE -e $EXPERIMENT --j $JOB_NAME --output-directory-id stdouterr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also able to stream the stdout and stderr that our job produces. This is great to check the progress of our job as well as debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFile found with URL \"https://batchddtfst.file.core.windows.net/batchddtfshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/stdouterr/stdout.txt?sv=2016-05-31&sr=f&sig=tiLmDJR%2BC8cuOj%2Bm%2BM3ZRQZAkrfOLKXR3dpmHL6cI1U%3D&se=2018-08-09T12%3A43%3A32Z&sp=rl\". Start streaming\u001b[0m\n",
      "10.0.0.5,10.0.0.6\n",
      "[0] MPI startup(): Intel(R) MPI Library, Version 2017 Update 3  Build 20170405 (id: 17193)\n",
      "[0] MPI startup(): Copyright (C) 2003-2017 Intel Corporation.  All rights reserved.\n",
      "[0] MPI startup(): Multi-threaded optimized library\n",
      "[0] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[1] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-ib0\n",
      "[1] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[1] MPI startup(): dapl data transfer mode\n",
      "[0] MPI startup(): DAPL provider ofa-v2-ib0\n",
      "[0] MPI startup(): dapl data transfer mode\n",
      "[0] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[0] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[1] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000\n",
      "[1] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000\n",
      "[0] MPI startup(): Device_reset_idx=4\n",
      "[0] MPI startup(): Allgather: 1: 0-0 & 0-4\n",
      "[0] MPI startup(): Allgather: 5: 1-1 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 2-2 & 0-4\n",
      "[0] MPI startup(): Allgather: 5: 3-6 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 7-48 & 0-4\n",
      "[0] MPI startup(): Allgather: 5: 49-107 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 108-6630 & 0-4\n",
      "[0] MPI startup(): Allgather: 3: 6631-8929 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 8930-17155 & 0-4\n",
      "[0] MPI startup(): Allgather: 5: 17156-99947 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 99948-131072 & 0-4\n",
      "[0] MPI startup(): Allgather: 5: 131073-262144 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Allgather: 1: 0-0 & 5-8\n",
      "[0] MPI startup(): Allgather: 5: 1-1 & 5-8\n",
      "[0] MPI startup(): Allgather: 1: 2-2 & 5-8\n",
      "[0] MPI startup(): Allgather: 5: 3-7 & 5-8\n",
      "[0] MPI startup(): Allgather: 1: 8-16 & 5-8\n",
      "[0] MPI startup(): Allgather: 5: 17-64 & 5-8\n",
      "[0] MPI startup(): Allgather: 1: 65-256 & 5-8\n",
      "[0] MPI startup(): Allgather: 5: 257-6581 & 5-8\n",
      "[0] MPI startup(): Allgather: 1: 6582-10281 & 5-8\n",
      "[0] MPI startup(): Allgather: 5: 10282-2883613 & 5-8\n",
      "[0] MPI startup(): Allgather: 1: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Allgather: 2: 0-0 & 9-16\n",
      "[0] MPI startup(): Allgather: 5: 1-1 & 9-16\n",
      "[0] MPI startup(): Allgather: 1: 2-5 & 9-16\n",
      "[0] MPI startup(): Allgather: 5: 6-9 & 9-16\n",
      "[0] MPI startup(): Allgather: 2: 10-43 & 9-16\n",
      "[0] MPI startup(): Allgather: 5: 44-64 & 9-16\n",
      "[0] MPI startup(): Allgather: 1: 65-256 & 9-16\n",
      "[0] MPI startup(): Allgather: 2: 257-568 & 9-16\n",
      "[0] MPI startup(): Allgather: 5: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Allgather: 2: 0-0 & 17-32\n",
      "[0] MPI startup(): Allgather: 1: 1-2 & 17-32\n",
      "[0] MPI startup(): Allgather: 5: 3-8 & 17-32\n",
      "[0] MPI startup(): Allgather: 1: 9-16 & 17-32\n",
      "[0] MPI startup(): Allgather: 5: 17-2097152 & 17-32\n",
      "[0] MPI startup(): Allgather: 1: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Allgather: 1: 0-4 & 33-64\n",
      "[0] MPI startup(): Allgather: 5: 5-8 & 33-64\n",
      "[0] MPI startup(): Allgather: 1: 9-1024 & 33-64\n",
      "[0] MPI startup(): Allgather: 5: 1025-262144 & 33-64\n",
      "[0] MPI startup(): Allgather: 1: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Allgather: 1: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Allgather: 5: 1-2 & 65-2147483647\n",
      "[0] MPI startup(): Allgather: 1: 3-4 & 65-2147483647\n",
      "[0] MPI startup(): Allgather: 5: 5-128 & 65-2147483647\n",
      "[0] MPI startup(): Allgather: 1: 129-512 & 65-2147483647\n",
      "[0] MPI startup(): Allgather: 5: 513-65536 & 65-2147483647\n",
      "[0] MPI startup(): Allgather: 1: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 0-3183 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 2: 3184-5581 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 3: 5582-11269 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 1: 11270-30476 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 3: 30477-37575 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 1: 37576-109818 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Allgatherv: 2: 0-1 & 5-8\n",
      "[0] MPI startup(): Allgatherv: 1: 2-8053 & 5-8\n",
      "[0] MPI startup(): Allgatherv: 3: 8054-8192 & 5-8\n",
      "[0] MPI startup(): Allgatherv: 2: 8193-32768 & 5-8\n",
      "[0] MPI startup(): Allgatherv: 1: 32769-75947 & 5-8\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Allgatherv: 1: 0-8192 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 2: 8193-32768 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 1: 32769-69300 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Allgatherv: 1: 0-4 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 2: 5-8 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 1: 9-256 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 2: 257-65536 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Allgatherv: 1: 0-4096 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 2: 4097-32768 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 1: 32769-65536 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Allgatherv: 4: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 1-3 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 4-4 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 5-8 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 9-64 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 65-256 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 257-554 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 555-1609 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 1: 1610-10180 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 2: 10181-98801 & 65-2147483647\n",
      "[0] MPI startup(): Allgatherv: 3: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 0-0 & 0-4\n",
      "[0] MPI startup(): Allreduce: 10: 1-12 & 0-4\n",
      "[0] MPI startup(): Allreduce: 12: 13-21 & 0-4\n",
      "[0] MPI startup(): Allreduce: 10: 22-32 & 0-4\n",
      "[0] MPI startup(): Allreduce: 11: 33-64 & 0-4\n",
      "[0] MPI startup(): Allreduce: 1: 65-336 & 0-4\n",
      "[0] MPI startup(): Allreduce: 12: 337-1024 & 0-4\n",
      "[0] MPI startup(): Allreduce: 10: 1025-2048 & 0-4\n",
      "[0] MPI startup(): Allreduce: 12: 2049-15202 & 0-4\n",
      "[0] MPI startup(): Allreduce: 7: 15203-24865 & 0-4\n",
      "[0] MPI startup(): Allreduce: 8: 24866-41031 & 0-4\n",
      "[0] MPI startup(): Allreduce: 7: 41032-65536 & 0-4\n",
      "[0] MPI startup(): Allreduce: 2: 65537-131072 & 0-4\n",
      "[0] MPI startup(): Allreduce: 7: 131073-363383 & 0-4\n",
      "[0] MPI startup(): Allreduce: 2: 363384-847045 & 0-4\n",
      "[0] MPI startup(): Allreduce: 7: 847046-2097152 & 0-4\n",
      "[0] MPI startup(): Allreduce: 8: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Allreduce: 1: 0-0 & 5-8\n",
      "[0] MPI startup(): Allreduce: 11: 1-4096 & 5-8\n",
      "[0] MPI startup(): Allreduce: 10: 4097-16384 & 5-8\n",
      "[0] MPI startup(): Allreduce: 2: 16385-64984 & 5-8\n",
      "[0] MPI startup(): Allreduce: 8: 64985-65765 & 5-8\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Allreduce: 4: 0-0 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 1-4 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 5-8 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 9-16 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 17-32 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 33-128 & 9-16\n",
      "[0] MPI startup(): Allreduce: 11: 129-4096 & 9-16\n",
      "[0] MPI startup(): Allreduce: 12: 4097-10674 & 9-16\n",
      "[0] MPI startup(): Allreduce: 10: 10675-16384 & 9-16\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Allreduce: 2: 0-0 & 17-32\n",
      "[0] MPI startup(): Allreduce: 11: 1-8 & 17-32\n",
      "[0] MPI startup(): Allreduce: 1: 9-18 & 17-32\n",
      "[0] MPI startup(): Allreduce: 11: 19-8192 & 17-32\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Allreduce: 5: 0-0 & 33-64\n",
      "[0] MPI startup(): Allreduce: 11: 1-5 & 33-64\n",
      "[0] MPI startup(): Allreduce: 1: 6-9 & 33-64\n",
      "[0] MPI startup(): Allreduce: 11: 10-64 & 33-64\n",
      "[0] MPI startup(): Allreduce: 12: 65-128 & 33-64\n",
      "[0] MPI startup(): Allreduce: 11: 129-404 & 33-64\n",
      "[0] MPI startup(): Allreduce: 12: 405-512 & 33-64\n",
      "[0] MPI startup(): Allreduce: 10: 513-1024 & 33-64\n",
      "[0] MPI startup(): Allreduce: 12: 1025-2048 & 33-64\n",
      "[0] MPI startup(): Allreduce: 10: 2049-8192 & 33-64\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Allreduce: 2: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 1-17 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 12: 18-51 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 52-64 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 12: 65-128 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 129-367 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 10: 368-1433 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 11: 1434-4761 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 12: 4762-10922 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 10: 10923-16384 & 65-2147483647\n",
      "[0] MPI startup(): Allreduce: 2: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Alltoall: 1: 0-0 & 0-4\n",
      "[0] MPI startup(): Alltoall: 2: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Alltoall: 1: 0-0 & 5-8\n",
      "[0] MPI startup(): Alltoall: 2: 1-1048576 & 5-8\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Alltoall: 3: 0-0 & 9-16\n",
      "[0] MPI startup(): Alltoall: 2: 1-8 & 9-16\n",
      "[0] MPI startup(): Alltoall: 1: 9-32 & 9-16\n",
      "[0] MPI startup(): Alltoall: 2: 33-524288 & 9-16\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Alltoall: 1: 0-256 & 17-32\n",
      "[0] MPI startup(): Alltoall: 2: 257-262144 & 17-32\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Alltoall: 1: 0-256 & 33-64\n",
      "[0] MPI startup(): Alltoall: 2: 257-524288 & 33-64\n",
      "[0] MPI startup(): Alltoall: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Alltoall: 1: 0-256 & 65-2147483647\n",
      "[0] MPI startup(): Alltoall: 2: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Alltoallv: 1: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Alltoallw: 0: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Barrier: 7: 0-2147483647 & 0-144\n",
      "[0] MPI startup(): Barrier: 8: 0-2147483647 & 145-576\n",
      "[0] MPI startup(): Barrier: 7: 0-2147483647 & 577-1152\n",
      "[0] MPI startup(): Barrier: 8: 0-2147483647 & 1153-2147483647\n",
      "[0] MPI startup(): Bcast: 2: 0-0 & 0-4\n",
      "[0] MPI startup(): Bcast: 9: 1-16 & 0-4\n",
      "[0] MPI startup(): Bcast: 10: 17-32 & 0-4\n",
      "[0] MPI startup(): Bcast: 9: 33-64 & 0-4\n",
      "[0] MPI startup(): Bcast: 10: 65-315 & 0-4\n",
      "[0] MPI startup(): Bcast: 9: 316-512 & 0-4\n",
      "[0] MPI startup(): Bcast: 10: 513-1024 & 0-4\n",
      "[0] MPI startup(): Bcast: 9: 1025-7045 & 0-4\n",
      "[0] MPI startup(): Bcast: 10: 7046-31861 & 0-4\n",
      "[0] MPI startup(): Bcast: 7: 31862-262144 & 0-4\n",
      "[0] MPI startup(): Bcast: 4: 262145-524288 & 0-4\n",
      "[0] MPI startup(): Bcast: 3: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Bcast: 1: 0-0 & 5-8\n",
      "[0] MPI startup(): Bcast: 9: 1-1 & 5-8\n",
      "[0] MPI startup(): Bcast: 4: 2-8 & 5-8\n",
      "[0] MPI startup(): Bcast: 9: 9-64 & 5-8\n",
      "[0] MPI startup(): Bcast: 11: 65-128 & 5-8\n",
      "[0] MPI startup(): Bcast: 9: 129-256 & 5-8\n",
      "[0] MPI startup(): Bcast: 11: 257-968 & 5-8\n",
      "[0] MPI startup(): Bcast: 1: 969-2048 & 5-8\n",
      "[0] MPI startup(): Bcast: 9: 2049-8192 & 5-8\n",
      "[0] MPI startup(): Bcast: 2: 8193-16384 & 5-8\n",
      "[0] MPI startup(): Bcast: 11: 16385-44039 & 5-8\n",
      "[0] MPI startup(): Bcast: 5: 44040-262144 & 5-8\n",
      "[0] MPI startup(): Bcast: 4: 262145-803780 & 5-8\n",
      "[0] MPI startup(): Bcast: 2: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Bcast: 8: 0-0 & 9-16\n",
      "[0] MPI startup(): Bcast: 11: 1-1 & 9-16\n",
      "[0] MPI startup(): Bcast: 10: 2-51 & 9-16\n",
      "[0] MPI startup(): Bcast: 8: 52-64 & 9-16\n",
      "[0] MPI startup(): Bcast: 9: 65-128 & 9-16\n",
      "[0] MPI startup(): Bcast: 10: 129-918 & 9-16\n",
      "[0] MPI startup(): Bcast: 1: 919-4096 & 9-16\n",
      "[0] MPI startup(): Bcast: 10: 4097-8192 & 9-16\n",
      "[0] MPI startup(): Bcast: 11: 8193-16384 & 9-16\n",
      "[0] MPI startup(): Bcast: 2: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Bcast: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Bcast: 9: 1-1 & 17-32\n",
      "[0] MPI startup(): Bcast: 4: 2-5 & 17-32\n",
      "[0] MPI startup(): Bcast: 10: 6-8 & 17-32\n",
      "[0] MPI startup(): Bcast: 11: 9-32 & 17-32\n",
      "[0] MPI startup(): Bcast: 4: 33-107 & 17-32\n",
      "[0] MPI startup(): Bcast: 10: 108-128 & 17-32\n",
      "[0] MPI startup(): Bcast: 11: 129-256 & 17-32\n",
      "[0] MPI startup(): Bcast: 10: 257-933 & 17-32\n",
      "[0] MPI startup(): Bcast: 1: 934-8988 & 17-32\n",
      "[0] MPI startup(): Bcast: 10: 8989-32768 & 17-32\n",
      "[0] MPI startup(): Bcast: 2: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Bcast: 1: 0-0 & 33-64\n",
      "[0] MPI startup(): Bcast: 8: 1-639 & 33-64\n",
      "[0] MPI startup(): Bcast: 1: 640-4096 & 33-64\n",
      "[0] MPI startup(): Bcast: 10: 4097-65536 & 33-64\n",
      "[0] MPI startup(): Bcast: 4: 65537-133608 & 33-64\n",
      "[0] MPI startup(): Bcast: 2: 133609-351685 & 33-64\n",
      "[0] MPI startup(): Bcast: 4: 351686-775473 & 33-64\n",
      "[0] MPI startup(): Bcast: 6: 775474-1591897 & 33-64\n",
      "[0] MPI startup(): Bcast: 4: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Bcast: 11: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 4: 1-2 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 10: 3-11 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 4: 12-31 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 10: 32-32 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 4: 33-125 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 10: 126-361 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 4: 362-1000 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 1: 1001-2048 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 4: 2049-4096 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 1: 4097-8878 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 5: 8879-16384 & 65-2147483647\n",
      "[0] MPI startup(): Bcast: 2: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Exscan: 0: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Gather: 1: 0-0 & 0-8\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 0-8\n",
      "[0] MPI startup(): Gather: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Gather: 3: 1-8 & 9-16\n",
      "[0] MPI startup(): Gather: 2: 9-32 & 9-16\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Gather: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Gather: 2: 1-2 & 17-32\n",
      "[0] MPI startup(): Gather: 3: 3-10 & 17-32\n",
      "[0] MPI startup(): Gather: 1: 11-128 & 17-32\n",
      "[0] MPI startup(): Gather: 4: 129-391 & 17-32\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Gather: 3: 0-0 & 33-64\n",
      "[0] MPI startup(): Gather: 1: 1-770 & 33-64\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Gather: 1: 0-11 & 65-2147483647\n",
      "[0] MPI startup(): Gather: 4: 12-27 & 65-2147483647\n",
      "[0] MPI startup(): Gather: 1: 28-77 & 65-2147483647\n",
      "[0] MPI startup(): Gather: 4: 78-201 & 65-2147483647\n",
      "[0] MPI startup(): Gather: 1: 202-1071 & 65-2147483647\n",
      "[0] MPI startup(): Gather: 3: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Gatherv: 1: 0-2147483647 & 0-32\n",
      "[0] MPI startup(): Gatherv: 3: 0-2147483647 & 33-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 1: 0-0 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-4 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 1: 5-15 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 3: 16-42 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 1: 43-81 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 3: 82-128 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 1: 129-916 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 3: 917-65536 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-0 & 5-8\n",
      "[0] MPI startup(): Reduce_scatter: 5: 1-15 & 5-8\n",
      "[0] MPI startup(): Reduce_scatter: 1: 16-25 & 5-8\n",
      "[0] MPI startup(): Reduce_scatter: 3: 26-32768 & 5-8\n",
      "[0] MPI startup(): Reduce_scatter: 3: 32769-131072 & 5-8\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Reduce_scatter: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-4 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 5: 5-27 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 1: 28-72 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 5: 73-192 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 1: 193-268 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 3: 269-186693 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Reduce_scatter: 3: 0-0 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-118 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 3: 119-216989 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 2: 216990-395652 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 4: 395653-524288 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Reduce_scatter: 3: 0-0 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-123 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 1: 124-1353 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 3: 1354-66737 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 1: 66738-219788 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Reduce_scatter: 5: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 4: 1-156 & 65-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 1: 157-32768 & 65-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 3: 32769-65536 & 65-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 1: 65537-212469 & 65-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 3: 212470-543069 & 65-2147483647\n",
      "[0] MPI startup(): Reduce_scatter: 2: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 2: 0-0 & 0-4\n",
      "[0] MPI startup(): Reduce: 7: 1-4998 & 0-4\n",
      "[0] MPI startup(): Reduce: 10: 4999-8192 & 0-4\n",
      "[0] MPI startup(): Reduce: 9: 8193-16384 & 0-4\n",
      "[0] MPI startup(): Reduce: 3: 16385-41104 & 0-4\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 5-8\n",
      "[0] MPI startup(): Reduce: 9: 1-32 & 5-8\n",
      "[0] MPI startup(): Reduce: 8: 33-64 & 5-8\n",
      "[0] MPI startup(): Reduce: 9: 65-341 & 5-8\n",
      "[0] MPI startup(): Reduce: 11: 342-512 & 5-8\n",
      "[0] MPI startup(): Reduce: 8: 513-1024 & 5-8\n",
      "[0] MPI startup(): Reduce: 9: 1025-10669 & 5-8\n",
      "[0] MPI startup(): Reduce: 7: 10670-31684 & 5-8\n",
      "[0] MPI startup(): Reduce: 3: 31685-80806 & 5-8\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Reduce: 7: 1-8192 & 9-16\n",
      "[0] MPI startup(): Reduce: 10: 8193-16384 & 9-16\n",
      "[0] MPI startup(): Reduce: 5: 16385-72453 & 9-16\n",
      "[0] MPI startup(): Reduce: 3: 72454-139086 & 9-16\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Reduce: 10: 1-903 & 17-32\n",
      "[0] MPI startup(): Reduce: 8: 904-1024 & 17-32\n",
      "[0] MPI startup(): Reduce: 10: 1025-2048 & 17-32\n",
      "[0] MPI startup(): Reduce: 8: 2049-4096 & 17-32\n",
      "[0] MPI startup(): Reduce: 9: 4097-16384 & 17-32\n",
      "[0] MPI startup(): Reduce: 5: 16385-137084 & 17-32\n",
      "[0] MPI startup(): Reduce: 3: 137085-443433 & 17-32\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 33-64\n",
      "[0] MPI startup(): Reduce: 7: 1-2048 & 33-64\n",
      "[0] MPI startup(): Reduce: 10: 2049-16384 & 33-64\n",
      "[0] MPI startup(): Reduce: 5: 16385-197019 & 33-64\n",
      "[0] MPI startup(): Reduce: 3: 197020-833161 & 33-64\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Reduce: 1: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 1-4 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 8: 5-8 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 9-219 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 10: 220-275 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 276-512 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 10: 513-1024 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 1025-2048 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 10: 2049-4096 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 11: 4097-8703 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 8: 8704-16384 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 5: 16385-274440 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 3: 274441-1539469 & 65-2147483647\n",
      "[0] MPI startup(): Reduce: 1: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Scan: 0: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Scatter: 3: 0-12 & 0-4\n",
      "[0] MPI startup(): Scatter: 1: 13-22 & 0-4\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 0-4\n",
      "[0] MPI startup(): Scatter: 3: 0-0 & 5-8\n",
      "[0] MPI startup(): Scatter: 2: 1-4 & 5-8\n",
      "[0] MPI startup(): Scatter: 3: 5-12 & 5-8\n",
      "[0] MPI startup(): Scatter: 2: 13-34 & 5-8\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 5-8\n",
      "[0] MPI startup(): Scatter: 1: 0-0 & 9-16\n",
      "[0] MPI startup(): Scatter: 2: 1-40 & 9-16\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 9-16\n",
      "[0] MPI startup(): Scatter: 1: 0-0 & 17-32\n",
      "[0] MPI startup(): Scatter: 2: 1-42 & 17-32\n",
      "[0] MPI startup(): Scatter: 3: 43-64 & 17-32\n",
      "[0] MPI startup(): Scatter: 1: 65-128 & 17-32\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 17-32\n",
      "[0] MPI startup(): Scatter: 2: 0-4 & 33-64\n",
      "[0] MPI startup(): Scatter: 1: 5-8 & 33-64\n",
      "[0] MPI startup(): Scatter: 2: 9-34 & 33-64\n",
      "[0] MPI startup(): Scatter: 1: 35-1802 & 33-64\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 33-64\n",
      "[0] MPI startup(): Scatter: 2: 0-0 & 65-2147483647\n",
      "[0] MPI startup(): Scatter: 1: 1-15495 & 65-2147483647\n",
      "[0] MPI startup(): Scatter: 3: 0-2147483647 & 65-2147483647\n",
      "[0] MPI startup(): Scatterv: 1: 0-2147483647 & 0-2147483647\n",
      "[0] MPI startup(): Rank    Pid      Node name                               Pin cpu\n",
      "[0] MPI startup(): 0       900      060fc13d0cef4fafbcbda63b7964fa69000000  {0,1,2,3,4,5,6,7,8,9,10,11}\n",
      "[0] MPI startup(): 1       901      060fc13d0cef4fafbcbda63b7964fa69000000  {12,13,14,15,16,17,18,19,20,21,22,23}\n",
      "[0] MPI startup(): Recognition=2 Platform(code=128 ippn=1 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[1] MPI startup(): Recognition=2 Platform(code=128 ippn=1 dev=3) Fabric(intra=4 inter=4 flags=0x0)\n",
      "[0] MPI startup(): I_MPI_DAPL_PROVIDER=ofa-v2-ib0\n",
      "[0] MPI startup(): I_MPI_DEBUG=6\n",
      "[0] MPI startup(): I_MPI_DYNAMIC_CONNECTION=0\n",
      "[0] MPI startup(): I_MPI_FABRICS=dapl\n",
      "[0] MPI startup(): I_MPI_INFO_NUMA_NODE_MAP=mlx4_0:-1\n",
      "[0] MPI startup(): I_MPI_INFO_NUMA_NODE_NUM=2\n",
      "[0] MPI startup(): I_MPI_PIN_MAPPING=2:0 0,1 12\n",
      "INFO:__main__:0:  Runnin Distributed\n",
      "INFO:__main__:0:  Tensorflow version 1.9.0\n",
      "INFO:__main__:0:  Reading training data info\n",
      "INFO:__main__:1:  Runnin Distributed\n",
      "INFO:__main__:1:  Tensorflow version 1.9.0\n",
      "INFO:__main__:1:  Reading training data info\n",
      "INFO:__main__:1:  Reading validation data info\n",
      "INFO:__main__:0:  Reading validation data info\n",
      "INFO:__main__:1:  Creating estimator with params: {'classes': 1000, 'learning_rate': 0.001}\n",
      "INFO:__main__:0:  Creating estimator with params: {'learning_rate': 0.001, 'classes': 1000}\n",
      "Using config: {'_save_checkpoints_steps': None, '_service': None, '_master': '', '_device_fn': None, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_task_type': 'worker', '_is_chief': True, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"1\"\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc6252dfc88>, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': None}\n",
      "Using config: {'_save_checkpoints_secs': None, '_save_summary_steps': 100, '_train_distribute': None, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_model_dir': '/mnt/batch/tasks/shared/LS_root/mounts/extfs/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/outputs/Models', '_task_type': 'worker', '_num_ps_replicas': 0, '_service': None, '_device_fn': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "}\n",
      ", '_task_id': 0, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2b07c5f828>, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_steps': None, '_is_chief': True, '_master': ''}\n",
      "INFO:__main__:1:  Rank: 1 Cluster Size 2\n",
      "INFO:__main__:1:  Training...\n",
      "INFO:__main__:0:  Rank: 0 Cluster Size 2\n",
      "INFO:__main__:0:  Training...\n",
      "Calling model_fn.\n",
      "INFO:__main__:0:  Creating model in train mode\n",
      "Calling model_fn.\n",
      "INFO:__main__:1:  Creating model in train mode\n",
      "Done calling model_fn.\n",
      "Done calling model_fn.\n",
      "Graph was finalized.\n",
      "Graph was finalized.\n",
      "Running local_init_op.\n",
      "Running local_init_op.\n",
      "Done running local_init_op.\n",
      "Done running local_init_op.\n",
      "loss = 7.0434036, step = 0\n",
      "loss = 7.0467443, step = 0\n",
      "global_step/sec: 2.10974\n",
      "loss = 1.505756, step = 100 (47.400 sec)\n",
      "global_step/sec: 2.11012\n",
      "loss = 1.5710309, step = 100 (47.391 sec)\n",
      "global_step/sec: 3.70436\n",
      "loss = 1.6848712, step = 200 (26.995 sec)\n",
      "global_step/sec: 3.70432\n",
      "loss = 1.1104316, step = 200 (26.996 sec)\n",
      "global_step/sec: 4.28741\n",
      "loss = 4.104802, step = 300 (23.324 sec)\n",
      "global_step/sec: 4.28808\n",
      "loss = 3.0557795, step = 300 (23.549 sec)\n",
      "global_step/sec: 4.14884\n",
      "global_step/sec: 4.14846\n",
      "loss = 3.620397, step = 400 (23.874 sec)\n",
      "loss = 3.6067135, step = 400 (24.105 sec)\n",
      "global_step/sec: 4.55797\n",
      "loss = 4.9604735, step = 500 (21.939 sec)\n",
      "global_step/sec: 4.55723\n",
      "loss = 5.568121, step = 500 (21.943 sec)\n",
      "global_step/sec: 4.48824\n",
      "global_step/sec: 4.4875\n",
      "loss = 5.5936565, step = 600 (22.280 sec)\n",
      "loss = 5.43467, step = 600 (22.285 sec)\n",
      "global_step/sec: 4.44318\n",
      "global_step/sec: 4.44319\n",
      "loss = 4.5918245, step = 700 (22.505 sec)\n",
      "loss = 4.28307, step = 700 (22.507 sec)\n",
      "global_step/sec: 4.42472\n",
      "loss = 4.756772, step = 800 (22.600 sec)\n",
      "global_step/sec: 4.42436\n",
      "loss = 4.5693073, step = 800 (22.602 sec)\n",
      "global_step/sec: 4.44651\n",
      "loss = 5.665137, step = 900 (22.490 sec)\n",
      "global_step/sec: 4.44629\n",
      "loss = 5.3247557, step = 900 (22.723 sec)\n",
      "global_step/sec: 4.34372\n",
      "loss = 5.4585023, step = 1000 (23.022 sec)\n",
      "global_step/sec: 4.34293\n",
      "loss = 5.489979, step = 1000 (22.794 sec)\n",
      "global_step/sec: 4.46399\n",
      "loss = 4.946332, step = 1100 (22.401 sec)\n",
      "global_step/sec: 4.4623\n",
      "loss = 5.241954, step = 1100 (22.410 sec)\n",
      "global_step/sec: 4.41102\n",
      "loss = 5.372737, step = 1200 (22.670 sec)\n",
      "global_step/sec: 4.40961\n",
      "loss = 5.512772, step = 1200 (22.678 sec)\n",
      "global_step/sec: 4.48382\n",
      "loss = 5.439809, step = 1300 (22.302 sec)\n",
      "global_step/sec: 4.48185\n",
      "loss = 5.580116, step = 1300 (22.312 sec)\n",
      "global_step/sec: 4.42846\n",
      "loss = 5.6808023, step = 1400 (22.581 sec)\n",
      "global_step/sec: 4.4289\n",
      "loss = 5.6941786, step = 1400 (22.579 sec)\n",
      "global_step/sec: 4.44934\n",
      "loss = 5.094384, step = 1500 (22.475 sec)\n",
      "global_step/sec: 4.44755\n",
      "loss = 5.0762644, step = 1500 (22.706 sec)\n",
      "global_step/sec: 4.4263\n",
      "loss = 5.0993996, step = 1600 (22.592 sec)\n",
      "global_step/sec: 4.42639\n",
      "loss = 5.3733463, step = 1600 (22.370 sec)\n",
      "global_step/sec: 4.48026\n",
      "global_step/sec: 4.4809\n",
      "loss = 5.6711645, step = 1700 (22.320 sec)\n",
      "loss = 5.407062, step = 1700 (22.317 sec)\n",
      "global_step/sec: 4.37322\n",
      "loss = 5.165067, step = 1800 (22.866 sec)\n",
      "global_step/sec: 4.37297\n",
      "loss = 5.251631, step = 1800 (22.868 sec)\n",
      "global_step/sec: 4.43824\n",
      "loss = 5.3209233, step = 1900 (22.531 sec)\n",
      "global_step/sec: 4.43787\n",
      "loss = 5.2511463, step = 1900 (22.534 sec)\n",
      "global_step/sec: 4.35072\n",
      "global_step/sec: 4.35084\n",
      "loss = 5.568375, step = 2000 (22.985 sec)\n",
      "loss = 5.168417, step = 2000 (22.984 sec)\n",
      "global_step/sec: 4.47306\n",
      "loss = 5.7722635, step = 2100 (22.356 sec)\n",
      "global_step/sec: 4.47304\n",
      "loss = 5.2816057, step = 2100 (22.612 sec)\n",
      "global_step/sec: 4.3529\n",
      "global_step/sec: 4.35295\n",
      "loss = 5.571311, step = 2200 (22.973 sec)\n",
      "loss = 5.7755055, step = 2200 (22.717 sec)\n",
      "global_step/sec: 4.24574\n",
      "global_step/sec: 4.24575\n",
      "loss = 5.7421923, step = 2300 (23.553 sec)\n",
      "loss = 5.870731, step = 2300 (23.553 sec)\n",
      "global_step/sec: 4.3543\n",
      "loss = 5.9818096, step = 2400 (22.965 sec)\n",
      "global_step/sec: 4.35383\n",
      "loss = 5.510818, step = 2400 (22.968 sec)\n",
      "global_step/sec: 4.30912\n",
      "global_step/sec: 4.30865\n",
      "loss = 6.0613894, step = 2500 (23.207 sec)\n",
      "loss = 5.890982, step = 2500 (23.209 sec)\n",
      "global_step/sec: 4.26984\n",
      "loss = 5.4658556, step = 2600 (23.420 sec)\n",
      "global_step/sec: 4.26978\n",
      "loss = 5.7245274, step = 2600 (23.421 sec)\n",
      "global_step/sec: 4.34153\n",
      "loss = 5.7663054, step = 2700 (23.033 sec)\n",
      "global_step/sec: 4.34143\n",
      "loss = 5.5922875, step = 2700 (23.280 sec)\n",
      "global_step/sec: 4.27289\n",
      "global_step/sec: 4.27279\n",
      "loss = 5.7702684, step = 2800 (23.157 sec)\n",
      "loss = 5.882741, step = 2800 (23.404 sec)\n",
      "global_step/sec: 4.3015\n",
      "global_step/sec: 4.30142\n",
      "loss = 5.534139, step = 2900 (23.248 sec)\n",
      "loss = 5.5105557, step = 2900 (23.248 sec)\n",
      "global_step/sec: 4.27993\n",
      "global_step/sec: 4.2799\n",
      "loss = 5.6503873, step = 3000 (23.365 sec)\n",
      "loss = 5.9493866, step = 3000 (23.365 sec)\n",
      "global_step/sec: 4.2337\n",
      "global_step/sec: 4.23371\n",
      "loss = 5.470111, step = 3100 (23.620 sec)\n",
      "loss = 5.572877, step = 3100 (23.620 sec)\n",
      "global_step/sec: 4.27893\n",
      "loss = 6.0152054, step = 3200 (23.371 sec)\n",
      "global_step/sec: 4.27783\n",
      "loss = 6.0032344, step = 3200 (23.378 sec)\n",
      "global_step/sec: 4.2875\n",
      "loss = 5.5414686, step = 3300 (23.322 sec)\n",
      "global_step/sec: 4.28656\n",
      "loss = 5.405508, step = 3300 (23.558 sec)\n",
      "global_step/sec: 4.20706\n",
      "loss = 5.7304864, step = 3400 (23.540 sec)\n",
      "global_step/sec: 4.20705\n",
      "loss = 5.7913055, step = 3400 (23.769 sec)\n",
      "global_step/sec: 4.34269\n",
      "global_step/sec: 4.34288\n",
      "loss = 5.579653, step = 3500 (23.027 sec)\n",
      "loss = 5.89927, step = 3500 (23.026 sec)\n",
      "global_step/sec: 4.20234\n",
      "loss = 5.762496, step = 3600 (23.796 sec)\n",
      "global_step/sec: 4.20128\n",
      "loss = 5.4297433, step = 3600 (23.802 sec)\n",
      "global_step/sec: 4.29182\n",
      "global_step/sec: 4.29294\n",
      "loss = 5.886033, step = 3700 (23.300 sec)\n",
      "loss = 5.794219, step = 3700 (23.294 sec)\n",
      "global_step/sec: 4.24898\n",
      "global_step/sec: 4.24898\n",
      "loss = 5.538507, step = 3800 (23.535 sec)\n",
      "loss = 5.7740374, step = 3800 (23.535 sec)\n",
      "global_step/sec: 4.22896\n",
      "loss = 5.920272, step = 3900 (23.646 sec)\n",
      "global_step/sec: 4.22897\n",
      "loss = 5.880265, step = 3900 (23.875 sec)\n",
      "global_step/sec: 4.19801\n",
      "global_step/sec: 4.19796\n",
      "loss = 6.1412444, step = 4000 (23.821 sec)\n",
      "loss = 6.0881186, step = 4000 (23.593 sec)\n",
      "global_step/sec: 4.25476\n",
      "loss = 6.0858345, step = 4100 (23.503 sec)\n",
      "global_step/sec: 4.2534\n",
      "loss = 5.965233, step = 4100 (23.526 sec)\n",
      "global_step/sec: 4.28249\n",
      "global_step/sec: 4.2838\n",
      "loss = 5.845398, step = 4200 (23.350 sec)\n",
      "loss = 5.9808297, step = 4200 (23.328 sec)\n",
      "global_step/sec: 4.28379\n",
      "global_step/sec: 4.28379\n",
      "loss = 5.886545, step = 4300 (23.344 sec)\n",
      "loss = 5.891184, step = 4300 (23.344 sec)\n",
      "global_step/sec: 4.23079\n",
      "global_step/sec: 4.23082\n",
      "loss = 5.6109176, step = 4400 (23.636 sec)\n",
      "loss = 5.6397867, step = 4400 (23.636 sec)\n",
      "global_step/sec: 4.28899\n",
      "loss = 5.729904, step = 4500 (23.316 sec)\n",
      "global_step/sec: 4.28899\n",
      "loss = 5.452046, step = 4500 (23.703 sec)\n",
      "global_step/sec: 4.20165\n",
      "global_step/sec: 4.20161\n",
      "loss = 5.492218, step = 4600 (23.412 sec)\n",
      "loss = 5.8150797, step = 4600 (23.800 sec)\n",
      "global_step/sec: 4.24863\n",
      "global_step/sec: 4.24859\n",
      "loss = 6.0309277, step = 4700 (23.537 sec)\n",
      "loss = 5.961488, step = 4700 (23.537 sec)\n",
      "global_step/sec: 4.27274\n",
      "global_step/sec: 4.27259\n",
      "loss = 6.0306954, step = 4800 (23.404 sec)\n",
      "loss = 5.8709097, step = 4800 (23.405 sec)\n",
      "global_step/sec: 4.22989\n",
      "global_step/sec: 4.22995\n",
      "loss = 5.7852736, step = 4900 (23.641 sec)\n",
      "loss = 6.110596, step = 4900 (23.641 sec)\n",
      "global_step/sec: 4.22852\n",
      "global_step/sec: 4.22847\n",
      "loss = 5.7312374, step = 5000 (23.649 sec)\n",
      "loss = 5.9515185, step = 5000 (23.649 sec)\n",
      "global_step/sec: 4.2588\n",
      "loss = 5.7105303, step = 5100 (23.481 sec)\n",
      "global_step/sec: 4.25887\n",
      "loss = 5.913477, step = 5100 (23.738 sec)\n",
      "global_step/sec: 4.11038\n",
      "global_step/sec: 4.11032\n",
      "loss = 6.18524, step = 5200 (24.329 sec)\n",
      "loss = 6.3072157, step = 5200 (24.071 sec)\n",
      "global_step/sec: 4.24563\n",
      "global_step/sec: 4.24472\n",
      "loss = 5.705654, step = 5300 (23.559 sec)\n",
      "loss = 5.730936, step = 5300 (23.561 sec)\n",
      "global_step/sec: 4.22294\n",
      "global_step/sec: 4.22196\n",
      "loss = 5.6705637, step = 5400 (23.678 sec)\n",
      "loss = 5.68605, step = 5400 (23.682 sec)\n",
      "global_step/sec: 4.21515\n",
      "global_step/sec: 4.21503\n",
      "loss = 5.686718, step = 5500 (23.724 sec)\n",
      "loss = 5.8512697, step = 5500 (23.723 sec)\n",
      "global_step/sec: 4.21878\n",
      "global_step/sec: 4.21878\n",
      "loss = 5.8658605, step = 5600 (23.703 sec)\n",
      "loss = 5.526469, step = 5600 (23.704 sec)\n",
      "global_step/sec: 4.18527\n",
      "loss = 5.6964664, step = 5700 (23.893 sec)\n",
      "global_step/sec: 4.18515\n",
      "loss = 5.8900456, step = 5700 (24.150 sec)\n",
      "global_step/sec: 4.26719\n",
      "global_step/sec: 4.26707\n",
      "loss = 5.692251, step = 5800 (23.179 sec)\n",
      "loss = 5.280491, step = 5800 (23.435 sec)\n",
      "global_step/sec: 4.3069\n",
      "global_step/sec: 4.30691\n",
      "loss = 5.810165, step = 5900 (23.218 sec)\n",
      "loss = 5.884845, step = 5900 (23.218 sec)\n",
      "global_step/sec: 4.20168\n",
      "loss = 5.9490495, step = 6000 (23.800 sec)\n",
      "global_step/sec: 4.20143\n",
      "loss = 6.1328444, step = 6000 (23.801 sec)\n",
      "global_step/sec: 4.24061\n",
      "global_step/sec: 4.24031\n",
      "loss = 6.218255, step = 6100 (23.581 sec)\n",
      "loss = 6.3052893, step = 6100 (23.583 sec)\n",
      "global_step/sec: 4.23196\n",
      "global_step/sec: 4.23195\n",
      "loss = 6.208642, step = 6200 (23.630 sec)\n",
      "loss = 6.142722, step = 6200 (23.630 sec)\n",
      "global_step/sec: 4.22055\n",
      "loss = 6.0383034, step = 6300 (23.694 sec)\n",
      "global_step/sec: 4.22034\n",
      "loss = 6.253669, step = 6300 (23.971 sec)\n",
      "global_step/sec: 4.15905\n",
      "global_step/sec: 4.15916\n",
      "loss = 6.2223263, step = 6400 (24.044 sec)\n",
      "loss = 6.2235537, step = 6400 (23.768 sec)\n",
      "global_step/sec: 4.19479\n",
      "loss = 6.1014314, step = 6500 (23.839 sec)\n",
      "global_step/sec: 4.19454\n",
      "loss = 6.16918, step = 6500 (23.841 sec)\n",
      "global_step/sec: 4.24879\n",
      "loss = 5.6949534, step = 6600 (23.536 sec)\n",
      "global_step/sec: 4.24765\n",
      "loss = 5.772238, step = 6600 (23.542 sec)\n",
      "global_step/sec: 4.23064\n",
      "loss = 5.8458223, step = 6700 (23.637 sec)\n",
      "global_step/sec: 4.23064\n",
      "loss = 5.4713826, step = 6700 (23.638 sec)\n",
      "global_step/sec: 4.28233\n",
      "global_step/sec: 4.28326\n",
      "loss = 5.9524417, step = 6800 (23.352 sec)\n",
      "loss = 5.7287397, step = 6800 (23.345 sec)\n",
      "global_step/sec: 4.24159\n",
      "loss = 6.0005713, step = 6900 (23.576 sec)\n",
      "global_step/sec: 4.24166\n",
      "loss = 5.787831, step = 6900 (23.848 sec)\n",
      "global_step/sec: 4.10633\n",
      "global_step/sec: 4.10635\n",
      "loss = 6.1037507, step = 7000 (24.081 sec)\n",
      "loss = 5.998364, step = 7000 (24.352 sec)\n",
      "global_step/sec: 4.2439\n",
      "global_step/sec: 4.24381\n",
      "loss = 5.8528147, step = 7100 (23.563 sec)\n",
      "loss = 5.772395, step = 7100 (23.564 sec)\n",
      "global_step/sec: 4.27454\n",
      "global_step/sec: 4.27446\n",
      "loss = 5.727265, step = 7200 (23.394 sec)\n",
      "loss = 5.940016, step = 7200 (23.395 sec)\n",
      "global_step/sec: 4.23895\n",
      "global_step/sec: 4.23898\n",
      "loss = 6.198329, step = 7300 (23.591 sec)\n",
      "loss = 5.7052355, step = 7300 (23.591 sec)\n",
      "global_step/sec: 4.27019\n",
      "global_step/sec: 4.27015\n",
      "loss = 6.5912313, step = 7400 (23.418 sec)\n",
      "loss = 6.43095, step = 7400 (23.418 sec)\n",
      "global_step/sec: 4.1321\n",
      "loss = 6.151272, step = 7500 (24.201 sec)\n",
      "global_step/sec: 4.13277\n",
      "loss = 5.92468, step = 7500 (24.477 sec)\n",
      "global_step/sec: 4.17746\n",
      "global_step/sec: 4.1768\n",
      "loss = 6.2712336, step = 7600 (23.938 sec)\n",
      "loss = 6.205436, step = 7600 (23.661 sec)\n",
      "global_step/sec: 4.23828\n",
      "global_step/sec: 4.2383\n",
      "loss = 6.0196495, step = 7700 (23.594 sec)\n",
      "loss = 6.0562906, step = 7700 (23.594 sec)\n",
      "global_step/sec: 4.12778\n",
      "global_step/sec: 4.12776\n",
      "loss = 6.262889, step = 7800 (24.226 sec)\n",
      "loss = 6.2666864, step = 7800 (24.226 sec)\n",
      "global_step/sec: 4.17748\n",
      "global_step/sec: 4.17742\n",
      "loss = 6.415777, step = 7900 (23.938 sec)\n",
      "loss = 6.326841, step = 7900 (23.938 sec)\n",
      "global_step/sec: 4.13385\n",
      "global_step/sec: 4.1339\n",
      "loss = 6.5520725, step = 8000 (24.191 sec)\n",
      "loss = 6.3761587, step = 8000 (24.190 sec)\n",
      "global_step/sec: 4.22653\n",
      "loss = 6.435708, step = 8100 (23.660 sec)\n",
      "global_step/sec: 4.22654\n",
      "loss = 6.4204583, step = 8100 (23.923 sec)\n",
      "global_step/sec: 4.21681\n",
      "global_step/sec: 4.21676\n",
      "loss = 6.3785133, step = 8200 (23.451 sec)\n",
      "loss = 6.4873476, step = 8200 (23.715 sec)\n",
      "global_step/sec: 4.19396\n",
      "global_step/sec: 4.19397\n",
      "loss = 6.4465623, step = 8300 (23.844 sec)\n",
      "loss = 6.6333513, step = 8300 (23.844 sec)\n",
      "global_step/sec: 4.17153\n",
      "global_step/sec: 4.17152\n",
      "loss = 6.6143737, step = 8400 (23.972 sec)\n",
      "loss = 6.7397676, step = 8400 (23.972 sec)\n",
      "global_step/sec: 4.24007\n",
      "global_step/sec: 4.2401\n",
      "loss = 6.6237907, step = 8500 (23.584 sec)\n",
      "loss = 6.6384687, step = 8500 (23.584 sec)\n",
      "global_step/sec: 4.18624\n",
      "global_step/sec: 4.18619\n",
      "loss = 6.6748905, step = 8600 (23.888 sec)\n",
      "loss = 6.5936966, step = 8600 (23.888 sec)\n",
      "global_step/sec: 4.18472\n",
      "loss = 6.8372555, step = 8700 (23.897 sec)\n",
      "global_step/sec: 4.18478\n",
      "loss = 6.6861677, step = 8700 (24.227 sec)\n",
      "global_step/sec: 4.09588\n",
      "global_step/sec: 4.09588\n",
      "loss = 6.766254, step = 8800 (24.084 sec)\n",
      "loss = 6.788624, step = 8800 (24.415 sec)\n",
      "global_step/sec: 4.2514\n",
      "loss = 6.752, step = 8900 (23.522 sec)\n",
      "global_step/sec: 4.25116\n",
      "loss = 6.8271656, step = 8900 (23.523 sec)\n",
      "global_step/sec: 4.22232\n",
      "global_step/sec: 4.2221\n",
      "loss = 6.793917, step = 9000 (23.684 sec)\n",
      "loss = 6.82543, step = 9000 (23.685 sec)\n",
      "global_step/sec: 4.184\n",
      "global_step/sec: 4.18394\n",
      "loss = 6.856535, step = 9100 (23.901 sec)\n",
      "loss = 6.849081, step = 9100 (23.901 sec)\n",
      "global_step/sec: 4.24788\n",
      "global_step/sec: 4.24779\n",
      "loss = 6.8662357, step = 9200 (23.541 sec)\n",
      "loss = 6.8298883, step = 9200 (23.542 sec)\n",
      "global_step/sec: 4.14205\n",
      "loss = 6.8107576, step = 9300 (24.143 sec)\n",
      "global_step/sec: 4.14199\n",
      "loss = 6.878744, step = 9300 (24.338 sec)\n",
      "global_step/sec: 4.13594\n",
      "global_step/sec: 4.13588\n",
      "loss = 6.7419662, step = 9400 (23.983 sec)\n",
      "loss = 6.801876, step = 9400 (24.179 sec)\n",
      "global_step/sec: 4.2706\n",
      "global_step/sec: 4.27055\n",
      "loss = 6.6563873, step = 9500 (23.416 sec)\n",
      "loss = 6.501853, step = 9500 (23.416 sec)\n",
      "global_step/sec: 4.16974\n",
      "global_step/sec: 4.16975\n",
      "loss = 5.854846, step = 9600 (23.982 sec)\n",
      "loss = 5.8051686, step = 9600 (23.982 sec)\n",
      "global_step/sec: 4.23531\n",
      "global_step/sec: 4.2353\n",
      "loss = 5.3273478, step = 9700 (23.611 sec)\n",
      "loss = 5.0454397, step = 9700 (23.611 sec)\n",
      "global_step/sec: 4.21026\n",
      "global_step/sec: 4.21025\n",
      "loss = 5.720562, step = 9800 (23.751 sec)\n",
      "loss = 5.48579, step = 9800 (23.752 sec)\n",
      "global_step/sec: 4.22416\n",
      "loss = 5.306076, step = 9900 (23.674 sec)\n",
      "global_step/sec: 4.22416\n",
      "loss = 6.2421856, step = 9900 (23.897 sec)\n",
      "global_step/sec: 4.21468\n",
      "global_step/sec: 4.21464\n",
      "loss = 5.432027, step = 10000 (23.726 sec)\n",
      "loss = 5.757989, step = 10000 (23.503 sec)\n",
      "Loss for final step: 5.942581.\n",
      "INFO:__main__:1:  Training took 2428.790 seconds\n",
      "INFO:__main__:1:  Data length:      1281167\n",
      "INFO:__main__:1:  Total duration:   2428.790\n",
      "INFO:__main__:1:  Total images/sec: 527.492\n",
      "INFO:__main__:1:  Batch size:       (Per GPU 64: Total 128)\n",
      "INFO:__main__:1:  Distributed:      True\n",
      "INFO:__main__:1:  Num GPUs:         2.000\n",
      "INFO:__main__:1:  Dataset:          Imagenet\n",
      "Loss for final step: 6.1382895.\n",
      "INFO:__main__:0:  Training took 2429.050 seconds\n",
      "INFO:__main__:0:  Data length:      1281167\n",
      "INFO:__main__:0:  Total duration:   2429.050\n",
      "INFO:__main__:0:  Total images/sec: 527.435\n",
      "INFO:__main__:0:  Batch size:       (Per GPU 64: Total 128)\n",
      "INFO:__main__:0:  Distributed:      True\n",
      "INFO:__main__:0:  Num GPUs:         2.000\n",
      "INFO:__main__:0:  Dataset:          Imagenet\n"
     ]
    }
   ],
   "source": [
    "!az batchai job file stream -w $WORKSPACE -e $EXPERIMENT --j $JOB_NAME --output-directory-id stdouterr -f stdout.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFile found with URL \"https://batchddtfst.file.core.windows.net/batchddtfshare/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/stdouterr/stderr.txt?sv=2016-05-31&sr=f&sig=XukVGrYD3NYPMTbk6IZ5Vs1IV%2Bwi%2BiF8ckg4COBvf2s%3D&se=2018-08-09T12%3A43%3A43Z&sp=rl\". Start streaming\u001b[0m\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_service': None, '_master': '', '_device_fn': None, '_model_dir': '/mnt/batch/tasks/shared/LS_root/jobs/workspace/distributed_tensorflow_v100/tf-horovod-8/wd', '_task_type': 'worker', '_is_chief': True, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"1\"\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc6252dfc88>, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': None}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_save_summary_steps': 100, '_train_distribute': None, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_model_dir': '/mnt/batch/tasks/shared/LS_root/mounts/extfs/edf507a2-6235-46c5-b560-fd463ba2e771/batchddtfrg/workspaces/workspace/experiments/distributed_tensorflow_v100/jobs/tf-horovod-8/2b7d405f-f071-4050-a1a5-06337ac315b4/outputs/Models', '_task_type': 'worker', '_num_ps_replicas': 0, '_service': None, '_device_fn': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "}\n",
      ", '_task_id': 0, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2b07c5f828>, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_steps': None, '_is_chief': True, '_master': ''}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-09 10:17:52.563263: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-08-09 10:17:52.739774: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-08-09 10:17:52.992018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: cf11:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.35GiB\n",
      "2018-08-09 10:17:52.992076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 1\n",
      "2018-08-09 10:17:53.299341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: bc76:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.35GiB\n",
      "2018-08-09 10:17:53.299395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n",
      "2018-08-09 10:17:53.365659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-09 10:17:53.365738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      1 \n",
      "2018-08-09 10:17:53.365751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N \n",
      "2018-08-09 10:17:53.366066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-16GB, pci bus id: cf11:00:00.0, compute capability: 7.0)\n",
      "2018-08-09 10:17:53.537432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-09 10:17:53.537507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n",
      "2018-08-09 10:17:53.537520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n",
      "2018-08-09 10:17:53.537820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: bc76:00:00.0, compute capability: 7.0)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:loss = 7.0434036, step = 0\n",
      "INFO:tensorflow:loss = 7.0467443, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.10974\n",
      "INFO:tensorflow:loss = 1.505756, step = 100 (47.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.11012\n",
      "INFO:tensorflow:loss = 1.5710309, step = 100 (47.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.70436\n",
      "INFO:tensorflow:loss = 1.6848712, step = 200 (26.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.70432\n",
      "INFO:tensorflow:loss = 1.1104316, step = 200 (26.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28741\n",
      "INFO:tensorflow:loss = 4.104802, step = 300 (23.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28808\n",
      "INFO:tensorflow:loss = 3.0557795, step = 300 (23.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.14884\n",
      "INFO:tensorflow:global_step/sec: 4.14846\n",
      "INFO:tensorflow:loss = 3.620397, step = 400 (23.874 sec)\n",
      "INFO:tensorflow:loss = 3.6067135, step = 400 (24.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55797\n",
      "INFO:tensorflow:loss = 4.9604735, step = 500 (21.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55723\n",
      "INFO:tensorflow:loss = 5.568121, step = 500 (21.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4875\n",
      "INFO:tensorflow:global_step/sec: 4.48824\n",
      "INFO:tensorflow:loss = 5.5936565, step = 600 (22.280 sec)\n",
      "INFO:tensorflow:loss = 5.43467, step = 600 (22.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44318\n",
      "INFO:tensorflow:global_step/sec: 4.44319\n",
      "INFO:tensorflow:loss = 4.5918245, step = 700 (22.505 sec)\n",
      "INFO:tensorflow:loss = 4.28307, step = 700 (22.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42472\n",
      "INFO:tensorflow:loss = 4.756772, step = 800 (22.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42436\n",
      "INFO:tensorflow:loss = 4.5693073, step = 800 (22.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44629\n",
      "INFO:tensorflow:global_step/sec: 4.44651\n",
      "INFO:tensorflow:loss = 5.665137, step = 900 (22.490 sec)\n",
      "INFO:tensorflow:loss = 5.3247557, step = 900 (22.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34372\n",
      "INFO:tensorflow:loss = 5.4585023, step = 1000 (23.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34293\n",
      "INFO:tensorflow:loss = 5.489979, step = 1000 (22.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46399\n",
      "INFO:tensorflow:loss = 4.946332, step = 1100 (22.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4623\n",
      "INFO:tensorflow:loss = 5.241954, step = 1100 (22.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41102\n",
      "INFO:tensorflow:loss = 5.372737, step = 1200 (22.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40961\n",
      "INFO:tensorflow:loss = 5.512772, step = 1200 (22.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48382\n",
      "INFO:tensorflow:loss = 5.439809, step = 1300 (22.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48185\n",
      "INFO:tensorflow:loss = 5.580116, step = 1300 (22.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42846\n",
      "INFO:tensorflow:loss = 5.6808023, step = 1400 (22.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4289\n",
      "INFO:tensorflow:loss = 5.6941786, step = 1400 (22.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44934\n",
      "INFO:tensorflow:loss = 5.094384, step = 1500 (22.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44755\n",
      "INFO:tensorflow:loss = 5.0762644, step = 1500 (22.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4263\n",
      "INFO:tensorflow:loss = 5.0993996, step = 1600 (22.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42639\n",
      "INFO:tensorflow:loss = 5.3733463, step = 1600 (22.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48026\n",
      "INFO:tensorflow:global_step/sec: 4.4809\n",
      "INFO:tensorflow:loss = 5.6711645, step = 1700 (22.320 sec)\n",
      "INFO:tensorflow:loss = 5.407062, step = 1700 (22.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37322\n",
      "INFO:tensorflow:loss = 5.165067, step = 1800 (22.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37297\n",
      "INFO:tensorflow:loss = 5.251631, step = 1800 (22.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43824\n",
      "INFO:tensorflow:loss = 5.3209233, step = 1900 (22.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43787\n",
      "INFO:tensorflow:loss = 5.2511463, step = 1900 (22.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35072\n",
      "INFO:tensorflow:global_step/sec: 4.35084\n",
      "INFO:tensorflow:loss = 5.568375, step = 2000 (22.985 sec)\n",
      "INFO:tensorflow:loss = 5.168417, step = 2000 (22.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47306\n",
      "INFO:tensorflow:global_step/sec: 4.47304\n",
      "INFO:tensorflow:loss = 5.7722635, step = 2100 (22.356 sec)\n",
      "INFO:tensorflow:loss = 5.2816057, step = 2100 (22.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3529\n",
      "INFO:tensorflow:global_step/sec: 4.35295\n",
      "INFO:tensorflow:loss = 5.571311, step = 2200 (22.973 sec)\n",
      "INFO:tensorflow:loss = 5.7755055, step = 2200 (22.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24574\n",
      "INFO:tensorflow:global_step/sec: 4.24575\n",
      "INFO:tensorflow:loss = 5.7421923, step = 2300 (23.553 sec)\n",
      "INFO:tensorflow:loss = 5.870731, step = 2300 (23.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3543\n",
      "INFO:tensorflow:loss = 5.9818096, step = 2400 (22.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35383\n",
      "INFO:tensorflow:loss = 5.510818, step = 2400 (22.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30912\n",
      "INFO:tensorflow:global_step/sec: 4.30865\n",
      "INFO:tensorflow:loss = 6.0613894, step = 2500 (23.207 sec)\n",
      "INFO:tensorflow:loss = 5.890982, step = 2500 (23.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26984\n",
      "INFO:tensorflow:global_step/sec: 4.26978\n",
      "INFO:tensorflow:loss = 5.4658556, step = 2600 (23.420 sec)\n",
      "INFO:tensorflow:loss = 5.7245274, step = 2600 (23.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34153\n",
      "INFO:tensorflow:global_step/sec: 4.34143\n",
      "INFO:tensorflow:loss = 5.7663054, step = 2700 (23.033 sec)\n",
      "INFO:tensorflow:loss = 5.5922875, step = 2700 (23.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27289\n",
      "INFO:tensorflow:global_step/sec: 4.27279\n",
      "INFO:tensorflow:loss = 5.7702684, step = 2800 (23.157 sec)\n",
      "INFO:tensorflow:loss = 5.882741, step = 2800 (23.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3015\n",
      "INFO:tensorflow:global_step/sec: 4.30142\n",
      "INFO:tensorflow:loss = 5.534139, step = 2900 (23.248 sec)\n",
      "INFO:tensorflow:loss = 5.5105557, step = 2900 (23.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27993\n",
      "INFO:tensorflow:global_step/sec: 4.2799\n",
      "INFO:tensorflow:loss = 5.6503873, step = 3000 (23.365 sec)\n",
      "INFO:tensorflow:loss = 5.9493866, step = 3000 (23.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2337\n",
      "INFO:tensorflow:global_step/sec: 4.23371\n",
      "INFO:tensorflow:loss = 5.470111, step = 3100 (23.620 sec)\n",
      "INFO:tensorflow:loss = 5.572877, step = 3100 (23.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27893\n",
      "INFO:tensorflow:loss = 6.0152054, step = 3200 (23.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27783\n",
      "INFO:tensorflow:loss = 6.0032344, step = 3200 (23.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28656\n",
      "INFO:tensorflow:global_step/sec: 4.2875\n",
      "INFO:tensorflow:loss = 5.5414686, step = 3300 (23.322 sec)\n",
      "INFO:tensorflow:loss = 5.405508, step = 3300 (23.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20706\n",
      "INFO:tensorflow:loss = 5.7304864, step = 3400 (23.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20705\n",
      "INFO:tensorflow:loss = 5.7913055, step = 3400 (23.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34269\n",
      "INFO:tensorflow:global_step/sec: 4.34288\n",
      "INFO:tensorflow:loss = 5.579653, step = 3500 (23.027 sec)\n",
      "INFO:tensorflow:loss = 5.89927, step = 3500 (23.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20234\n",
      "INFO:tensorflow:loss = 5.762496, step = 3600 (23.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20128\n",
      "INFO:tensorflow:loss = 5.4297433, step = 3600 (23.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29182\n",
      "INFO:tensorflow:global_step/sec: 4.29294\n",
      "INFO:tensorflow:loss = 5.886033, step = 3700 (23.300 sec)\n",
      "INFO:tensorflow:loss = 5.794219, step = 3700 (23.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24898\n",
      "INFO:tensorflow:global_step/sec: 4.24898\n",
      "INFO:tensorflow:loss = 5.538507, step = 3800 (23.535 sec)\n",
      "INFO:tensorflow:loss = 5.7740374, step = 3800 (23.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22897\n",
      "INFO:tensorflow:global_step/sec: 4.22896\n",
      "INFO:tensorflow:loss = 5.920272, step = 3900 (23.646 sec)\n",
      "INFO:tensorflow:loss = 5.880265, step = 3900 (23.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.19801\n",
      "INFO:tensorflow:global_step/sec: 4.19796\n",
      "INFO:tensorflow:loss = 6.1412444, step = 4000 (23.821 sec)\n",
      "INFO:tensorflow:loss = 6.0881186, step = 4000 (23.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.25476\n",
      "INFO:tensorflow:loss = 6.0858345, step = 4100 (23.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2534\n",
      "INFO:tensorflow:loss = 5.965233, step = 4100 (23.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28249\n",
      "INFO:tensorflow:global_step/sec: 4.2838\n",
      "INFO:tensorflow:loss = 5.845398, step = 4200 (23.350 sec)\n",
      "INFO:tensorflow:loss = 5.9808297, step = 4200 (23.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28379\n",
      "INFO:tensorflow:global_step/sec: 4.28379\n",
      "INFO:tensorflow:loss = 5.886545, step = 4300 (23.344 sec)\n",
      "INFO:tensorflow:loss = 5.891184, step = 4300 (23.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23079\n",
      "INFO:tensorflow:global_step/sec: 4.23082\n",
      "INFO:tensorflow:loss = 5.6109176, step = 4400 (23.636 sec)\n",
      "INFO:tensorflow:loss = 5.6397867, step = 4400 (23.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28899\n",
      "INFO:tensorflow:global_step/sec: 4.28899\n",
      "INFO:tensorflow:loss = 5.729904, step = 4500 (23.316 sec)\n",
      "INFO:tensorflow:loss = 5.452046, step = 4500 (23.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20165\n",
      "INFO:tensorflow:global_step/sec: 4.20161\n",
      "INFO:tensorflow:loss = 5.492218, step = 4600 (23.412 sec)\n",
      "INFO:tensorflow:loss = 5.8150797, step = 4600 (23.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24863\n",
      "INFO:tensorflow:global_step/sec: 4.24859\n",
      "INFO:tensorflow:loss = 6.0309277, step = 4700 (23.537 sec)\n",
      "INFO:tensorflow:loss = 5.961488, step = 4700 (23.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27274\n",
      "INFO:tensorflow:global_step/sec: 4.27259\n",
      "INFO:tensorflow:loss = 6.0306954, step = 4800 (23.404 sec)\n",
      "INFO:tensorflow:loss = 5.8709097, step = 4800 (23.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22989\n",
      "INFO:tensorflow:global_step/sec: 4.22995\n",
      "INFO:tensorflow:loss = 5.7852736, step = 4900 (23.641 sec)\n",
      "INFO:tensorflow:loss = 6.110596, step = 4900 (23.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22852\n",
      "INFO:tensorflow:global_step/sec: 4.22847\n",
      "INFO:tensorflow:loss = 5.7312374, step = 5000 (23.649 sec)\n",
      "INFO:tensorflow:loss = 5.9515185, step = 5000 (23.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.25887\n",
      "INFO:tensorflow:global_step/sec: 4.2588\n",
      "INFO:tensorflow:loss = 5.7105303, step = 5100 (23.481 sec)\n",
      "INFO:tensorflow:loss = 5.913477, step = 5100 (23.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.11038\n",
      "INFO:tensorflow:global_step/sec: 4.11032\n",
      "INFO:tensorflow:loss = 6.18524, step = 5200 (24.329 sec)\n",
      "INFO:tensorflow:loss = 6.3072157, step = 5200 (24.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24563\n",
      "INFO:tensorflow:global_step/sec: 4.24472\n",
      "INFO:tensorflow:loss = 5.705654, step = 5300 (23.559 sec)\n",
      "INFO:tensorflow:loss = 5.730936, step = 5300 (23.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22294\n",
      "INFO:tensorflow:global_step/sec: 4.22196\n",
      "INFO:tensorflow:loss = 5.6705637, step = 5400 (23.678 sec)\n",
      "INFO:tensorflow:loss = 5.68605, step = 5400 (23.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.21515\n",
      "INFO:tensorflow:global_step/sec: 4.21503\n",
      "INFO:tensorflow:loss = 5.686718, step = 5500 (23.724 sec)\n",
      "INFO:tensorflow:loss = 5.8512697, step = 5500 (23.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.21878\n",
      "INFO:tensorflow:global_step/sec: 4.21878\n",
      "INFO:tensorflow:loss = 5.8658605, step = 5600 (23.703 sec)\n",
      "INFO:tensorflow:loss = 5.526469, step = 5600 (23.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.18527\n",
      "INFO:tensorflow:global_step/sec: 4.18515\n",
      "INFO:tensorflow:loss = 5.6964664, step = 5700 (23.893 sec)\n",
      "INFO:tensorflow:loss = 5.8900456, step = 5700 (24.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26719\n",
      "INFO:tensorflow:global_step/sec: 4.26707\n",
      "INFO:tensorflow:loss = 5.692251, step = 5800 (23.179 sec)\n",
      "INFO:tensorflow:loss = 5.280491, step = 5800 (23.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3069\n",
      "INFO:tensorflow:global_step/sec: 4.30691\n",
      "INFO:tensorflow:loss = 5.810165, step = 5900 (23.218 sec)\n",
      "INFO:tensorflow:loss = 5.884845, step = 5900 (23.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20168\n",
      "INFO:tensorflow:loss = 5.9490495, step = 6000 (23.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20143\n",
      "INFO:tensorflow:loss = 6.1328444, step = 6000 (23.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24061\n",
      "INFO:tensorflow:global_step/sec: 4.24031\n",
      "INFO:tensorflow:loss = 6.218255, step = 6100 (23.581 sec)\n",
      "INFO:tensorflow:loss = 6.3052893, step = 6100 (23.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23196\n",
      "INFO:tensorflow:global_step/sec: 4.23195\n",
      "INFO:tensorflow:loss = 6.208642, step = 6200 (23.630 sec)\n",
      "INFO:tensorflow:loss = 6.142722, step = 6200 (23.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22055\n",
      "INFO:tensorflow:loss = 6.0383034, step = 6300 (23.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22034\n",
      "INFO:tensorflow:loss = 6.253669, step = 6300 (23.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.15905\n",
      "INFO:tensorflow:global_step/sec: 4.15916\n",
      "INFO:tensorflow:loss = 6.2223263, step = 6400 (24.044 sec)\n",
      "INFO:tensorflow:loss = 6.2235537, step = 6400 (23.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.19479\n",
      "INFO:tensorflow:loss = 6.1014314, step = 6500 (23.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.19454\n",
      "INFO:tensorflow:loss = 6.16918, step = 6500 (23.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24879\n",
      "INFO:tensorflow:loss = 5.6949534, step = 6600 (23.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24765\n",
      "INFO:tensorflow:loss = 5.772238, step = 6600 (23.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23064\n",
      "INFO:tensorflow:loss = 5.8458223, step = 6700 (23.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23064\n",
      "INFO:tensorflow:loss = 5.4713826, step = 6700 (23.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28326\n",
      "INFO:tensorflow:global_step/sec: 4.28233\n",
      "INFO:tensorflow:loss = 5.7287397, step = 6800 (23.345 sec)\n",
      "INFO:tensorflow:loss = 5.9524417, step = 6800 (23.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24166\n",
      "INFO:tensorflow:global_step/sec: 4.24159\n",
      "INFO:tensorflow:loss = 6.0005713, step = 6900 (23.576 sec)\n",
      "INFO:tensorflow:loss = 5.787831, step = 6900 (23.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.10633\n",
      "INFO:tensorflow:global_step/sec: 4.10635\n",
      "INFO:tensorflow:loss = 6.1037507, step = 7000 (24.081 sec)\n",
      "INFO:tensorflow:loss = 5.998364, step = 7000 (24.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2439\n",
      "INFO:tensorflow:global_step/sec: 4.24381\n",
      "INFO:tensorflow:loss = 5.8528147, step = 7100 (23.563 sec)\n",
      "INFO:tensorflow:loss = 5.772395, step = 7100 (23.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27454\n",
      "INFO:tensorflow:global_step/sec: 4.27446\n",
      "INFO:tensorflow:loss = 5.727265, step = 7200 (23.394 sec)\n",
      "INFO:tensorflow:loss = 5.940016, step = 7200 (23.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23895\n",
      "INFO:tensorflow:global_step/sec: 4.23898\n",
      "INFO:tensorflow:loss = 6.198329, step = 7300 (23.591 sec)\n",
      "INFO:tensorflow:loss = 5.7052355, step = 7300 (23.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27019\n",
      "INFO:tensorflow:global_step/sec: 4.27015\n",
      "INFO:tensorflow:loss = 6.5912313, step = 7400 (23.418 sec)\n",
      "INFO:tensorflow:loss = 6.43095, step = 7400 (23.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.13277\n",
      "INFO:tensorflow:global_step/sec: 4.1321\n",
      "INFO:tensorflow:loss = 6.151272, step = 7500 (24.201 sec)\n",
      "INFO:tensorflow:loss = 5.92468, step = 7500 (24.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17746\n",
      "INFO:tensorflow:global_step/sec: 4.1768\n",
      "INFO:tensorflow:loss = 6.2712336, step = 7600 (23.938 sec)\n",
      "INFO:tensorflow:loss = 6.205436, step = 7600 (23.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23828\n",
      "INFO:tensorflow:global_step/sec: 4.2383\n",
      "INFO:tensorflow:loss = 6.0196495, step = 7700 (23.594 sec)\n",
      "INFO:tensorflow:loss = 6.0562906, step = 7700 (23.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.12778\n",
      "INFO:tensorflow:global_step/sec: 4.12776\n",
      "INFO:tensorflow:loss = 6.262889, step = 7800 (24.226 sec)\n",
      "INFO:tensorflow:loss = 6.2666864, step = 7800 (24.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17748\n",
      "INFO:tensorflow:global_step/sec: 4.17742\n",
      "INFO:tensorflow:loss = 6.415777, step = 7900 (23.938 sec)\n",
      "INFO:tensorflow:loss = 6.326841, step = 7900 (23.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.1339\n",
      "INFO:tensorflow:global_step/sec: 4.13385\n",
      "INFO:tensorflow:loss = 6.3761587, step = 8000 (24.190 sec)\n",
      "INFO:tensorflow:loss = 6.5520725, step = 8000 (24.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22653\n",
      "INFO:tensorflow:global_step/sec: 4.22654\n",
      "INFO:tensorflow:loss = 6.435708, step = 8100 (23.660 sec)\n",
      "INFO:tensorflow:loss = 6.4204583, step = 8100 (23.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.21681\n",
      "INFO:tensorflow:global_step/sec: 4.21676\n",
      "INFO:tensorflow:loss = 6.3785133, step = 8200 (23.451 sec)\n",
      "INFO:tensorflow:loss = 6.4873476, step = 8200 (23.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.19396\n",
      "INFO:tensorflow:global_step/sec: 4.19397\n",
      "INFO:tensorflow:loss = 6.4465623, step = 8300 (23.844 sec)\n",
      "INFO:tensorflow:loss = 6.6333513, step = 8300 (23.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17153\n",
      "INFO:tensorflow:global_step/sec: 4.17152\n",
      "INFO:tensorflow:loss = 6.6143737, step = 8400 (23.972 sec)\n",
      "INFO:tensorflow:loss = 6.7397676, step = 8400 (23.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24007\n",
      "INFO:tensorflow:global_step/sec: 4.2401\n",
      "INFO:tensorflow:loss = 6.6237907, step = 8500 (23.584 sec)\n",
      "INFO:tensorflow:loss = 6.6384687, step = 8500 (23.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.18624\n",
      "INFO:tensorflow:global_step/sec: 4.18619\n",
      "INFO:tensorflow:loss = 6.6748905, step = 8600 (23.888 sec)\n",
      "INFO:tensorflow:loss = 6.5936966, step = 8600 (23.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.18478\n",
      "INFO:tensorflow:global_step/sec: 4.18472\n",
      "INFO:tensorflow:loss = 6.8372555, step = 8700 (23.897 sec)\n",
      "INFO:tensorflow:loss = 6.6861677, step = 8700 (24.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.09588\n",
      "INFO:tensorflow:global_step/sec: 4.09588\n",
      "INFO:tensorflow:loss = 6.766254, step = 8800 (24.084 sec)\n",
      "INFO:tensorflow:loss = 6.788624, step = 8800 (24.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2514\n",
      "INFO:tensorflow:loss = 6.752, step = 8900 (23.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.25116\n",
      "INFO:tensorflow:loss = 6.8271656, step = 8900 (23.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22232\n",
      "INFO:tensorflow:global_step/sec: 4.2221\n",
      "INFO:tensorflow:loss = 6.793917, step = 9000 (23.684 sec)\n",
      "INFO:tensorflow:loss = 6.82543, step = 9000 (23.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.184\n",
      "INFO:tensorflow:global_step/sec: 4.18394\n",
      "INFO:tensorflow:loss = 6.856535, step = 9100 (23.901 sec)\n",
      "INFO:tensorflow:loss = 6.849081, step = 9100 (23.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24788\n",
      "INFO:tensorflow:global_step/sec: 4.24779\n",
      "INFO:tensorflow:loss = 6.8662357, step = 9200 (23.541 sec)\n",
      "INFO:tensorflow:loss = 6.8298883, step = 9200 (23.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.14205\n",
      "INFO:tensorflow:global_step/sec: 4.14199\n",
      "INFO:tensorflow:loss = 6.8107576, step = 9300 (24.143 sec)\n",
      "INFO:tensorflow:loss = 6.878744, step = 9300 (24.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.13594\n",
      "INFO:tensorflow:global_step/sec: 4.13588\n",
      "INFO:tensorflow:loss = 6.7419662, step = 9400 (23.983 sec)\n",
      "INFO:tensorflow:loss = 6.801876, step = 9400 (24.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27055\n",
      "INFO:tensorflow:global_step/sec: 4.2706\n",
      "INFO:tensorflow:loss = 6.6563873, step = 9500 (23.416 sec)\n",
      "INFO:tensorflow:loss = 6.501853, step = 9500 (23.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.16974\n",
      "INFO:tensorflow:global_step/sec: 4.16975\n",
      "INFO:tensorflow:loss = 5.854846, step = 9600 (23.982 sec)\n",
      "INFO:tensorflow:loss = 5.8051686, step = 9600 (23.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23531\n",
      "INFO:tensorflow:global_step/sec: 4.2353\n",
      "INFO:tensorflow:loss = 5.0454397, step = 9700 (23.611 sec)\n",
      "INFO:tensorflow:loss = 5.3273478, step = 9700 (23.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.21026\n",
      "INFO:tensorflow:global_step/sec: 4.21025\n",
      "INFO:tensorflow:loss = 5.720562, step = 9800 (23.751 sec)\n",
      "INFO:tensorflow:loss = 5.48579, step = 9800 (23.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22416\n",
      "INFO:tensorflow:global_step/sec: 4.22416\n",
      "INFO:tensorflow:loss = 5.306076, step = 9900 (23.674 sec)\n",
      "INFO:tensorflow:loss = 6.2421856, step = 9900 (23.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.21468\n",
      "INFO:tensorflow:global_step/sec: 4.21464\n",
      "INFO:tensorflow:loss = 5.432027, step = 10000 (23.726 sec)\n",
      "INFO:tensorflow:loss = 5.757989, step = 10000 (23.503 sec)\n",
      "INFO:tensorflow:Loss for final step: 5.942581.\n",
      "INFO:tensorflow:Loss for final step: 6.1382895.\n"
     ]
    }
   ],
   "source": [
    "!az batchai job file stream -w $WORKSPACE -e $EXPERIMENT --j $JOB_NAME --output-directory-id stdouterr -f stderr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either wait for the job to complete or delete it with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az batchai job delete -w $WORKSPACE -e $EXPERIMENT --name $JOB_NAME -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we wish to tidy up the resource we created.\n",
    "First we delete the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az configure --defaults group=''\n",
    "!az configure --defaults location=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az batchai cluster delete -w $WORKSPACE --name $CLUSTER_NAME -g $GROUP_NAME -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cluster is deleted you will not incur any cost for the computation but you can still retain your experiments and workspace. If you wish to delete those as well execute the commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished ..\u001b[31maz: error: unrecognized arguments: -w workspace\u001b[0m\n",
      "usage: az [-h] [--verbose] [--debug] [--output {json,jsonc,table,tsv}]\n",
      "          [--query JMESPATH]\n",
      "          {batchai} ...\n"
     ]
    }
   ],
   "source": [
    "!az batchai experiment delete -w $WORKSPACE --name $EXPERIMENT -g $GROUP_NAME -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az batchai workspace delete -n $WORKSPACE -g $GROUP_NAME -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can delete the group and we will have deleted everything created for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^CK - Running ...\n",
      "\u001b[K\u001b[31mLong-running operation wait cancelled.  \u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az group delete --name $GROUP_NAME -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
